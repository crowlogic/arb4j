\documentclass{article}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb}

%%%%%%%%%% Start TeXmacs macros
\newcommand{\tmtextbf}[1]{\text{{\bfseries{#1}}}}
%%%%%%%%%% End TeXmacs macros

%


\begin{document}

\title{Variance Structure Function and Dudley's Metric Entropy Integral}

\date{}

\maketitle

\section{Variance Structure Function}

The \tmtextbf{variance structure function} for a Gaussian process $X_t$ is
defined as:
\begin{equation}
  D (s, t) =\mathbb{E} [|X_s - X_t |^2]
\end{equation}
This function describes the variance of points of the function separated by a
given distance.

\section{Induced Metric}

The induced metric based on the variance structure function is defined as:
\begin{equation}
  d (s, t) = \sqrt{D (s, t)} = \sqrt{\mathbb{E} [|X_s - X_t |^2]}
\end{equation}
This metric reflects how distances between points relate to their variability.

\section{Dudley's Metric Entropy Integral}

\tmtextbf{Dudley's theorem} relates the expected supremum of a stochastic
process to the complexity of its function space via an entropy integral. The
relevant integral is expressed as:
\begin{equation}
  \int_0^D \sqrt{\log N (T, d ; \epsilon)}  \hspace{0.17em} d \epsilon
\end{equation}
where:
\begin{itemize}
  \item $D$ is the diameter of the space defined by the metric $d$.
  
  \item $N (T, d ; \epsilon)$ is the covering number that counts the minimum
  number of balls of radius $\epsilon$ needed to cover $T$.
\end{itemize}

\section{Significance of the Variance Structure Function}

The variance structure function $D (s, t)$ is essential for understanding the
behavior of a Gaussian process. It describes the variance of points of the
function separated by a given distance.

This function provides insight into the relationships and dependencies between
outputs of the process at various locations. Understanding this structure is
crucial for interpreting the stochastic nature of Gaussian processes and their
continuity properties.

\section{Application in Gaussian Processes}

For a zero-mean Gaussian process indexed by $t \in T$, Dudley's theorem states
that:
\begin{equation}
  \mathbb{E} [\sup_{t \in T} X_t] \leq C \int_0^D \sqrt{\log N (T, d ;
  \epsilon)}  \hspace{0.17em} d \epsilon
\end{equation}
where $C$ is a constant that may depend on specific properties of the process.

\section{Variance Structure Function}

{\noindent}For a real-valued Gaussian process $\{X_t \}_{t \in \mathbb{R}}$:
\begin{equation}
  \begin{array}{ll}
    R (s, t) & =\mathbb{E} [(X_s -\mathbb{E}[X_s]) (X_t -\mathbb{E}[X_t])]\\
    & = \int_{- \infty}^{\infty} \int_{- \infty}^{\infty} (X_u
    -\mathbb{E}[X_u])  (X_v -\mathbb{E}[X_v])  \hspace{0.17em} dudv\\
    & = \lim_{n \to \infty}  \sum_{i = 1}^n (X_{t_i} -\mathbb{E}[X_{t_i}]) 
    (X_{t_{i + 1}} -\mathbb{E}[X_{t_{i + 1}}])\\
    & = \frac{1}{2}  (v (s, s) + v (t, t) - v (s, t))
  \end{array}
\end{equation}



\begin{equation}
  \begin{array}{ll}
    v (s, t) & =\mathbb{E} [(X_s - X_t)^2]\\
    & = \int_{- \infty}^{\infty} \int_{- \infty}^{\infty} (X_u - X_v)^2 
    \hspace{0.17em} dudv\\
    & = R (s, s) + R (t, t) - 2 R (s, t)\\
    & = \lim_{n \to \infty}  \sum_{i = 1}^n (X_{t_i} - X_{t_{i - 1}})^2
  \end{array}
\end{equation}
where $t_i = s + i (\frac{t - s}{n})$ for $i \in \{1, \ldots, n\}$.
\begin{equation}
  \begin{array}{ll}
    d (s, t) & = \sqrt{v (s, t)} = \sqrt{\mathbb{E} [(X_s - X_t)^2]} = \sqrt{R
    (s, s) + R (t, t) - 2 R (s, t)}
  \end{array}
\end{equation}

\end{document}
