\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{footnote}

\title{On Harmonizable Stochastic Processes}

\author{
STAMATIS CAMBANIS\thanks{Research of both authors supported by the National Science Foundation under Grant GK-1439 and by the Air Force Office of Scientific Research under Grant AFOSR-1333-67.}\thanks{Formerly with the Department of Electrical Engineering, Princeton University, Princeton, New Jersey.}\\
Department of Statistics, University of North Carolina, Chapel Hill, North Carolina 27514
\and
BEDE LIU\\
Department of Electrical Engineering, Princeton University, Princeton, New Jersey 08540
}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\begin{document}
\maketitle

\begin{abstract}
This paper presents a new orthogonal series representation and a new orthogonal integral representation for harmonizable stochastic processes. It also demonstrates the importance of harmonizable stochastic processes in systems analysis by showing that the output of a wide class of systems is a harmonizable process.
\end{abstract}

\section*{1. Introduction}

Harmonizable stochastic processes, a generalization of wide sense stationary processes, have been investigated in connection with a variety of subjects. Properties related to their integral representation have been studied by Lo\`{e}ve \cite{loeve1963} and Rosanov \cite{rosanov1959}, their special role in the multiplicity theory of purely nondeterministic stochastic processes has been demonstrated by Cramer \cite{cramer1964}, and sampling theorems have been derived by Piranashvili \cite{piranashvili1967} and Rao \cite{rao1967}.

This paper makes two contributions related to the class of harmonizable stochastic processes. First it is proved under some general conditions that the output of a linear system is a harmonizable stochastic process; the system may be randomly time-varying and the input process need not be stationary nor even harmonizable. Thus harmonizable processes are the most general processes that need be considered in the analysis of a wide class of linear systems. In such analyses as well as in many other problems in communications and controls, series representation of stochastic processes has been used as a powerful tool. The second contribution of this paper is a series representation for harmonizable stochastic processes. A constructive procedure for obtaining the series representation is given. This representation is valid over the entire real line, while the well-known Karhunen-Lo\`{e}ve series representation is valid only on compact intervals. An orthogonal integral representation for harmonizable stochastic processes is also derived in this paper.

\section*{2. Notation}

Some definitions and basic properties are briefly mentioned here. For a more detailed discussion the reader is referred to Karhunen \cite{karhunen1947}, Cramer \cite{cramer1951}, Rosanov \cite{rosanov1959}, Parzen \cite{parzen1967}, and Masani \cite{masani1968}.

Consider a probability space $(\Omega, \mathscr{M}, P)$ and the Hilbert space $L_{2}(\Omega, \mathscr{M}, P)$ of all complex valued random variables with finite mean square value. A random measure $X$ on a class of subsets $\mathscr{N}$ of a set $E$ is a countably additive function on $\mathscr{N}$ to $L_{2}(\Omega, \mathscr{M}, P)$, i.e., $X(S, \omega)=\sum_{n=1}^{\infty} X\left(S_{n}, \omega\right)$ in the mean square sense whenever the disjoint sets $S_{n}, n=1,2, \ldots$, are in $\mathscr{N}$ and $S=\bigcup_{n=1}^{\infty} S_{n} \in \mathscr{N}$. To each $X$ on $\mathscr{N}$ there corresponds a complex measure $r_{X}$ defined on $\mathscr{N} \times \mathscr{N}$ by $r_{X}\left(S_{1} \times S_{2}\right)=\mathscr{E}\left[X\left(S_{1}, \omega\right) X^{*}\left(S_{2}, \omega\right)\right]$, where $\mathscr{E}$ is the expectation operator and the star denotes complex conjugate. $r_{X}$ is nonnegative definite on $\mathscr{N} \times \mathscr{N}$. $X$ is orthogonal if and only if $r_{X}\left(S_{1} \times S_{2}\right)=0$, whenever $S_{1}$ and $S_{2}$ are disjoint. To each orthogonal $X$ on $\mathscr{N}$ there corresponds a nonnegative measure $Q_{X}$ defined on $\mathscr{N}$ by $Q_{X}(S)=\mathscr{E}|X(S, \omega)|^{2}$. Usually $X$ is initially defined on a semiring of subsets $\mathscr{N}$. If $r_{X}$ is of bounded variation over $\mathscr{N} \times \mathscr{N}$ then $X$ can be extended to the restricted $\sigma$-ring $\mathscr{B}_{0}=\left\{S \in \sigma(\mathscr{N})=\mathscr{B} ;\left|r_{X}\right|(S \times S)<\infty\right\}$. We then say that $X$ is a random measure on $(E, \mathscr{B})$.

Let $L_{2}(X)=\sigma\left\{X(S, \omega) ; S \in \mathscr{B}_{0}\right\}$ denote the span of $X$ in $L_{2}(\Omega, \mathscr{M}, P)$ and let $\Lambda_{2}\left(r_{X}\right)$ be the set of all complex valued, $\mathscr{B}$-measurable functions $f$ on $E$ such that $\int_{E \times E} f(t) f^{*}(s) r_{X}(d t, d s)$ is finite. Then, upon considering two functions $f$ and $g$ in $\Lambda_{2}\left(r_{x}\right)$ as identical if and only if
\[
\int_{E \times E}[f(t)-g(t)]\left[f^{*}(s)-g^{*}(s)\right] r_{X}(d t, d s)=0,
\]
$\Lambda_{2}\left(r_{X}\right)$ becomes a Hilbert space with inner product
\[
(f, g)_{A_{2}\left(r_{X}\right)}=\int_{E \times E} f(t) g^{*}(s) r_{X}(d t, d s)
\]
and $\Lambda_{2}\left(r_{X}\right)=\sigma\left\{I_{S}(t) ; S \in \mathscr{B}_{0}\right\}$, where $I$ is the indicator function. $L_{2}(X)$ and $\Lambda_{2}\left(r_{X}\right)$ are isomorphic with corresponding elements $X(S, \omega)$ and $I_{S}(t)$, $S \in \mathscr{B}_{0}$, and integration of functions in $A_{2}\left(r_{X}\right)$ with respect to $X$ is defined by $\xi(\omega)=\int_{E} f(t) X(d t, \omega)$, where $\xi$ and $f$ are corresponding elements under the isomorphism.

\section*{3. Representation of Harmonizable Stochastic Processes}

Harmonizable stochastic processes have been introduced by Lo\`{e}ve \cite{loeve1963} as a first step generalization of wide sense stationary mean square continuous stochastic processes. A second-order stochastic process $\{x(t, \omega), t \in R^{1}, \omega \in \Omega\}$ is harmonizable if and only if it has the integral representation
\[
x(t, \omega)=\int_{-\infty}^{\infty} e^{i t u} X(d u, \omega) \quad \text { for all } \quad t \in R^{1}
\]
where $X$ is a random measure defined for all Borel sets $\mathscr{B}^{1}$ of the real line $R^{1}$.

It is shown by Lo\`{e}ve \cite{loeve1963} and Cram\`{e}r \cite{cramer1951} that a second-order stochastic process $x(t, \omega)$ is harmonizable if and only if its autocorrelation function $R_{x x}(t, s)$ has the integral representation
\[
R_{x x}(t, s)=\int_{-\infty}^{\infty} \int^{\infty} e^{i(t u-s v)} r_{X}(d u, d v) \quad \text { for all } \quad t, s \in R^{1}
\]
where $r_{X}$ is a measure of bounded variation on the whole plane $R^{2}$ and nonnegative definite on $\mathscr{B}^{1} \times \mathscr{B}^{1}$. $r_{X}$ can be regarded as the two-dimensional spectral measure of the harmonizable process $x(t, \omega)$, with two-dimensional spectral distribution $\rho_{x x}(u, v)=r_{X}((-\infty, u] \times(-\infty, v])$.

It is clear that a mean square continuous wide sense stationary stochastic process is harmonizable, with $X$ an orthogonal random measure and $r_{X}$ a nonnegative measure concentrated on the diagonal of the plane.

The functions $\{e^{i t u}, t \in R^{1}\}$ span the whole $\Lambda_{2}(r_{X})$ space and this implies that $L_{2}(x)=L_{2}(X)$, where $L_{2}(x)=\sigma\{x(t, \omega), t \in R^{\mathbf{1}}\}$ denotes the span of $x$ in $L_{2}(\Omega, \mathscr{M}, P)$.

\section*{Orthogonal Series Representation of a Harmonizable Stochastic Process}

An orthogonal series representation for harmonizable stochastic processes is provided by the following:

\begin{theorem}
A harmonizable stochastic process $\{x(t, \omega), t \in R^{1}, \omega \in \Omega\}$ is uniformly mean square continuous and has an orthogonal series expansion
\[
x(t, \omega)=\sum_{n} a_{n}(t) \xi_{n}(\omega)
\]
in the mean square sense for all $t \in R^{1}$, where
\[
\xi_{n}(\omega)=\int_{-\infty}^{\infty} f_{n}(u) X(d u, \omega), \quad \mathscr{E}[\xi_{n} \xi_{m}^{*}]=\delta_{n m}
\]
and
\[
a_{n}(t)=\iint_{-\infty}^{\infty} e^{i t u} f_{n}^{*}(v) r_{X}(d u, d v)
\]
and $\{f_{n}(\cdot)\}$ is an orthonormal and complete set of functions in $\Lambda_{2}(r_{X})$.
\end{theorem}

\begin{proof}
The autocorrelation function $R_{x x}(t, s)$ of $x(t, \omega)$ is given by (2). Since $e^{i(t u-s v)}$ is continuous in $t, s$ uniformly in $u, v$ and is bounded by 1, which is integrable with respect to $r_{X}$, it follows by the bounded convergence theorem that $R_{x x}(t, s)$ is uniformly continuous in $t, s$. Hence $x(t, \omega)$ is uniformly mean square continuous.

Since $x(t, \omega)$ is mean square continuous, $L_{2}(x)$ is separable, as shown by Parzen \cite{parzen1967} in Theorem 2C. Hence $L_{2}(X)=L_{2}(x)$ is separable and so is its isomorphic space $\Lambda_{2}(r_{X})$. Let $\{f_{n}(\cdot)\}$ be an orthonormal basis in $\Lambda_{2}(r_{X})$. If for each $n, \xi_{n}(\omega)$ is the element of $L_{2}(x)$ corresponding to $f_{n}(\cdot) \in \Lambda_{2}(r_{X})$ under the isomorphism, then $\{\xi_{n}(\omega)\}$ is an orthonormal basis in $L_{2}(X)=L_{2}(x)$, i.e., $\mathscr{E}[\xi_{n} \xi_{m}^{*}]=\delta_{n m}$, and
\[
\xi_{n}(\omega)=\int_{-\infty}^{\infty} f_{n}(u) X(d u, \omega)
\]

Hence, for all $t \in R^{1}$, we have
\[
x(t, \omega)=\sum_{n} a_{n}(t) \xi_{n}(\omega)
\]
in the mean square sense and
\[
a_{n}(t)=\mathscr{E}[x(t) \xi_{n}^{*}]
\]

Since $x(t, \omega)$ and $e^{i t u}$, as well as $\xi_{n}(\omega)$ and $f_{n}(u)$, are corresponding elements of $L_{2}(X)$ and $\Lambda_{2}(r_{X})$ under the isomorphism, we obtain
\[
a_{n}(t)=(e^{i t u}, f_{n}(u))_{\Lambda_{2}(r_{X})}=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{i t u} f_{n}^{*}(v) r_{X}(d u, d v)
\]
\end{proof}

It follows from (3) and (4) that the autocorrelation function of a harmonizable stochastic process $x(t, \omega)$ has a series expansion
\[
R_{x x}(t, s)=\sum_{n} a_{n}(t) a_{n}^{*}(s) \quad \text { for all } \quad t, s \in R^{1}
\]
where the $a_{n}$'s are given by (5).

For all $f \in \Lambda_{2}(r_{x})$ we have $e^{i t u} f(u) \in \Lambda_{2}(r_{X})$ for all $t \in R^{1}$, since
\[
|e^{i t u} f(u)| \leqslant |f(u)| \in \Lambda_{2}(r_{X})
\]

Hence
\[
y(t, \omega)=\int_{-\infty}^{\infty} e^{i t u} f(u) X(d u, \omega)
\]
is well-defined in $L_{2}(X)=L_{2}(x)$ and is thus a linear operation on $x(t, \omega)$. $y(t, \omega)$ is harmonizable itself, since if a random measure $Y$ is defined by $Y(S, \omega)=\int_{S} f(u) X(d u, \omega)$ for all $S \in \mathscr{B}^{1}$, then $Y$ is finite on $R^{1}$ and
\[
y(t, \omega)=\int_{-\infty}^{\infty} e^{i t u} Y(d u, \omega)
\]

Let $y_{n}(t, \omega)$ be the linear operation on $x(t, \omega)$ defined by (7) when $f(u)=f_{n}(u)
Let $y_{n}(t, \omega)$ be the linear operation on $x(t, \omega)$ defined by (7) when $f(u)=f_{n}(u)$. Then $\xi_{n}(\omega)=y_{n}(0, \omega)$. If $f_{n}$ has Fourier transform $h_{n}$, i.e., if $f_{n}(u)=\int_{-\infty}^{\infty} h_{n}(v) e^{-i u v} m(d v)$, with $h_{n} \in L_{1}(R^{1}, \mathscr{B}^{1}, m)$, then, as it is shown by Rosanov \cite{rosanov1959}, p. 278, the order of integration in (7) can be interchanged to give
\[
y_{n}(t, \omega)=\int_{-\infty}^{\infty} h_{n}(v) x(t-v, \omega) m(d v)
\]

Hence $\xi_{n}(\omega)$ may be regarded as the output at time $t=0$ of a linear time invariant system with impulse response $h_{n}$ and input $x(t, \omega)$. We also obtain from (5)
\[
a_{n}(t)=\int_{-\infty}^{\infty} h_{n}^{*}(\tau) R_{x x}(t,-\tau) m(d \tau)
\]

It should be noted that the series representation of Theorem 1 is by no means unique, since for each orthonormal and complete set of functions in $\Lambda_{2}(r_{X})$ a distinct representation (3) is obtained by (4) and (5). However, in the context of a particular problem, one may be able to determine those representations, if any, which have some optimal properties. The significance of the representation is primarily in the fact that it exists and it is orthogonal, which enables one to use it as a model for the harmonizable process in problems involving mean square error criteria.

Theorem 1 has been proven for mean square continuous, wide sense stationary stochastic processes by Masry et. al. \cite{masry1968} and also by Campbell \cite{campbell1969}.

The orthogonal series expansion (3) has been shown in Theorem 1 to hold for all harmonizable stochastic processes. Some nonorthogonal series expansions have been reported in the literature for particular cases of harmonizable processes. It is shown by Piranashvili \cite{piranashvili1967} that if the support of $X$, or of $r_{X}$, is bounded then $x(t, \omega)$ admits a usual periodic sampling expansion; and that if the support of $X$, or of $r_{X}$, is not bounded then $x(t, \omega)$ can be approximated within $\epsilon$ in the mean square sense by a finite usual periodic sampling expansion, where both the number of terms and the sampling rate of the expansion depend on $\epsilon$. Rao \cite{rao1967} gave a necessary and sufficient condition for $L_{2}(x)=\sigma\{x(n T, \omega), n=0, \pm 1, \pm 2, \ldots\}$, i.e., for a periodic sampling expansion to approximate $x(t, \omega)$ arbitrarily closely in the mean square sense and also a sufficient condition for $L_{2}(x)=\sigma\{x(t_{n}, \omega), n=0, \pm 1, \pm 2, \ldots\}$ where $\{t_{n}\}$ is a bounded set with infinitely many distinct points, i.e., for a bounded nonperiodic sampling expansion to approximate $x(t, \omega)$ arbitrarily closely in the mean square sense.

\section*{Orthonormal and Complete Sets in $\Lambda_{2}(r_{X})$}

It is clear from Theorem 1 that an explicit series expansion of a harmonizable process can be obtained by using (4) and (5) provided an orthonormal and complete set of functions in $\Lambda_{2}(r_{X})$ can be constructed.

If the harmonizable process $x$ is stationary then $\Lambda_{2}(r_{X})$ is isomorphic to $L_{2}(R^{1}, \mathscr{B}^{1}, Q_{X})$, where $Q_{X}$ is a finite nonnegative measure, and a general procedure to construct an orthonormal basis in the latter space is presented by Masry et. al. \cite{masry1968}.

Since
\[
\Lambda_{2}(r_{X})=\sigma\{e^{i t u}, t \text{ real }\}=\sigma\{e^{i t u}, t \text{ rational }\},
\]
an orthonormal and complete set of functions in $\Lambda_{2}(r_{X})$ can be obtained by orthonormalizing the countable set of functions $\{e^{i t u}, t$ rational $\}$ using the Gram-Schmidt procedure. However, this procedure solves the problem of finding an orthonormal basis in $\Lambda_{2}(r_{X})$ only in principle.

The following theorem gives a complete set of functions $\{F_{n}(t)\}$ in $\Lambda_{2}(r_{X})$. By orthonormalizing the set $\{F_{n}(t)\}$ using the Gram-Schmidt procedure, an orthonormal and complete set $\{f_{n}(t)\}$ is obtained.

\begin{theorem}
Let $\mu$ be any finite, nonnegative measure on $(R^{1}, \mathscr{B}^{1})$, absolutely continuous with respect to the Lebesgue measure $m$ with Radon-Nikodym derivative $[d \mu / d m](t)=h(t) \neq 0$ a.e. $[m]$, and let $\{\phi_{n}(t)\}$ be any complete set of functions in $L_{2}(R^{1}, \mathscr{B}^{1}, \mu)=L_{2}(\mu)$. Then the set $\{F_{n}(t)\}$ given by
\[
F_{n}(t)=\int_{-\infty}^{\infty} \phi_{n}^{*}(u) e^{i t u} \mu(d u)
\]
is complete in $\Lambda_{2}(r_{X})$.
\end{theorem}

\begin{proof}
Since $\mu$ is finite, $\phi_{n} \in L_{2}(\mu)$ implies $\phi_{n} \in L_{1}(\mu)$ and hence the functions $F_{n}(t)$ are well-defined by (10) everywhere and
\[
|F_{n}(t)| \leqslant \int_{-\infty}^{\infty}|\phi_{n}^{*}(u)| \mu(d u)=\|\phi_{n}\|_{L_{1}(\mu)}
\]

This implies that $F_{n} \in \Lambda_{2}(r_{X})$ and
\[
\|F_{n}\|_{\Lambda_{2}(r_{X})}^{2} \leqslant\|\phi_{n}\|_{L_{1}(\mu)}^{2}|r_{X}|(R^{2}),
\]
where $|r_{X}|$ denotes the total variation of $r_{X}$.

The completeness of the set $\{F_{n}(t)\}$ in $\Lambda_{2}(r_{X})$ is shown as follows. Let $f \in \Lambda_{2}(r_{X})$ and $(F_{n}, f)_{\Lambda_{2}(r_{X})}=0$ for all $n$. Then
\[
\begin{aligned}
0 &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} F_{n}(u) f^{*}(v) r_{X}(d u, d v) \\
&= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \phi_{n}^{*}(t) e^{i t u} f^{*}(v) \mu(d t) r_{X}(d u, d v) \\
&= \int_{-\infty}^{\infty} F(t) \phi_{n}^{*}(t) \mu(d t)
\end{aligned}
\]
where
\[
F(t)=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{i t u} f^{*}(v) r_{X}(d u, d v)=(e^{i t u}, f(u))_{\Lambda_{2}(r_{X})}
\]

It follows by (12) that
\[
\begin{aligned}
|F(t)|^{2} &\leqslant \|e^{i t u}\|_{\Lambda_{2}(r_{X})}^{2}\|f\|_{\Lambda_{2}(r_{X})}^{2}=R_{x x}(t, t)\|f\|_{\Lambda_{2}(r_{X})}^{2} \\
&\leqslant |r_{X}|(R^{2})\|f\|_{\Lambda_{2}(r_{X})}^{2}
\end{aligned}
\]
and
\[
\int_{-\infty}^{\infty}|F(t)|^{2} \mu(d t) \leqslant |r_{X}|(R^{2})\|f\|_{\Lambda_{2}(r_{X})}^{2} \mu(R^{1})<\infty
\]
i.e., $F \in L_{2}(\mu)$. The completeness of the set $\{\phi_{n}(t)\}$ in $L_{2}(\mu)$ and (11) imply that $F=0$ in $L_{2}(\mu)$, i.e., $|F(t)|^{2} h(t)=0$ a.e. $[m]$. Since $h(t) \neq 0$ a.e. [m], it follows that $F(t)=0$ a.e. [m]. But the continuity of $e^{i t u}$ in $t$ and the bounded convergence theorem imply by (12) that $F(t)$ is continuous in $t$. Hence $F(t)=0$ for all $t \in R^{1}$ and by (12) $f$ is orthogonal to the set $\{e^{i t u}, t \in R^{1}\}$, which is dense in $\Lambda_{2}(r_{X})$. It follows that $f=0$ in $\Lambda_{2}(r_{X})$ and hence the set $\{F_{n}(t)\}$ is complete in $\Lambda_{2}(r_{X})$.
\end{proof}

It should be pointed out that the set of functions $\{F_{n}(t)\}$ given by (10), which is shown in Theorem 2 to be complete in any $\Lambda_{2}(r_{X})$ space with $r_{X}$ of bounded variation on the entire plane, is independent of the measure $r_{X}$ and is completely determined by $\mu$ and $\{\phi_{n}(t)\}$. It is clear, however, that the orthonormal and complete set of functions $\{f_{n}(t)\}$ in $\Lambda_{2}(r_{X})$, obtained by orthonormalizing the complete set $\{F_{n}(t)\}$, depends on the measure $r_{X}$.

Theorem 2 allows considerable freedom in the choice of the measure $\mu$ and complete freedom in the choice of the complete set of functions $\{\phi_{n}(t)\}$ in $L_{2}(\mu)$. As a complete set of functions in $L_{2}(\mu)$ one can choose the orthonormal and complete set $\{\phi_{n}(t)\}$ given by Masry et. al. \cite{masry1968}:
\[
\phi_{n}(t)=\frac{1}{\sqrt{\mu(R^{1})}} \exp\left(\frac{i n 2 \pi}{\mu(R^{1})} \int_{-\infty}^{t} h(u) m(d u)\right), \quad n=0, \pm 1, \pm 2, \ldots
\]

Upon normalizing $\mu, \mu(R^{1})=1$, and using the complete set (13) in (10) we obtain the complete set of functions
\[
\begin{aligned}
F_{n}(t) &=\int_{-\infty}^{\infty} \exp [i\{t u-n 2 \pi H(u)\}] h(u) m(d u) \quad n=0, \pm 1, \pm 2, \ldots \\
&=\int_{0}^{1} \exp \left[i\left\{t H^{-1}(v)-n 2 \pi v\right\}\right] m(d v)
\end{aligned}
\]
where $h$ is any probability density with $h(u) \neq 0$ a.e. [$m$], and
\[
H(u)=\int_{-\infty}^{u} h(v) m(d v)
\]

It is clear that the functions given by (10) are uniformly continuous and uniformly bounded for fixed $n$, and that the family of functions given by (14) is equicontinuous and uniformly bounded.

\textbf{Examples.} By chosing probability densities $h$ of particular form, we obtain by (14) various sets of complete functions in $\Lambda_{2}(r_{X})$. However, as it is illustrated by the following examples, the integral in (14) is not easily expressed in terms of the elementary and the special functions.

1. The density of the normal distribution, $h(u)=(1 / \sqrt{2 \pi}) e^{-\frac{1}{2} u^{2}}$, gives
\[
F_{n}(t)=(-1)^{n} \sqrt{\frac{2}{\pi}} \int_{0}^{\infty} \cos \left[t u-n \pi \Phi\left(\frac{u}{\sqrt{2}}\right)\right] e^{-\frac{1}{2} u^{2}} m(d u)
\]
where $\Phi(u)=(2 / \sqrt{\pi}) \int_{0}^{u} e^{-v^{2}} m(d v)$.

2. The density of the double exponential distribution, $h(u)=\frac{1}{2} e^{-|u|}$, gives
\[
\begin{aligned}
F_{n}(t) &=\int_{0}^{\infty} e^{-u} \cos \left[t u+n \pi e^{-u}\right] m(d u) \\
&=\int_{0}^{1} \cos [t \ln v-n \pi v] m(d v)
\end{aligned}
\]

3. The density of the Cauchy distribution, $h(u)=(1 / \pi(1+u^{2}))$, gives
\[
\begin{aligned}
F_{n}(t) &=(-1)^{n} \frac{2}{\pi} \int_{0}^{\infty} \cos \left[t u-2 n \tan^{-1} u\right] \frac{m(d u)}{1+u^{2}} \\
&=(-1)^{n} \frac{2}{\pi} \int_{0}^{\pi / 2} \cos [t \tan v-2 n v] m(d v)
\end{aligned}
\]

4. The probability density
\[
h(u)= \begin{cases}
\alpha^{-k} & \text{ on } (k-1, k), \quad k \leqslant-1 \\
\frac{1-3 \alpha}{2(1-\alpha)} & \text{ on } (-1,+1), \\
\alpha^{k} & \text{ on } (k, k+1), \quad k \geqslant 1
\end{cases}
\]
where $0<\alpha<\frac{1}{3}$, gives
\[
F_{n}(t)=2(-1)^{n} \sum_{k=0}^{\infty} \alpha^{k} \cos \left[\left(k+\frac{1}{2}\right) t-n \pi c_{k}\right] \frac{\sin \left(\frac{1}{2} t-n \pi \alpha^{k}\right)}{\frac{1}{2} t-n \pi \alpha^{k}},
\]
where $c_{k}=1-(1+\alpha / 1-\alpha) \alpha^{k}$.

5. If $r_{X}$ is supported by $(a, b) \times(a, b)$, then by using the density of the uniform distribution on $(a, b), h(u)=(1 / b-a)$ on $(a, b)$ and zero elsewhere, we obtain the complete set of functions
\[
F_{n}(t)=\frac{e^{i b t}-e^{i a t}}{i[(b-a) t-n 2 \pi]}
\]
which in the particular case where $a=-T, b=T$ gives
\[
F_{n}(t)=(-1)^{n} \frac{\sin \left[\pi\left(\frac{T}{\pi} t-n\right)\right]}{\pi\left(\frac{T}{\pi} t-n\right)}
\]

\section*{Orthogonal Integral Representation of a Harmonizable Stochastic Process}

Clearly any second order stochastic process $x(t, \omega)$ having an orthogonal series expansion of the form (3) admits a trivial orthogonal integral representation of the form
\[
x(t, \omega)=\int_{-\infty}^{\infty} f(t, u) Y(d u, \omega),
\]
where the orthogonal random measure $Y$ is concentrated on the set of integers with $Y(\{n\}, \omega)=\xi_{n}(\omega)$ and $f(t, n)=a_{n}(t)$.

The following theorem shows that an explicit (nontrivial) orthogonal integral representation of a harmonizable stochastic process can always be obtained and that the nonnegative measure associated with the orthogonal random measure can be chosen arbitrarily from a wide class of measures.

\begin{theorem}
Let $\mu$ be any nonnegative measure on $(R^{1}, \mathscr{B}^{1})$, finite on the bounded Borel sets $\mathscr{B}$ and such that $L_{2}(R^{1}, \mathscr{B}^{1}, \mu)=L_{2}(\mu)$ is infinite dimensional. Let $\{\varphi_{n}(\cdot)\}$ be an orthonormal and complete set of functions in $L_{2}(\mu)$. Then every harmonizable stochastic process $x(t, \omega)$ admits an orthogonal integral representation
\[
x(t, \omega)=\int_{-\infty}^{\infty} f(t, u) Y(d u, \omega)
\]

The function $f(t, u)$ is given by
\[
f(t, u)=\sum_{n} a_{n}(t) \varphi_{n}(u)
\]
in $L_{2}(\mu)$ for all $t \in R^{1}$. The orthogonal random measure $Y$ is defined on $\mathscr{B}$ by
\[
Y(S, \omega)=\sum_{n} \xi_{n}(\omega) \int_{S} \varphi_{n}^{*}(u) \mu(d u)
\]
in the mean square sense for all $S \in \mathscr{B}$ and has $Q_{Y}=\mu$. The $a_{n}$'s and the $\xi_{n}$'s are given in Theorem 1.
\end{theorem}

\begin{proof}
We first show that $Y$ is well-defined on $\mathscr{B}$ by (17) and that it is orthogonal. Since $\mu$ is finite on $\mathscr{B}, I_{S} \in L_{2}(\mu)$ for all $S \in \mathscr{B}$. Hence
\[
I_{S}(u)=\sum_{n} b_{n}(S) \varphi_{n}(u)
\]
where
\[
b_{n}(S)=\int_{S} \varphi_{n}^{*}(u) \mu(d u)
\]

It follows that
\[
\begin{aligned}
&\sum_{n} \int_{S_{1}} \varphi_{n}^{*}(u) \mu(d u) \int_{S_{2}} \varphi_{n}(u) \mu(d u) \\
&\quad=(I_{S_{1}}, I_{S_{2}})_{L_{2}(\mu)}=\mu(S_{1} \cap S_{2})<\infty \quad \text{ for all } \quad S_{1}, S_{2} \in \mathscr{B}
\end{aligned}
\]
and in particular that
\[
\sum_{n}\left|\int_{S} \varphi_{n}^{*}(u) \mu(d u)\right|^{2}=\|I_{S}\|_{L_{2}(\mu)}^{2}=\mu(S)<\infty
\]

Hence $Y$ is well-defined by (17) in $L_{2}(\Omega, \mathscr{M}, P)$ for all $S \in \mathscr{B}$. It follows by (17) and (18) that
\[
r_{Y}(S_{1} \times S_{2})=\mu(S_{1} \cap S_{2})
\]
and thus $Y$ is orthogonal with $Q_{Y}=\mu$.

We next show that $f(t, u)$ is well-defined in $L_{2}(\mu)$ by (16) for all $t \in R^{1}$. This is clear since from (6)
\[
\sum_{n}|a_{n}(t)|^{2}=R_{x x}(t, t)<\infty \quad \text{ for all } \quad t \in R_{1}
\]

Hence the integral in (15) is well-defined and from (16), (17), and (3) we have
\[
\begin{aligned}
\int_{-\infty}^{\infty} f(t, u) Y(d u, \omega) &=\sum_{n} a_{n}(t) \int_{-\infty}^{\infty} \varphi_{n}(u) Y(d u, \omega) \\
&=\sum_{n} a_{n}(t) \sum_{m} \int_{-\infty}^{\infty} \varphi_{n}(u) \varphi_{m}^{*}(u) \mu(d u) \xi_{m}(\omega) \\
&=\sum_{n} a_{n}(t) \xi_{n}(\omega)=x(t, \omega)
\end{aligned}
\]
which proves (15).
\end{proof}

The freedom in choosing the measure $\mu$ enables us to obtain various orthogonal integral representations (15) of particular form. If $\mu$ is chosen to be a finite nonnegative measure on $R^{1}$ then $Y$ will be finite on the whole real line and the $\varphi_{n}$'s can be chosen as in (13) given by Masry et. al. \cite{masry1968}. If $\mu$ is chosen to be the Lebesgue measure or the Lebesgue measure restricted to the half line or to an interval, then the $\varphi_{n}$'s may be chosen to be well-known orthonormal and complete sets of functions such as the Tchebysheff-Hermite functions, the Tchebysheff-Laguerre functions, the Legendre polynomials or the trigonometric system. In this latter case it is clear from (20) that the orthogonal random measure $Y$ has stationary values.

A harmonizable stochastic process is shown to have the nonorthogonal integral representation (1), the orthogonal series expansion (3) and the orthogonal integral representation (15). The relationship between the orthogonal random measure $Y$ and the random measure $X$ is
\[
Y(S, \omega)=\int_{-\infty}^{\infty}\left[\sum_{n} f_{n}(v) \int_{S} \varphi_{n}^{*}(u) \mu(d u)\right] X(d v, \omega)
\]
for all $S \in \mathscr{B}$, which can be obtained by (17) and (4).

\section*{4. Moving Average Representations and Harmonizable Stochastic Processes}

A second-order stochastic process $\{x(t, \omega), t \in R^{1}, \omega \in \Omega\}$ is said to have a moving average representation if and only if
\[
x(t, \omega)=\int_{-\infty}^{\infty} f(t-u) X(d u, \omega) \quad \text{ for all } \quad t \in R^{1}
\]
where $X$ is a random measure defined on the bounded Borel sets of $R^{1}$ and $f(t-\cdot) \in \Lambda_{2}(r_{X})$ for all $t \in R^{1}$. This is a generalization of the usual definition which assumes $X$ to be orthogonal and $Q_{X}$ to be the Lebesgue measure. A moving average representation is orthogonal if and only if $X$ is orthogonal and in this case $f(t-\cdot) \in L_{2}(Q_{X})$ for all $t \in R^{1}$.

It is shown by Karhunen \cite{karhunen1947} and Doob \cite{doob1953} that (i) a second-order stochastic process which has an orthogonal moving average representation with $Q_{X}=m$, the Lebesgue measure, and $f \in L_{2}(R^{1}, \mathscr{B}^{1}, m)=L_{2}(m)$ is mean square continuous wide sense stationary and has absolutely continuous spectrum; and conversely that (ii) a mean square continuous wide sense stationary process with absolutely continuous spectrum has a moving average representation with $Q_{X}=m$ and $f \in L_{2}(m)$ is the Fourier transform of the square root of its spectral density.

Sufficient conditions for the harmonizability of a stochastic process which has a moving average representation are given in the following

\begin{theorem}
If a second-order stochastic process $x(t, \omega)$ has a moving average representation with $r_{X}$ a measure of bounded variation on the entire plane $R^{2}, f \in L_{1}(m)$ and its Fourier transform $F \in L_{1}(m)$, then $x(t, \omega)$ is harmonizable.
\end{theorem}

\begin{proof}
We have
\[
f(\tau)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} F(\rho) e^{i \tau \rho} m(d \rho)
\]

Since $F \in L_{1}(m)$ and $r_{X}$ is finite, by interchanging the order of integration (see Rosanov \cite{rosanov1959}, p. 287), we obtain from (22)
\[
x(t, \omega)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} F(\rho) e^{-i u \rho} e^{i t \rho} X(d u, \omega) m(d \rho)
\]

Also, $F \in L_{1}(m)$ and $r_{X}$ finite imply that for all $S \in \mathscr{B}^{1}$
\[
\int_{S} F(\rho) e^{-i u \rho} m(d \rho) \in \Lambda_{2}(r_{X})
\]

Hence the random measure $Y$ on $(R^{1}, \mathscr{B}^{1})$ is well-defined by
\[
Y(S, \omega)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty}\left[\int_{S} F(\rho) e^{-i u \rho} m(d \rho)\right] X(d u, \omega)
\]
for all $S \in \mathscr{B}^{1}$ and by interchanging the order of integration we obtain
\[
Y(S, \omega)=\frac{1}{\sqrt{2 \pi}} \int_{S} F(\rho)\left[\int_{-\infty}^{\infty} e^{-i u \rho} X(d u, \omega)\right] m(d \rho)
\]
i.e.,
\[
\left[\frac{d Y}{d m}\right](\rho, \omega)=\frac{F(\rho)}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} e^{-i u \rho} X(d u, \omega)
\]

Since $F \in L_{1}(m)$ and $r_{X}$ is finite, the lemma which follows this proof applies, and (23) and (24) imply
\[
x(t, \omega)=\int_{-\infty}^{\infty} e^{i t \rho} Y(d \rho, \omega)
\]

Therefore, $x(t, \omega)$ is harmonizable.
\end{proof}

The property used in the last step of the proof of Theorem 4 will be proven now. It corresponds to the familiar property of Radon-Nikodym derivative in the scalar case and is used in later sections of this paper.

\begin{lemma}
If the second-order stochastic process $\{y(t, \omega), t \in R^{1}, \omega \in \Omega\}$ is such that
\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} |R_{y y}(t, s)| m(d t) m(d s)<\infty
\]
then
\[
Y(S, \omega)=\int_{S} y(t, \omega) m(d t), \quad S \in \mathscr{B}^{1}
\]
defines a random measure $Y$ on $(R^{1}, \mathscr{B}^{1})$ with $r_{Y}$ of bounded variation on $R^{2}$, and for all $g \in \Lambda_{2}(r_{Y})$
\[
\int_{-\infty}^{\infty} g(t) Y(d t, \omega)=\int_{-\infty}^{\infty} g(t) y(t, \omega) m(d t)
\]
all equalities being in the mean square sense.
\end{lemma}

\begin{proof}
It is clear from (25) that (26) defines a random measure $Y$ on $(R^{1}, \mathscr{B}^{1})$ with $r_{Y}$ of bounded variation on $R^{2}$.

If we put
\[
\xi(\omega)=\int_{-\infty}^{\infty} g(t) Y(d t, \omega) \quad \text{ and } \quad \eta(\omega)=\int_{-\infty}^{\infty} g(t) y(t, \omega) m(d t)
\]
it suffices to show that
\[
\mathscr{E}[|\xi-\eta|^{2}]=\mathscr{E}[|\xi|^{2}]+\mathscr{E}[|\eta|^{2}]-\mathscr{E}[\xi \eta^{*}]-\mathscr{E}[\eta \xi^{*}]=0
\]

We have
\[
\begin{aligned}
\mathscr{E}[|\xi|^{2}] &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(t) g^{*}(s) r_{Y}(d t, d s) \\
&= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(t) g^{*}(s) R_{y y}(t, s) m(d t) m(d s) \\
\mathscr{E}[|\eta|^{2}] &= \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(t) g^{*}(s) R_{y y}(t, s) m(d t) m(d s), \\
\mathscr{E}[\eta \xi^{*}] &= \int_{-\infty}^{\infty} g(t) \mathscr{E}[y(t) \xi^{*}] m(d t) \\
\mathscr{E}[y(t) \xi^{*}] &= \int_{-\infty}^{\infty} g^{*}(s) \lambda_{t}(d s)
\end{aligned}
\]
where the measure $\lambda_{t}$ on $(R^{1}, \mathscr{B}^{1})$ is defined by
\[
\lambda_{t}(S)=\mathscr{E}[y(t) Y^{*}(S)]=\int_{S} R_{y y}(t, s) m(d s)
\]
for all $S \in \mathscr{B}^{1}$. It follows by (33) and (34) that
\[
\mathscr{E}[y(t) \xi^{*}]=\int_{-\infty}^{\infty} g^{*}(s) R_{y y}(t, s) m(d s)
\]
and by (32)
\[
\mathscr{E}[\eta \xi^{*}]=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(t) g^{*}(s) R_{y y}(t, s) m(d t) m(d s)=\mathscr{E}[\xi \eta^{*}]
\]

The validity of (29) follows from (30), (31), and (36) and the proof is complete.
\end{proof}

If the moving average representation in Theorem 4 is orthogonal, then the condition of bounded variation of $r_{X}$ is equivalent to the finiteness of $Q_{X}$.

If the second-order stochastic process $x(t, \omega)$ has a moving average representation and $X$ has Radon-Nikodym derivative with respect to the Lebesgue measure the second-order stochastic process $y(t, \omega),[d Y / d m]=y$, then
\[
x(t, \omega)=\int_{-\infty}^{\infty} f(t-u) y(u, \omega) m(d u)
\]

In this case $x(t, \omega)$ can be regarded as the output of a linear time invariant system with impulse response $f$ and input the stochastic process $y(t, \omega)$. Theorem 4 then implies that if $y(t, \omega)$ is integrable over $R^{1}$ in the mean square sense, i.e., if $R_{y y}(t, s)$ is integrable over $R^{2}$, and $f, F \in L_{1}(m)$ then the output $x(t, \omega)$ is a harmonizable stochastic process. In the following section a more general result is proven which includes time varying linear systems.

\section*{5. Linear Time Varying Systems and Harmonizable Stochastic Processes}

Two kinds of linear time varying systems characterized by their impulse response $h(t, \tau)$, i.e., the response at time $t$ to a unit impulse input at time $\tau$, are considered in this section. Systems with $h$ a deterministic function and systems with $h$ a sample function of a stochastic process.

\section*{Deterministic Linear Time Varying Systems}

Consider a linear time varying system with impulse response $h(t, \tau)$. If the input process $x$ is such that
\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} h(t, u) h^{*}(t, v) R_{x x}(u, v) m(d u) m(d v)<\infty \quad \text{ for all } \quad t \in R^{1}
\]
then the output of the system is the second-order stochastic process $y$ defined by
\[
y(t, \omega)=\int_{-\infty}^{\infty} h(t, u) x(u, \omega) m(d u) \quad \text{ for all } \quad t \in R^{1}
\]

It is apparent that a sufficient condition for the output of the system to be a stochastic process of second-order for all input processes $x$ which have uniformly bounded autocorrelation functions
\[
|R_{x x}(u, v)| \leqslant M<\infty \quad \text{ for all } u, v \in R^{1}
\]
is
\[
h(t, \cdot) \in L_{1}(m) \quad \text{ for all } t \in R^{1}
\]

The wide sense stationary processes $x$ belong to this class since
\[
|R_{x x}(u, v)|=|R_{x x}(u-v)| \leqslant R_{x x}(0)<\infty \quad \text{ for all } u, v \in R^{1}
\]
and so do the harmonizable stochastic processes $x$, since
\[
|R_{x x}(u, v)| \leqslant |r_{X}|(R^{2})<\infty \quad \text{ for all } u, v \in R^{1}
\]

The following theorem provides a set of sufficient conditions which imply the harmonizability of the output of a linear time varying system.

\begin{theorem}
Let $h(t, \tau)$ be the impulse response of a linear time varying system and $x(t, \omega)$ be the input stochastic process. If $h(\cdot, \tau)$ is the Fourier transform of a function $g(\cdot, \tau) \in L_{1}(m)$ for all $\tau \in R^{1}$ and if $g$ satisfies
\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} |g(\tau, u)||g^{*}(\sigma, v)||R_{x x}(u, v)| m(d u) m(d v) m(d \tau) m(d \sigma)<\infty
\]
then the output stochastic process is harmonizable.
\end{theorem}

\begin{proof}
For all $\tau \in R^{1}$ we have
\[
h(t, \tau)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} g(s, \tau) e^{i t s} m(d s)
\]

Hence (39) implies (37) and $y(t, \omega)$ is well-defined by (38) in the stochastic mean. It follows by (39) that the random measure $Y$ defined on $(R^{1}, \mathscr{B}^{1})$ by
\[
\left[\frac{d Y}{d m}\right](\tau, \omega)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} g(\tau, u) x(u, \omega) m(d u)
\]
has $r_{Y}$ of finite variation on the entire plane $R^{2}$. For all $S_{1}, S_{2} \in \mathscr{B}^{1}$
\[
r_{Y}(S_{1} \times S_{2})=\frac{1}{2 \pi} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{S_{1}} \int_{S_{2}} g(\tau, u) g^{*}(\sigma, v) R_{x x}(u, v) m(d \tau) m(d \sigma) m(d u) m(d v)
\]

It is clear from (38), (40), (41) and the lemma that
\[
y(t, \omega)=\int_{-\infty}^{\infty} e^{i t \tau}\left[\frac{d Y}{d m}\right](\tau, \omega) m(d \tau)=\int_{-\infty}^{\infty} e^{i t \tau} Y(d \tau, \omega)
\]
in the stochastic mean sense and hence $y$ is harmonizable.
\end{proof}

A sufficient condition for (39) to be satisfied for the class of input processes with uniformly bounded autocorrelation functions is clearly
\[
g(s, \tau) \in L_{1}(m \times m)
\]

As an example, let
\[
h(t, \tau)=\frac{\alpha+\gamma|\tau|}{t^{2}+(\alpha+\gamma|\tau|)^{2}} e^{-\beta|\tau|} \quad \alpha, \beta>0, \quad \gamma \geqslant 0
\]

Then $h(t, \tau)$ is the Fourier transform of $g(s, \tau)$ :
\[
g(s, \tau)=\sqrt{\frac{\pi}{2}} e^{-\alpha|s|-\beta|\tau|-\gamma|s \tau|}
\]
and $g$ satisfies (44). The condition (39) can be written in the form
\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \frac{e^{-\beta|u|}}{\alpha+\gamma|u|} \cdot \frac{e^{-\beta|v|}}{\alpha+\gamma|v|}|R_{x x}(u, v)| m(d u) m(d v)<\infty
\]
and the output of the system with impulse response $h(t, \tau)$ to all input processes which satisfy this condition is a harmonizable stochastic process. In particular, if $x$ is harmonizable with
\[
x(t, \omega)=\int_{-\infty}^{\infty} e^{i t \lambda} X(d \lambda, \omega)
\]
then it follows by (41) that
\[
\left[\frac{d Y}{d m}\right](\tau, \omega)=(\beta+\gamma|\tau|) e^{-\alpha|\tau|} \int_{-\infty}^{\infty} \frac{X(d \lambda, \omega)}{\lambda^{2}+(\beta+\gamma|\tau|)^{2}}
\]
and the output $y$ has the harmonizable representation (43) which can also be written in the form
\[
y(t, \omega)=\int_{-\infty}^{\infty}\left[\int_{-\infty}^{\infty} \frac{\beta+\gamma|\tau|}{\lambda^{2}+(\beta+\gamma|\tau|)^{2}} e^{-\alpha|\tau|+i t \tau} m(d \tau)\right] X(d \lambda, \omega)
\]

This representation takes the following simple form in the particular case where $\gamma=0$, i.e., $h(t, \tau)=\alpha e^{-\beta|\tau|}/(\alpha^{2}+t^{2})$,
\[
y(t, \omega)=\frac{2 \beta}{\alpha^{2}+t^{2}} \int_{-\infty}^{\infty} \frac{X(d \lambda, \omega)}{\beta^{2}+\lambda^{2}}
\]

\section*{Linear Randomly Time Varying Systems}

Let the impulse response of a linear time varying system be a sample function of a stochastic process of second order $h(t, \tau, \omega)$ with autocorrelation function $R_{h h}(t, s ; \tau, \sigma)$. For all second-order input processes $x(t, \omega)$ independent of $h$ and such that
\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} R_{h h}(t, t ; u, v) R_{x x}(u, v) m(d u) m(d v)<\infty \quad \text{ for all } \quad t \in R^{1}
\]
the output of the system is the second-order stochastic process $y$ defined by
\[
y(t, \omega)=\int_{-\infty}^{\infty} h(t, u, \omega) x(u, \omega) m(d u)
\]

A sufficient condition for (45) to hold for all input processes $x$ with uniformly bounded autocorrelation functions is clearly $R_{h h}(t, t ; \cdot, \cdot) \in L_{1}(m \times m)$ for all $t \in R^{1}$.

A set of sufficient conditions for the harmonizability of the output of a linear randomly time varying system is given in the following theorem. Its proof is similar to the proof of Theorem 5 and as such it is omitted.

\begin{theorem}
If the impulse response $h(t, u, \omega)$ of a linear randomly time varying system is the Fourier transform in the stochastic mean sense of a second-order stochastic process $H(\rho, u, \omega)$, i.e.,
\[
h(t, u, \omega)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} H(\rho, u, \omega) e^{i t \rho} m(d \rho)
\]
which is such that $R_{H H}(\cdot, \cdot ; u, u) \in L_{1}(m \times m)$ for all $u \in R^{1}$ and
\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} |R_{H H}(\tau, \sigma ; u, v)||R_{x x}(u, v)| m(d \tau) m(d \sigma) m(d u) m(d v)<\infty
\]
and if the input $x$ is independent of $h$, then the output stochastic process $y(t, \omega)$ is harmonizable.
\end{theorem}

We have
\[
y(t, \omega)=\int_{-\infty}^{\infty} e^{i t \rho} Y(d \rho, \omega)=\int_{-\infty}^{\infty} e^{i t \rho}\left[\frac{d Y}{d m}\right](\rho, \omega) m(d \rho),
\]
where
\[
\left[\frac{d Y}{d m}\right](\rho, \omega)=\frac{1}{\sqrt{2 \pi}} \int_{-\infty}^{\infty} H(\rho, u, \omega) x(u, \omega) m(d u)
\]

A sufficient condition for (48) to hold for all input processes $x$ with uniformly bounded autocorrelation functions is clearly $R_{H H} \in L_{1}(m^{4})$.

\begin{thebibliography}{99}

\bibitem{campbell1969} Campbell, L. L. (1969), Series expansions for random processes, in ``Proceedings of the International Symposium on Probability and Information Theory,'' Lecture Notes in Mathematics, No. 89, pp. 77-95, Springer, New York.

\bibitem{cramer1951} Cramer, H. (1951), A contribution to the theory of stochastic processes, 2nd Berkeley Symp. Math. Stat. Probability, 329-339.

\bibitem{cramer1964} Cramer, H. (1964), Stochastic processes as curves in Hilbert space, Theor. Probability Appl. 9, 169-179.

\bibitem{doob1953} Doob, J. L. (1953), ``Stochastic Processes,'' Wiley, New York.

\bibitem{karhunen1947} Karhunen, K. (1947), Uber lineare Methoden in der Wahrscheinlichkeitsrechnung, Ann. Acad. Sci. Fenn. Ser. Al No. 37, 1-79.

\bibitem{loeve1963} Loève, M. (1963), ``Probability Theory,'' Van Nostrand, Princeton, N. J.

\bibitem{masani1968} Masani, P. (1968), Orthogonally scattered measures, Advan. Math. 2, 61-117.

\bibitem{masry1968} Masry, E., Liu, B., And Steiglitz, K. (1968), Series expansion of wide-sense stationary random processes, IEEE Trans. IT-14, 792-796.

\bibitem{parzen1967} Parzen, E. (1967), Statistical inference on time series by Hilbert space methods, in ``Time series Analysis Papers,'' Holden-Day, San Francisco, Calif.

\bibitem{piranashvili1967} Piranashyili, Z. A. (1967), On the problem of interpolation of random processes, Theor. Probability Appl. 12, 647-657.

\bibitem{rao1967} Rao, M. M. (1967), Inference in stochastic processes-III, Z. Wahrscheinlichkeitstheorie und verw. Gebiete 8, 49-72.

\bibitem{rosanov1959} Rosanov, Y. A. (1959), Spectral analysis of abstract functions, Theor. Probability Appl. 4, 271-287.

\end{thebibliography}
