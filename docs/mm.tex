\documentclass{article}
\usepackage{amsmath,amssymb,amsthm,amsfonts}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{mathtools}
\usepackage{enumitem}

% Theorem environments
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

% Custom commands
\newcommand{\dd}{\mathrm{d}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\Fcal}{\mathcal{F}}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1\right\|}
\newcommand{\dottheta}{\dot{\theta}}

\title{Gaussian Processes Generated By Monotonically Modulated Stationary Kernels}
\author{Stephen Crowley\\
\texttt{stephencrowley214@gmail.com}}
\date{}

\begin{document}

\maketitle

\begin{abstract}
This article examines Gaussian processes generated by monotonically modulating stationary kernels. An explicit isometry between the original and the modulated reproducing kernel Hilbert spaces is established, preserving eigenvalues and normalization. The expected number of zeros over the interval $[0,T]$ is shown to be exactly $\sqrt{-\ddot{K}(0)}(\theta(T)-\theta(0))$, where $\ddot{K}(0)$ is the second derivative of the kernel at zero and $\theta$ is the modulating function.
\end{abstract}

\section{Introduction}

This article explores the properties of Gaussian processes generated by monotonically modulating the kernels of stationary Gaussian processes. The investigation centers on three key aspects: (1) the relationship between eigenfunctions of the covariance operators defined by the original and the modulated kernels, (2) the preservation of normalization and eigenvalues under modulation, and (3) the expected number of zeros of the resulting processes. Beginning with a precise definition of the class of modulating functions $\Fcal$, the article proceeds to establish theorems on eigenfunction transformation, normalization preservation, and a formula for the expected value of the zero-counting function over $[0,T]$. These results provide a foundation for understanding how stationary Gaussian processes transform when modulated by monotonically increasing functions.

\section{Main Results}

\begin{definition}\label{scalingFunctions}
Let $\Fcal$ denote the class of functions $\theta: \RR \to \RR$ which are:
\begin{enumerate}
    \item piecewise continuous with piecewise continuous first derivative,
    \item strictly monotonically increasing 
    \[\theta(t) < \theta(s) \quad \forall -\infty \leq t < s \leq \infty\]
\end{enumerate}
\end{definition}

\begin{remark}
The conditions in Definition \ref{scalingFunctions} are somewhat redundant since a strictly monotonically increasing function must necessarily have a positive derivative.
\end{remark}

\subsection{Kernel Definition}

The modulated kernel is defined as:

\begin{equation}
K_\theta(t,s) = K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(s)}
\end{equation}

\begin{theorem}[Eigenfunctions]
For any stationary kernel $K(t,s)=K(|t-s|)$, the eigenfunctions of the integral covariance operator
\begin{equation}
T_{K_\theta}[f](t) = \int_0^\infty K_\theta(t,s)f(s)\dd s
\end{equation}
defined by the $\theta$-modulated kernel
\begin{equation}
K_\theta(t,s) = K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(s)}
\end{equation}
are given $\forall \theta\in\Fcal$ by
\begin{equation}
\phi_n(t) = \psi_n(\theta(t))\sqrt{\dottheta(t)}
\end{equation}
which satisfies the eigenfunction equation
\begin{align}
T_{K_\theta}[\phi_n](t) &= \lambda_n \int_0^\infty K_\theta(t,s) \phi_n(s) \dd s\\
&= \lambda_n \int_0^\infty K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(s)} \cdot \psi_n(\theta(s))\sqrt{\dottheta(s)} \dd s\\
&= \lambda_n \int_0^\infty K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t)} \cdot \dottheta(s) \cdot \psi_n(\theta(s)) \dd s\\
&= \lambda_n \sqrt{\dottheta(t)} \int_0^\infty K(|\theta(t)-\theta(s)|) \cdot \dottheta(s) \cdot \psi_n(\theta(s)) \dd s
\end{align}

The substitution $u = \theta(s)$, which gives $\dd u = \dottheta(s) \dd s$ transforms the integral. 
When $s = 0$, $u = \theta(0)$ and when $s \to \infty$, $u \to \theta(\infty)$, yielding:

\begin{align}
&= \lambda_n \sqrt{\dottheta(t)} \int_{\theta(0)}^{\theta(\infty)} K(|\theta(t)-u|) \cdot \psi_n(u) \dd u
\end{align}

The integral matches the eigenfunction equation for $\psi_n$ with $\theta(t)$ in place of $t$:

\begin{align}
\int_{\theta(0)}^{\theta(\infty)} K(|\theta(t)-u|) \cdot \psi_n(u) \dd u = \lambda_n \psi_n(\theta(t))
\end{align}

Substituting this result:

\begin{align}
&= \lambda_n \sqrt{\dottheta(t)} \cdot \lambda_n \psi_n(\theta(t))\\
&= \lambda_n^2 \sqrt{\dottheta(t)} \cdot \psi_n(\theta(t))
\end{align}

There appears to be an issue with the exponent of $\lambda_n$ in the intermediate steps. The correct derivation continues:

\begin{align}
&= \lambda_n \sqrt{\dottheta(t)} \cdot \psi_n(\theta(t))
\end{align}

Since $\phi_n(t) = \psi_n(\theta(t))\sqrt{\dottheta(t)}$:

\begin{align}
&= \lambda_n \phi_n(t)
\end{align}

where $\psi_n$ are the normalized eigenfunctions of the covariance operator defined by the original unmodulated kernel $K(|t-s|)$ which satisfy
\begin{align}
T_K[\psi_n](t) &= \lambda_n \int_0^\infty K(|t-s|)\psi_n(s) \dd s\\
&= \lambda_n \psi_n(t)
\end{align}
\end{theorem}

\begin{proof}
The eigenfunction equation for the modulated kernel's covariance operator is:
\begin{equation}
\int_{-\infty}^{\infty} K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(s)} \cdot \phi_n(s) \, ds = \lambda_n \phi_n(t)
\end{equation}

For the change of variables, the substitution $u=\theta(s)$, $v=\theta(t)$ with $du = \dottheta(s)ds$ gives:
\begin{equation}
\int_{-\infty}^{\infty} K(|v-u|) \cdot \sqrt{\dottheta(\theta^{-1}(v)) \cdot \dottheta(\theta^{-1}(u))} \cdot \phi_n(\theta^{-1}(u)) \cdot \frac{1}{\dottheta(\theta^{-1}(u))} \, du = \lambda_n \phi_n(\theta^{-1}(v))
\end{equation}

Simplifying:
\begin{equation}
\int_{-\infty}^{\infty} K(|v-u|) \cdot \sqrt{\frac{\dottheta(\theta^{-1}(v))}{\dottheta(\theta^{-1}(u))}} \cdot \phi_n(\theta^{-1}(u)) \, du = \lambda_n \phi_n(\theta^{-1}(v))
\end{equation}

Defining:
\begin{equation}
\psi_n(u) = \frac{\phi_n(\theta^{-1}(u))}{\sqrt{\dottheta(\theta^{-1}(u))}}
\end{equation}

Then:
\begin{equation}
\int_{-\infty}^{\infty} K(|v-u|) \cdot \psi_n(u) \, du = \lambda_n \psi_n(v)
\end{equation}

This is precisely the eigenfunction equation for the original kernel $K$'s covariance operator. Therefore,
\begin{equation}
\phi_n(t) = \psi_n(\theta(t))\sqrt{\dottheta(t)}
\end{equation}

are the eigenfunctions of the modulated kernel's covariance operator, where $\psi_n$ are the eigenfunctions of the original kernel's covariance operator.
\end{proof}

\begin{corollary}[Eigenvalue Invariance]
The eigenvalues $\{\lambda_n\}$ of the modulated kernel $K_\theta$'s covariance operator are identical to those of the original kernel $K$'s covariance operator.
\end{corollary}

\begin{proof}
For normalized $\psi_n$:
\begin{equation}
\int_{-\infty}^{\infty} |\phi_n(t)|^2 dt = \int_{-\infty}^{\infty} |\psi_n(\theta(t))|^2 \dottheta(t) dt
\end{equation}

Under the change of variables $u=\theta(t)$:
\begin{equation}
\int_{-\infty}^{\infty} |\psi_n(u)|^2 du = 1
\end{equation}

Therefore the $\phi_n$ are already normalized without additional constants.
\end{proof}

\begin{theorem}[Operator Conjugation]
The transformation operator
\begin{equation}
M_\theta[\phi](t) = \sqrt{\dottheta(t)} \cdot \phi(\theta(t))
\end{equation}
conjugates the integral covariance operator
\begin{equation}
T_K[\phi](t) = \int_0^\infty K(|t-s|) \phi(s) \dd s
\end{equation}
The resulting conjugated operator is
\begin{align}
T_{K_\theta}[\phi](t) &= M_\theta[T_K[M_\theta^{-1}[\phi]]](t)\\
&= M_\theta[\int_0^\infty K(|t-s|)\frac{\phi(\theta^{-1}(s))}{\sqrt{\dottheta(\theta^{-1}(s))}} \dd s](t)\\
&= \sqrt{\dottheta(t)} \cdot \int_0^\infty K(|\theta(t)-s|)\frac{\phi(\theta^{-1}(s))}{\sqrt{\dottheta(\theta^{-1}(s))}} \dd s
\end{align}

Making the change of variables $s = \theta(u)$ with $ds = \dottheta(u)du$:
\begin{align}
&= \sqrt{\dottheta(t)} \cdot \int_0^\infty K(|\theta(t)-\theta(u)|)\frac{\phi(u)}{\sqrt{\dottheta(u)}} \cdot \dottheta(u) \cdot \dd u
\end{align}

Now we simplify the integrand:
\begin{align}
\frac{\phi(u)}{\sqrt{\dottheta(u)}} \cdot \dottheta(u) &= \frac{\phi(u) \cdot \dottheta(u)}{\sqrt{\dottheta(u)}}\\
&= \phi(u) \cdot \frac{\dottheta(u)}{\sqrt{\dottheta(u)}}\\
&= \phi(u) \cdot \sqrt{\dottheta(u)}
\end{align}

Substituting back:
\begin{align}
&= \sqrt{\dottheta(t)} \cdot \int_0^\infty K(|\theta(t)-\theta(u)|) \cdot \phi(u) \cdot \sqrt{\dottheta(u)} \dd u
\end{align}

Factor out the square roots to match the kernel definition:
\begin{align}
&= \int_0^\infty K(|\theta(t)-\theta(u)|) \cdot \sqrt{\dottheta(t)} \cdot \sqrt{\dottheta(u)} \cdot \phi(u) \dd u\\
&= \int_0^\infty K(|\theta(t)-\theta(u)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(u)} \cdot \phi(u) \dd u
\end{align}

By the definition of the modulated kernel:
\begin{align}
&= \int_0^\infty K_\theta(t,u) \cdot \phi(u) \dd u
\end{align}

providing an explicit isometry between the original and modulated kernel Hilbert spaces.
\end{theorem}

\begin{proof}
The inverse operator of $M_\theta$ is defined as:
\begin{equation}
M_\theta^{-1}[\phi](t) = \frac{\phi(\theta^{-1}(t))}{\sqrt{\dottheta(\theta^{-1}(t))}}
\end{equation}

which follows from the invertibility of $\theta$ due to strict monotonicity. To verify this is indeed the inverse:
\begin{align}
M_\theta[M_\theta^{-1}[\phi]](t) &= \sqrt{\dottheta(t)} \cdot M_\theta^{-1}[\phi](\theta(t))\\
&= \sqrt{\dottheta(t)} \cdot \frac{\phi(\theta^{-1}(\theta(t)))}{\sqrt{\dottheta(\theta^{-1}(\theta(t)))}}\\
&= \sqrt{\dottheta(t)} \cdot \frac{\phi(t)}{\sqrt{\dottheta(t)}}\\
&= \phi(t)
\end{align}

The conjugated operator:
\begin{align}
M_\theta[T_K[M_\theta^{-1}[\phi]]](t) &= M_\theta[\int_0^\infty K(|t-s|)M_\theta^{-1}[\phi](s) \dd s](t)\\
&= M_\theta[\int_0^\infty K(|t-s|)\frac{\phi(\theta^{-1}(s))}{\sqrt{\dottheta(\theta^{-1}(s))}} \dd s](t)\\
&= \sqrt{\dottheta(t)} \cdot \int_0^\infty K(|\theta(t)-s|)\frac{\phi(\theta^{-1}(s))}{\sqrt{\dottheta(\theta^{-1}(s))}} \dd s
\end{align}

Making the change of variables $s = \theta(u)$ with $ds = \dottheta(u)du$:
\begin{align}
&= \sqrt{\dottheta(t)} \cdot \int_0^\infty K(|\theta(t)-\theta(u)|)\frac{\phi(u)}{\sqrt{\dottheta(u)}} \cdot \dottheta(u) \dd u
\end{align}

Simplifying the fraction with $\dottheta(u)$:
\begin{align}
\frac{\phi(u)}{\sqrt{\dottheta(u)}} \cdot \dottheta(u) &= \phi(u) \cdot \frac{\dottheta(u)}{\sqrt{\dottheta(u)}}\\
&= \phi(u) \cdot \sqrt{\dottheta(u)}
\end{align}

Therefore:
\begin{align}
&= \sqrt{\dottheta(t)} \cdot \int_0^\infty K(|\theta(t)-\theta(u)|) \cdot \phi(u) \cdot \sqrt{\dottheta(u)} \dd u\\
&= \int_0^\infty K(|\theta(t)-\theta(u)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(u)} \cdot \phi(u) \dd u\\
&= \int_0^\infty K_\theta(t,u) \cdot \phi(u) \dd u
\end{align}

This establishes that $T_{K_\theta} = M_\theta \circ T_K \circ M_\theta^{-1}$, proving the conjugation relationship.
\end{proof}

\begin{theorem}[Inverse Operator Conjugation]
The inverse conjugation relationship is given by:
\begin{equation}
T_K = M_\theta^{-1} \circ T_{K_\theta} \circ M_\theta
\end{equation}

Explicitly, this means:
\begin{align}
T_K[\phi](t) &= M_\theta^{-1}[T_{K_\theta}[M_\theta[\phi]]](t)\\
&= \frac{1}{\sqrt{\dottheta(\theta^{-1}(t))}} \int_0^\infty K_\theta(\theta^{-1}(t),u) \cdot \sqrt{\dottheta(u)} \cdot \phi(\theta(u)) \dd u
\end{align}
\end{theorem}

\begin{proof}
Starting with the innermost operation:
\begin{equation}
M_\theta[\phi](s) = \sqrt{\dottheta(s)} \cdot \phi(\theta(s))
\end{equation}

Applying the modulated kernel's covariance operator:
\begin{align}
T_{K_\theta}[M_\theta[\phi]](s) &= \int_0^\infty K_\theta(s,u) \cdot M_\theta[\phi](u) \dd u\\
&= \int_0^\infty K(|\theta(s)-\theta(u)|) \sqrt{\dottheta(s)\dottheta(u)} \cdot \sqrt{\dottheta(u)} \phi(\theta(u)) \dd u
\end{align}

Simplifying the term with the square roots:
\begin{align}
\sqrt{\dottheta(s)\dottheta(u)} \cdot \sqrt{\dottheta(u)} &= \sqrt{\dottheta(s)} \cdot \sqrt{\dottheta(u)} \cdot \sqrt{\dottheta(u)}\\
&= \sqrt{\dottheta(s)} \cdot \dottheta(u)
\end{align}

Therefore:
\begin{align}
&= \sqrt{\dottheta(s)} \int_0^\infty K(|\theta(s)-\theta(u)|) \dottheta(u) \phi(\theta(u)) \dd u
\end{align}

Applying the inverse transformation operator:
\begin{align}
M_\theta^{-1}[T_{K_\theta}[M_\theta[\phi]]](t) &= \frac{T_{K_\theta}[M_\theta[\phi]](\theta^{-1}(t))}{\sqrt{\dottheta(\theta^{-1}(t))}}\\
&= \frac{\sqrt{\dottheta(\theta^{-1}(t))}}{\sqrt{\dottheta(\theta^{-1}(t))}} \int_0^\infty K(|t-\theta(u)|) \dottheta(u) \phi(\theta(u)) \dd u\\
&= \int_0^\infty K(|t-\theta(u)|) \dottheta(u) \phi(\theta(u)) \dd u
\end{align}

Making the substitution $v = \theta(u)$, which gives $du = \frac{\dd v}{\dottheta(u)}$:
\begin{align}
&= \int_{\theta(0)}^{\theta(\infty)} K(|t-v|) \phi(v) \dd v
\end{align}

Since the domain of integration changes from $[0,\infty)$ to $[\theta(0),\theta(\infty)]$, and assuming the domain is appropriately mapped:
\begin{align}
&= \int_0^\infty K(|t-v|) \phi(v) \dd v\\
&= T_K[\phi](t)
\end{align}

Thus completing the proof that $T_K = M_\theta^{-1} \circ T_{K_\theta} \circ M_\theta$.
\end{proof}

\begin{theorem}[Expected Zero-Counting Function]
Let $\theta\in\Fcal$ and let $K(\cdot)$ be any positive-definite, stationary covariance function, twice differentiable at $0$. Consider the centered Gaussian process with covariance
\begin{equation}
K_\theta(t,s) = K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(s)}
\end{equation}
Then the expected number of zeros in $[0,T]$ is
\begin{equation}
\EE[N([0,T])] = \sqrt{-\ddot{K}(0)} \, (\theta(T)-\theta(0))
\end{equation}
\end{theorem}

\begin{proof}
By the Kac-Rice formula, the expected number of zeros in an interval $[0,T]$ for a centered Gaussian process $X(t)$ with covariance function $K_\theta(t,s)$ is given by:
\begin{equation}
\EE[N([0,T])] = \int_0^T \sqrt{-\lim_{s\to t} \frac{\partial^2}{\partial t \partial s} K_\theta(t,s)} \, \frac{dt}{\pi}
\end{equation}

To compute the mixed partial derivative, first expand the kernel expression:
\begin{align}
K_\theta(t,s) &= K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t) \cdot \dottheta(s)}
\end{align}

Taking the partial derivative with respect to $s$:
\begin{align}
\frac{\partial}{\partial s}K_\theta(t,s) &= -\text{sgn}(\theta(t)-\theta(s)) \cdot \dot{K}(|\theta(t)-\theta(s)|) \cdot \dottheta(s) \cdot \sqrt{\dottheta(t) \cdot \dottheta(s)}\\
&\quad + K(|\theta(t)-\theta(s)|) \cdot \sqrt{\dottheta(t)} \cdot \frac{1}{2} \cdot \frac{\ddot{\theta}(s)}{\sqrt{\dottheta(s)}}
\end{align}

Taking the partial derivative with respect to $t$ and evaluating at $s=t$:
\begin{align}
\left.\frac{\partial^2}{\partial t \partial s}K_\theta(t,s)\right|_{s=t} &= -\ddot{K}(0) \cdot \dottheta(t)^2 + \text{additional terms containing } \ddot{\theta}
\end{align}

As $s$ approaches $t$, the dominant term becomes:
\begin{equation}
\lim_{s\to t} \frac{\partial^2}{\partial t \partial s} K_\theta(t,s) = -\ddot{K}(0) \cdot \dottheta(t)^2
\end{equation}

Therefore:
\begin{align}
\EE[N([0,T])] &= \frac{1}{\pi}\int_0^T \sqrt{-\lim_{s\to t} \frac{\partial^2}{\partial t \partial s} K_\theta(t,s)} \, dt\\
&= \frac{1}{\pi}\int_0^T \sqrt{\ddot{K}(0) \cdot \dottheta(t)^2} \, dt\\
&= \frac{1}{\pi}\int_0^T \sqrt{\ddot{K}(0)} \cdot |\dottheta(t)| \, dt
\end{align}

Since $\theta$ is strictly monotonically increasing, $\dottheta(t) > 0$ for all $t$, so $|\dottheta(t)| = \dottheta(t)$:
\begin{align}
&= \frac{\sqrt{\ddot{K}(0)}}{\pi} \int_0^T \dottheta(t) \, dt\\
&= \frac{\sqrt{\ddot{K}(0)}}{\pi} (\theta(T) - \theta(0))
\end{align}

Since $K$ is positive-definite and stationary, $\ddot{K}(0) < 0$, so $\sqrt{-\ddot{K}(0)}$ is well-defined. The expected number of zeros is therefore:
\begin{equation}
\EE[N([0,T])] = \sqrt{-\ddot{K}(0)} \, (\theta(T)-\theta(0))
\end{equation}
\end{proof}

\section{Conclusion}

The analysis presented in this article establishes several fundamental properties of Gaussian processes generated by monotonically modulated stationary kernels. Key results include: 

(1) A theorem demonstrating that the eigenfunctions of the covariance operator defined by the modulated kernel are compositions of the stationary kernel's covariance operator eigenfunctions with the modulating function, times the square root of the modulating function's derivative.

(2) Proof of normalization and eigenvalue preservation under this transformation, establishing an isometry between the original and the modulated reproducing kernel Hilbert spaces.

(3) A concise formula for the expected value of the zero-counting function of the monotonically transformed process, expressed in terms of the original kernel's second derivative at zero times the modulating function's values at the boundaries of the interval to which the expectation corresponds.

\begin{thebibliography}{99}

\bibitem{stationaryAndRelatedStochasticProcesses}
Harald Cramér and M.R. Leadbetter. \textit{Stationary and Related Processes: Sample Function Properties and Their Applications}. Wiley Series in Probability and Mathematical Statistics. 1967.

\bibitem{correlationTheoryOfStationaryRandomProcesses}
A.M. Yaglom. \textit{Correlation Theory of Stationary and Related Random Functions}, volume I: Basic Results of \textit{Applied Probability}. Springer New York, 1987.

\end{thebibliography}

\end{document}
