\documentclass[12pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{geometry}
\geometry{margin=1in}

\title{Spectral characteristics of nonstationary random processes - a critical review}
\author{
G.~Michaelov$^{a}$, S.~Sarkani$^{a,*}$, L.D.~Lutes$^{b}$\\[1ex]
$^{a}$School of Engineering and Applied Science, The George Washington University, Washington, DC, 20052, USA\\
$^{b}$Department of Civil Engineering, Texas A\&M University, College Station, TX 77098, USA
}
\date{}

\begin{document}

\maketitle

\begin{abstract}
This article analyzes the approaches to defining "spectral characteristics" derived from the spectral functions of nonstationary random processes. The processes considered are those for which an evolutionary power spectrum as designated by Priestley can be defined. Two basic approaches to defining spectral characteristics are reviewed. The first, characterized as geometric, leads to Vanmarke's spectral moments, which have proven to be very useful characteristics for stationary processes. However, these moments may be infinite for nonstationary processes, which creates problems for applications. The second approach, viewed as nongcometric, is based on Di Paola's pre-envelope covariances. The advantages and deficiencies of both approaches are discussed. It is also shown that the nongeometric spectral characteristics can be directly defined from the frequency domain as integrals of the one-sided auto- and crossspectra of the evolutionary process and its derivatives. These nongeometric spectral characteristics are then used in defining parameters that characterize the central frequency and the bandwidth of evolutionary processes. To this end, the probability distributions of the process envelope are analyzed. It is demonstrated that suitable central frequencies and bandwidth factors can be defined from the probability density functions of the derivatives of the envelope and the phase. Â© 1999 Elsevier Science Ltd. All rights reserved.
\end{abstract}

\section*{1. Introduction}

The probabilistic analysis of structural and mechanical vibrations deals with the description and characterization of structural loadings and response that are modeled as random processes. This characterization is not simple due to the complex mathematical structure of the response%
\footnotetext{
* Corresponding author. Tel.: +1-202-994-5450; fax:+1-202-994-0092.

E-mail address: sarkani@seas.gwu.edu (S. Sarkani)
}
random process, which evolves both in probability distribution space and in time. From a strict probabilistic viewpoint, the complete description of a random process requires that joint probability density functions (PDFs) be specified over any given set of points in the time domain. Because such an approach is difficult to use in applications, random vibration analysis is quite often performed in the frequency domain. In this technique, spectral density functions - representing the distribution of power or energy over frequency - are most commonly used as random process descriptors. The most renowned among these descriptors is the power spectral density (PSD) of stationary processes. The relative ease with which PSDs of related processes can be computed, such as in obtaining the PSD of a derivative process or in determining the PSD of the response from the PSD of the loading, is not the only factor determining the popularity of the frequency-domain approach. A number of parameters derived from PSDs are also employed in the probabilistic assessment of structural failure - for example, to compute barrier crossing rates, or the distribution of peaks and extreme values.

The parameters in question are, generally, the spectral moments - the moments of the onesided PSD with respect to the frequency origin. Since they were first introduced by Vanmarke~\cite{Vanmarke1972} the spectral moments have been perceived primarily as geometric characteristics of the PSD. Other frequency-domain parameters such as "central frequency" and "bandwidth factor" are also usually defined as geometric characteristics.

Application of spectral methods, and spectral moments in particular, to nonstationary random processes, however, is more complicated than for stationary processes. One such difficulty is the definition of an appropriate power or energy spectrum. Unlike a stationary process, for which the PSD is the only such spectrum that makes physical sense, a nonstationary process allows various possibilities and approaches. Among the several nonstationary spectra defined are the energy spectrum, the double-frequency spectrum, the Weigner spectrum, and Priestley's evolutionary power spectrum. For a discussion of the advantages and disadvantages of the different nonstationary spectrum definitions the reader is referred to Bendat and Piersol~\cite{BendatPiersol1986}, Priestley~\cite{Priestley1988}, and Michaelov~\cite{Michaelov1997}. This paper will consider only evolutionary processes - those nonstationary processes for which an evolutionary power spectral density (EPSD) function can be defined - since these seem to be most important for applications of nonstationary stochastic models.

There is no theoretical obstacle to applying the geometric definition of spectral characteristics to evolutionary processes. The moments are simply taken along the frequency coordinate of the EPSD, which is a two-parameter function of time and frequency. These transient spectral moments, however, have been proven to possess significant difficulties in some applications. Such difficulties were first reported by Corotis et al.~\cite{Corotis1972}, for the case of the transient response of a single-degree-of-freedom system (simple oscillator) to stationary Gaussian white noise. It was found that only the zero-order spectral moment exists. In particular, the integrals for the first and the second spectral moments were found to be unbounded. At the same time, all three of these spectral moments of the stationary response of the system - the process reached in the limit as time approaches infinity - are finite. For the particular case considered, Corotis et al.~\cite{Corotis1972} were able to avoid this difficulty by splitting the integrals of the spectral moments into convergent and nonconvergent parts and ignoring the nonconvergent parts altogether. Such an operation, however, is difficult enough even for the EPSD of the transient response to stationary white noise, which is undoubtedly the simplest nonstationary case of the response of simple oscillator. It is hardly possible to perform when the response is a result of a general evolutionary excitation.

Probably the first to question the usefulness of the spectral moments for nonstationary processes was Di Paola~\cite{DiPaola1985}. Di Paola's approach to defining nonstationary spectral characteristics derives from the introduction of a new complex-valued random process. The real part of this "pre-envelope" process is equal to the original nonstationary process, while the imaginary part is an auxiliary random process related to the real part. Di Paola defined all spectral characteristics as the auto- and cross-covariances of the pre-envelope process and its derivatives. As a result, all spectral characteristics up to the order corresponding to the highest derivative with finite variance become finite. Di Paola~\cite{DiPaola1985} further demonstrated that when the process becomes stationary the resulting spectral characteristics are reduced to the well-known spectral moments. Unfortunately, his work has remained largely unused. In many recent publications, such as the random vibration texts of Nigam and Narayanan~\cite{NigamNarayanan1994} and Soong and Grigoriu~\cite{SoongGrigoriu1993} the only nonstationary spectral characteristics considered are the moments of the evolutionary spectrum.

In this article, the problem of defining the spectral characteristics of an evolutionary process is analyzed again. Here, the concepts of "spectral moments" and "pre-envelope covariances" are presented, and the advantages and disadvantages of one definition over the other are examined. It will be demonstrated that Di Paola's spectral characteristics~\cite{DiPaola1985} can be introduced directly from the frequency domain, without resorting to the pre-envelope process. The time-domain interpretation of these spectral characteristics as covariances of the various derivatives of the preenvelope process is shown to be important because it allows investigation of bandwidth properties of evolutionary processes from a new perspective. This investigation is pursued by analyzing the probability distribution of the envelope and phase of an evolutionary process. Based on the probability distributions of the derivative processes of the envelope and the phase, the bandwidth properties of the evolutionary process are quantified and the appropriate definitions of the "central frequency" and "bandwidth factor" for evolutionary processes are given.

For simplicity all processes considered in this study are taken to be zero-mean.

\section*{2. Nonstationary processes with evolutionary power spectral density}

A real-valued evolutionary process $X(t)$, as defined by Priestley~\cite{Priestley1965}, can be expressed in the general form of a Fourier-Stieltjes integral as
\begin{equation}
X(t)=\int_{-\infty}^{\infty} A(t, \omega) \exp (i \omega t) \mathrm{d} Z(\omega)
\label{eq:1}
\end{equation}
in which $A(t, \omega)$ is a complex-valued deterministic amplitude modulating function and $Z(\omega)$ is a complex-valued random function, such that an "embedded" stationary process $X_{s}(t)$ exists whose spectral decomposition is
\begin{equation}
X_{S}(t)=\int_{-\infty}^{\infty} \exp (i \omega t) \mathrm{d} Z(\omega)
\label{eq:2}
\end{equation}
For the process $X(t)$ to be real, the complex modulating function must be such that $A(t,-\omega)=A^{*}(t, \omega)$, where * denotes complex-conjugate. Comparing Eq.~\eqref{eq:2} to the Fourier transform integral suggests an interpretation of $\mathrm{d} Z(\omega)=\hat{X}_{S}(\omega) \mathrm{d} \omega$ in which $\hat{X}_{S}(\omega)$ is the Fourier transform of $X_{S}(t)$, but caution must be used since a stationary process does not have a Fourier transform in a mean-square sense. Of course, the Fouricr transform relationship which does exist for a stationary process is the one between the autocovariance function and the power spectral density (PSD), and this relationship holds for Eq.~\eqref{eq:2} if
\begin{equation}
E\left[\mathrm{~d} Z\left(\omega_{1}\right) \mathrm{d} Z\left(\omega_{2}\right)\right]=S_{X X}\left(\omega_{1}\right) \delta\left(\omega_{1}+\omega_{2}\right) \mathrm{d} \omega_{1} \mathrm{~d} \omega_{2}
\label{eq:3}
\end{equation}
in which $S_{X X}(\omega)$ denotes the PSD of the stationary $X_{S}(t)$ and $\delta(\cdot)$ is Dirac's delta-function.

Eq.~\eqref{eq:1} is a frequency-domain statement that an evolutionary process results when some stationary process $X_{S}(t)$ passes through a time-variant deterministic filter with gain $A(t, \omega)$. If $A(t, \omega)$ is slowly varying in time in comparison to the oscillations of $X_{S}(t)$, which is usually the case of practical interest, the spectral decomposition in Eq.~\eqref{eq:1} represents an instantaneous frequency decomposition of the process~\cite{Priestley1965}. There is no problem defining the evolutionary process even if the "slowly varying" condition is violated, but then the evolutionary spectral density would not give the frequency decomposition of the process, since it ignores the frequency content of $A(t, \omega)$. Eq.~\eqref{eq:1} can also be expressed in the time domain through a convolution integral if the Fourier transform of $A(t, \omega) \exp (i \omega t)$ along its $\omega$ coordinate exists. In particular if
\begin{equation}
a(t, \tau)=\frac{1}{2 \pi} \int_{-\infty}^{\infty} A(t, \omega) \exp [i \omega(t-\tau)] \mathrm{d} \omega, \quad A(t, \omega) \exp (i \omega t)=\int_{-\infty}^{\infty} a(t, \tau) \exp (i \omega \tau) \mathrm{d} \tau
\label{eq:4}
\end{equation}
then the resulting expression for $X_{S}(t)$ becomes
\begin{equation}
X(t)=\int_{-\infty}^{\infty} a(t, \tau) X_{S}(\tau) \mathrm{d} \tau
\label{eq:5}
\end{equation}

This expression is rarely used in practice, though, because Eq.~\eqref{eq:1} is more convenient in derivations. The evolutionary power spectral density (EPSD) of $X(t)$ is defined as
\begin{equation}
G_{X X}(t, \omega)=|A(t, \omega)|^{2} S_{X X}(\omega)
\label{eq:6}
\end{equation}

At any given instant of time, the EPSD represents the spectral distribution of the instantaneous power of the process. Similarly, for a fixed frequency, the EPSD represents the time variation of the spectral amplitude associated with this frequency.

For two processes, $X(t)$ and $Y(t)$, that can be written in the form of Eq.~\eqref{eq:1}, an evolutionary cross-spectrum can be defined as
\begin{equation}
G_{X Y}(t, \omega)=A_{X}^{*}(t, \omega) A_{Y}(t, \omega) S_{X Y}(\omega)
\label{eq:7}
\end{equation}
where $A_{X}(t, \omega)$ and $A_{Y}(t, \omega)$ are the modulating functions of the two processes, $S_{X Y}(\omega)$ is the stationary cross-spectrum of the embedded stationary processes $X_{S}(t)$ and $Y_{S}(t)$. Like a stationary PSD, the integral of $G_{X X}(t, \omega)$ over the entire frequency range renders the transient variance of the process, $\sigma_{X}^{2}(t)$ and the integral of $G_{X Y}(t, \omega)$ gives the cross-covariance of the two evolutionary processes, $K_{X Y}(t, t)$.

It should be understood that EPSD does not apply to all nonstationary processes but only to those that allow representation in the form of Eq.~\eqref{eq:1}. Thus, the developments presented hereafter are strictly applicable to this nonstationary class only. Although this category of evolutionary processes is somewhat limiting, it contains a number of classes of nonstationary processes important in application. These include the modulated stationary processes, filtered modulated white noise, and modulated filtered white noise~\cite{NigamNarayanan1994}. Part of the interest these evolutionary processes hold for application is due exactly to the limitation of their definition. The reason for this is that for practical purposes a random loading must be evaluated from a limited number of recorded observations. Expectations can be computed from a single realization only for the ergodic processes, which by definition are stationary. In order to delegate ergodic properties to a nonstationary process, one must assume that the nonstationary behavior is due to some kind of deterministic departure from otherwise "perfect" stationarity. Such an assumption is incorporated into Eqs.~\eqref{eq:1} and~\eqref{eq:5}, which represent a superposition of two time variations: the first one deterministic, and the second one stochastic but stationary.

Of particular interest are not only the statistical properties of the evolutionary $X(t)$ but also the properties of its first derivative. By differentiating Eq.~\eqref{eq:1}, the latter can also be expressed in an evolutionary form as
\begin{equation}
\dot{X}(t)=\int_{-\infty}^{\infty} A_{1}(t, \omega) \exp (i \omega t) \mathrm{d} Z(\omega)
\label{eq:9}
\end{equation}
where
\begin{equation}
A_{1}(t, \omega)=\dot{A}(t, \omega)+(i \omega) A(t, \omega)
\label{eq:10}
\end{equation}
is its modulating function. Accordingly, the autospectrum of $\dot{X}(t)$ becomes
\begin{equation}
G_{\dot{X} \dot{X}}(t, \omega)=\left|A_{1}(t, \omega)\right|^{2} S_{X X}(\omega)
\label{eq:11}
\end{equation}
and an evolutionary cross-spectrum of $X(t)$ and $\dot{X}(t)$ can be found from Eq.~\eqref{eq:7} as
\begin{equation}
G_{X \dot{X}}(t, \omega)=G_{\dot{X} X}^{*}(t, \omega)=A^{*}(t, \omega) A_{\mathrm{I}}(t, \omega) S_{X X}(\omega)
\label{eq:12}
\end{equation}

\section*{3. Spectral moments of stationary and evolutionary processes}

The power spectral density $S_{X X}(\omega)$ of a stationary process $X_{S}(t)$ is an even function of $\omega$, which allows the so-called "one-sided" PSD to be defined as $2 S_{X X}(\omega)$ for positive (physical) frequencies only. The $n$th spectral moment is defined as the $n$th moment of this one-sided PSD, with respect to the frequency origin:
\begin{equation}
\lambda_{n}=2 \int_{0}^{\infty} \omega^{n} S_{X X}(\omega) \mathrm{d} \omega=\int_{-\infty}^{\infty}|\omega|^{n} S_{X X}(\omega) \mathrm{d} \omega
\label{eq:13}
\end{equation}

Vanmarke~\cite{Vanmarke1972}, who frist introduced Eq.~\eqref{eq:13}, suggested that the moments of the PSD should be used as frequency-domain (spectral) characteristics of a random process in exactly the same way that the moments of the PDF - the expectations - are used as time-domain characteristics of a random process.

In addition to this purely geometric argument, there are at least two important reasons why the stationary spectral moments have gained popularity in stochastic analysis of vibration. The first is that each moment of order $2 j$ is equal to the variance of the $j$ th derivative of the process; that is,
\begin{equation}
\sigma_{X^{(j)}}^{2}=\lambda_{2 j}=2 \int_{0}^{\infty} \omega^{2 j} S_{X X}(\omega) \mathrm{d} \omega
\label{eq:14}
\end{equation}
in which $X^{(j)}$ denotes the $j$ th derivative of $X(t)$. The advantage of Eq.~\eqref{eq:14} is that the variance of a derivative can be computed by integration in the frequency domain. This operation can even be carried out numerically, and for many applications it is much simpler than the alternative of differentiating a process's covariance in the time domain.

The second important property of the spectral moments is that they can be used to define measures of the shape of the PSD in much the same way that moments are used in other engineering applications (for example, to characterize a beam's cross-section). The PSD shape measurement is deemed necessary because shape may be a good indicator of the oscillatory behavior of a process's time histories - including the two distinctive cases known as narrowband and broadband. The two parameters most commonly defined are a "central frequency" and a "bandwidth factor."

The geometric arguments view the central frequency as the abscissa of the "mass" center of the one-sided PSD. Accordingly, a central frequency, $\omega_{c}$, is expressed in terms of the first and zeroorder spectral moments as
\begin{equation}
\omega_{c}=\frac{\lambda_{1}}{\lambda_{0}}
\label{eq:15}
\end{equation}

In a complete PSD-PDF analogy, for which the one-sided PSD is normalized by $\lambda_{0}$ so that the area under its curve is unity, $\omega_{c}$ corresponds to the expected value obtained from the PDF.

Similarly, a process's bandwidth can be quantified in terms of the PSD-PDF analogy for standard deviation. For comparative purposes, however, a dimensionless parameter is more useful and such a parameter can be found in the PSD analogy to the coefficient of variation. This is equal to
\begin{equation}
s=\frac{\sqrt{\lambda_{2} / \lambda_{0}-\omega_{c}^{2}}}{\omega_{c}}=\sqrt{\frac{\lambda_{0} \lambda_{2}}{\lambda_{1}^{2}}-1}
\label{eq:16}
\end{equation}

In geometric terms this is the "radius of gyration" of the spectral mass around its geometric center normalized by $\omega_{c}$. This parameter, however, has the inconvenience of taking on very large values for very broadband cases; therefore, the most commonly used bandwidth factor is defined as
\begin{equation}
q=\frac{s}{\sqrt{s^{2}+1}}=\sqrt{1-\frac{\lambda_{1}^{2}}{\lambda_{0} \lambda_{2}}}
\label{eq:17}
\end{equation}
which is always between zero and unity, as is evident from the Schwartz inequality. The parameter $q$ defined in Eq.~\eqref{eq:17} tends to be low (closer to zero) for narrowband processes and high (close to unity) for broadband processes.

It is a straightforward matter to extend the spectral moment definitions [Eq.~\eqref{eq:13}] to evolutionary processes since the EPSD, like the PSD of a stationary process, is a real-valued, even function of $\omega$. Accordingly, the transient spectral moments of an evolutionary process $X(t)$ are defined as the moments of its one-sided EPSD, i.e.
\begin{equation}
\lambda_{n}(t)=\int_{-\infty}^{\infty}|\omega|^{n} G_{X X}(t, \omega) \mathrm{d} \omega=2 \int_{0}^{\infty} \omega^{n} G_{X X}(t, \omega) \mathrm{d} \omega
\label{eq:18}
\end{equation}

The first property of stationary spectral moments - the equivalence of the even moments to the variance of the process and its derivatives - does not hold completely. Only the first spectral moment is equal to the variance of the process; all the other moments of even order are different from the variances of the process derivatives, i.e.
\begin{equation}
\sigma_{X}^{2}(t)=\lambda_{0}(t) \quad \sigma_{X^{(j)}}^{2}(t) \neq \lambda_{2 j}(t) \quad \text { for } j>0
\label{eq:19}
\end{equation}

The differences can be most easily seen for the variance of $\dot{X}(t)$ when the expression for its EPSD is considered. Using Eqs.~\eqref{eq:9} and~\eqref{eq:10} yields
\begin{equation}
\sigma_{\dot{X}}^{2}(t)=\lambda_{2}(t)+2 \int_{0}^{\infty}\left[2 \omega \operatorname{Im}\left[A^{*}(t, \omega) \dot{A}(t, \omega)\right]+|\dot{A}(t, \omega)|^{2}\right] \mathrm{d} \omega
\label{eq:20}
\end{equation}

Evidently, the difference between the variance, $\sigma_{\dot{X}}^{2}(t)$, and the second spectral moment, $\lambda_{2}(t)$, is due to terms that contain the furst derivative of the modulating function. Thus, one cannot compute $\sigma_{\dot{X}}^{2}(t)$ by simple integrations on $G_{X X}(t, \omega)$. However, if $A(t, \omega)$ is a slowly varying function of time, as is usually required for applied evolutionary processes, $\dot{A}(t, \omega)$ will be much smaller in magnitude than $A(t, \omega)$. Therefore, $\lambda_{2}(t)$ may dominate the right hand side of Eq.~\eqref{eq:20} and the variance of $\dot{X}(t)$ may be approximated by the second spectral moment. This would surely constitute a convenience for applications if it were not for situations in which the integral for $\lambda_{2}(t)$ becomes divergent while the exact $\sigma_{\dot{X}}^{2}(t)$ is finite.

Considering the second important feature of the stationary spectral moments, there is no conceptual obstacle to extending the geometric arguments to define the characteristics of the EPSD shape. Therefore, the transient spectral moments can bc used to define a "central frequency" and a "bandwidth factor" for the EPSD in a straightforward manner as
\begin{equation}
\omega_{c}(t)=\frac{\lambda_{1}(t)}{\lambda_{0}(t)}
\label{eq:21}
\end{equation}
\begin{equation}
q(t)=\sqrt{1-\frac{\lambda_{1}(t)^{2}}{\lambda_{0}(t) \lambda_{2}(t)}}
\label{eq:22}
\end{equation}

Note that, as with any other property of a nonstationary process, the central frequency and bandwidth of the EPSD are instantaneous properties. In other words, it should be acknowledged that a single process may be narrowband at one moment in time and broadband at another. Similarly, even if a process stays, for example, narrowband over extended time intervals, the predominant frequency may shift.

It was already mentioned that a situation with divergent spectral moments was discovered by Corotis et al.~\cite{Corotis1972}, for one of the simplest cases of an evolutionary process. The investigators considered the response of a simple oscillator to stationary white noise which, being a time-variant filtering of a stationary process, is an evolutionary process. It was discovered that the transient spectral moments converge only for $n=0$ and diverge for $n=1,2$ while $\sigma_{\dot{X}}^{2}(t)$ is finite. To overcome this difficulty the expressions containing the convergent terms of the integrals for the first and the second spectral moments were isolated and approximations of the spectral moments were computed by integrating the convergent terms only.

Concerns with the application usefulness of the transient spectral moment and the spectral characteristics defined through Eqs.~\eqref{eq:21} and~\eqref{eq:22} do not arise from a conceptual viewpoint. Rather, it is situations like the one encountered by Corotis et al.~\cite{Corotis1972}, and the possibility that even low-order spectral moments are unbounded, that hamper the application of transient spectral moments. These difficulties cannot generally be resolved by an approach that removes nonconvergent parts from a complex function like the EPSD, because systematic procedures for identifying a function as nonconvergent do not exist. Moreover, there may be many ways to separate some complicated expression into the sum of two expressions. Different results will be obtained for the "convergent" part depending on the separation of terms which is used. It could even be that both of the separate terms are found to be divergent if a poor choice is used. That is why the problem of defining spectral characteristics (which are at least suitable to quantify bandwidth properties of evolutionary processes) needs to be approached from some other (nongeometric) viewpoint.

Note also that use of the convergent parts of a transient spectral moment fundamentally changes the geometric basis of spectral characteristics as moments of the one-sided EPSD. Accordingly, the central frequency or the bandwidth factor computed by such a scheme would not have the strict geometric sense of its stationary counterparts, although they definitely can be used as bandwidth measures. This fact changes the whole perspective on spectral characteristics of nonstationary processes: it points out that these parameters may be defined in different ways, among which the spectral moments approach is not the most appropriate for application.

\section*{4. The pre-envelope for stationary and nonstationary processes}

The first to consider the problem of spectral characteristics from a nongeometric viewpoint was Di Paola~\cite{DiPaola1985}. The basic idea of his approach is to establish a time-domain interpretation of the spectral moments. Note that even the equivalence of a given even-order stationary spectral moment to the variance of a derivative of the process [Eq.~\eqref{eq:14}] cannot be considered as its true time-domain interpretation. This equivalence simply utilizes the symmetry of $\omega^{2 j} S_{X X}(\omega)$ with respect to the origin of the frequency axis. For nonstationary spectral moments this symmetry can be applied only to the zero-order spectral moment of an EPSD which is equal to the variance of the corresponding evolutionary process.

Di Paola noted that a one-sided spectrum is effectively a product of the usual PSD and the double Heaviside function. This, from a mathematical viewpoint, forms a convolution between the inverse Fourier transforms of the PSD and the Heaviside function. This convolution generates a complex-valued analytic process in the time domain. Di Paola demonstrated that the covariance structure of this process, which is the so-called "pre-envelope", introduced to the random vibration theory by Arens~\cite{Arens1957} and Dugundji~\cite{Dugundji1958}, can be used to establish time-domain interpretations of stationary spectral moments and that nonstationary spectral characteristics may be defined in an analogous way.

The pre-envelope $\Psi(t)$ of the nonstationary $X(t)$ process is defined as a modulation of a preenvelope $\Psi_{S}(t)$ for the stationary process $X_{S}(t)$. The stationary pre-envelope is defined as the complex process
\begin{equation}
\Psi_{S}(t)=X_{S}(t)+i Y_{S}(t)
\label{eq:23}
\end{equation}
in which the real process $Y_{S}(t)$ is the Hilbert transform of $X_{S}(t)$. The distinguishing characteristics of this pre-envelope are that its real part is the original stationary process $X_{S}(t)$, and its Fourier transform is one-sided, being zero for negative $\omega$ values. The latter property is easily verified from the frequency integral representation of the Hilbert transform:
\begin{equation}
Y_{S}(t)=-i \int_{-\infty}^{\infty} \exp (i \omega t) \operatorname{sgn}(\omega) \mathrm{d} Z(\omega)
\label{eq:24}
\end{equation}
in which sgn(.) is the signum function. The corresponding time domain relationship is the convolution integral
\begin{equation}
Y_{S}(t)=\frac{1}{\pi} \int_{-\infty}^{\infty} \frac{X_{S}(\tau)}{t-\tau} \mathrm{d} \tau
\label{eq:25}
\end{equation}

The one-sided Fourier transform of $\Psi_{S}(t)$ also gives it a one-sided PSD, $S_{\Psi \Psi}(\omega)$. The nonstationary pre-envelope can be defined by
\begin{equation}
\Psi(t)=X(t)+i Y(t)=\int_{-\infty}^{\infty} A(t, \omega) \exp (i \omega t)[1+\operatorname{sgn}(\omega)] \mathrm{d} Z(\omega)=2 \int_{0}^{\infty} A(t, \omega) \exp (i \omega t) \mathrm{d} Z(\omega)
\label{eq:26}
\end{equation}

The spectral decomposition of the pre-envelope $\Psi(t)$ is quite similar to that of $X(t)$ itself, but it exhibits power only within the positive frequency range. It may also be noted that the nonstationary "auxiliary" process $Y(t)$ is not the Hilbert transform of $X(t)$, even though $Y_{S(t)}$ is the Hilbert transform of $X_{S}(t)$. Rather, $Y(t)$ is the modulation of the stationary auxiliary process $Y_{S}(t)$,
\begin{equation}
Y(t)=-i \int_{-\infty}^{\infty} \exp (i \omega t) A(t, \omega) \operatorname{sgn}(\omega) \mathrm{d} Z(\omega)
\label{eq:27}
\end{equation}
and it can be expressed in the time domain as
\begin{equation}
Y(t)=\int_{-\infty}^{\infty} a(t, \tau) Y_{S}(\tau) \mathrm{d} \tau=\frac{1}{\pi} \int_{-\infty}^{\infty} \int_{-\infty}^{\infty} \frac{a(t, \tau) X_{S}(u)}{\tau-u} \mathrm{~d} u \mathrm{~d} \tau
\label{eq:28}
\end{equation}

The nonstationary envelope used by Di Paola for $X(t)$ will be denoted by $V(t)$, and is defined as
\begin{equation}
V(t)=|\Psi(t)|=\sqrt{X^{2}(t)+Y^{2}(t)}
\label{eq:29}
\end{equation}

Its covariance function can be written as
\begin{equation}
K_{\Psi \Psi}\left(t_{1}, t_{2}\right)=E\left[\Psi^{*}\left(t_{1}\right) \Psi\left(t_{2}\right)\right]=2 K_{X X}\left(t_{1}, t_{2}\right)+2 i K_{X Y}\left(t_{1}, t_{2}\right)
\label{eq:30}
\end{equation}
where $K_{X X}\left(t_{1}, t_{2}\right)$ and $K_{X Y}\left(t_{1}, t_{2}\right)$ are the autocovariance of $X(t)$, and the cross-covariance of $X(t)$ and $Y(t)$, respectively. These can be found as
\begin{equation}
K_{X X}\left(t_{1}, t_{2}\right)=E\left[X^{*}\left(t_{1}\right) X\left(t_{2}\right)\right]=\int_{-\infty}^{\infty} \exp \left[-i \omega\left(t_{2}-t_{1}\right)\right] A^{*}\left(t_{1}, \omega\right) A\left(t_{2}, \omega\right) S_{X X}(\omega) \mathrm{d} \omega
\label{eq:31}
\end{equation}
and
\begin{equation}
K_{X Y}\left(t_{1}, t_{2}\right)=E\left[X^{*}\left(t_{1}\right) Y\left(t_{2}\right)\right]=-i \int_{-\infty}^{\infty} \exp \left[-i \omega\left(t_{2}-t_{1}\right)\right] A^{*}\left(t_{1}, \omega\right) A\left(t_{2}, \omega\right) \operatorname{sgn}(\omega) S_{X X}(\omega) \mathrm{d} \omega
\label{eq:32}
\end{equation}

Substituting Eqs.~\eqref{eq:31} and~\eqref{eq:32} into Eq.~\eqref{eq:30} results in
\begin{equation}
K_{\Psi \Psi}\left(t_{1}, t_{2}\right)=4 \int_{0}^{\infty} \exp \left[i \omega\left(t_{2}-t_{1}\right)\right] A^{*}\left(t_{1}, \omega\right) A\left(t_{2}, \omega\right) S_{X X}(\omega) \mathrm{d} \omega
\label{eq:33}
\end{equation}
and taking the above expression for $t_{1}=t_{2}=t$ yields the variance of $\Psi(t)$ as
\begin{equation}
\sigma_{\Psi}^{2}(t)=K_{\Psi \Psi}(t, t)=4 \int_{0}^{\infty}|A(t, \omega)|^{2} S_{X X}(\omega) \mathrm{d} \omega=4 \int_{0}^{\infty} G_{X X}(t, \omega) \mathrm{d} \omega=2 \sigma_{X}^{2}(t)
\label{eq:34}
\end{equation}
which demonstrates that the variance of the pre-envelope is directly related to the integral of the one-sided EPSD. This is the result that prompted Di Paola and his co-workers~\cite{DiPaolaPetrucci1990,Muscolino1988,LutesSarkani1997} to investigate in detail the covariance structure of $\Psi(t)$ and establish its association with frequencydomain integrals.

To review the results achieved by Di Paola's investigation, consider the vector $\Psi_{n}(t)$ formed by all derivatives of $\Psi(t)$ up to order $n$, i.e.
\begin{equation}
\Psi_{n}(t)=\left[\Psi(t), \dot{\Psi}(t), \ddot{\Psi}(t), \ldots, \Psi^{(n)}(t)\right]^{T}
\label{eq:35}
\end{equation}

The cross-covariance of any two derivatives $\Psi^{(j)}(t)$ and $\Psi^{(k)}(t)$ can be found as
\begin{equation}
K_{\Psi^{(j)}\Psi^{(k)}}\left(t_{1}, t_{2}\right)=\frac{\partial^{j+k} K_{\Psi \Psi}\left(t_{1}, t_{2}\right)}{\partial t_{1}^{j} \partial t_{2}^{k}}=4 \int_{0}^{\infty} \exp \left[i \omega\left(t_{2}-t_{1}\right)\right] A_{j}^{*}\left(t_{1}, \omega\right) A_{k}\left(t_{2}, \omega\right) S_{X X}(\omega) \mathrm{d} \omega
\label{eq:36}
\end{equation}
where the functions $A_{j}(t, \omega)$ are defined in a recurrent manner as
\begin{equation}
A_{j}(t, \omega)=i \omega A_{j-1}(t,\omega)+\dot{A}_{j-1}(t, \omega), \quad A_{0}(t, \omega)=A(t, \omega)
\label{eq:37}
\end{equation}

For a stationary $X_{S}(t)$
\begin{equation}
A(t, \omega)=1, \quad A_{j}(t, \omega)=(i \omega)^{j}
\label{eq:38}
\end{equation}
Therefore, the cross-covariance relationship becomes
\begin{equation}
K_{\Psi_{S}^{(j)} \Psi_{S}^{(k)}}(t_{1}, t_{2})=K_{\Psi_{S}^{(j)} \Psi_{S}^{(k)}}(\tau)=4(-1)^{j} i^{j+k} \int_{0}^{\infty} \omega^{j+k} \exp [i \omega \tau] S_{X X}(\omega) \mathrm{d} \omega
\label{eq:39}
\end{equation}
where $\tau=t_{2}-t_{1}$. Setting $\tau=0$ gives
\begin{equation}
K_{\Psi_{S}^{(j)} \Psi_{S}^{(k)}}(0)=2(-1)^{j} i^{j+k} \lambda_{j+k}
\label{eq:40}
\end{equation}
where the $\lambda_{j+k}$ are the stationary spectral moments of Eq.~\eqref{eq:13}. Thus, the higher order spectral moments in the stationary case are proportional to the autocovariances and cross-covariances of the derivatives of the pre-envelope. From Eq.~\eqref{eq:40} the spectral moments arc expressed as
\begin{equation}
\lambda_{j+k}=\frac{(-1)^{k} i^{j+k}}{2} K_{\Psi_{S}^{(j)} \Psi_{S}^{(k)}}(0)
\label{eq:41}
\end{equation}

For the first three stationary moments, this formula yields
\begin{equation}
\lambda_{0}=0.5 K_{\Psi_{S} \Psi_{S}}(0), \quad \lambda_{1}=-0.5 i K_{\Psi_{S} \dot{\Psi}_{S}}(0), \quad \lambda_{2}=0.5 K_{\dot{\Psi}_{S} \dot{\Psi}_{S}}(0)
\label{eq:42}
\end{equation}

Based on these direct relationships between pre-envelope covariances and spectral moments in the stationary case, Di Paola~\cite{DiPaola1985} suggested that "spectral moments" for evolutionary processes should be defined by an analog of Eq.~\eqref{eq:41}. In particular, the time-dependent spectral characteristics are simply
\begin{equation}
c_{j k}(t)=\frac{(-1)^{k} i^{j+k}}{2} K_{\Psi^{(j)} \Psi^{(k)}}(t, t)
\label{eq:43}
\end{equation}

Note that in the nonstationary case two indices are needed to distinguish the spectral parameters from one another since $K_{\Psi^{(j)} \Psi^{(k)}}(t, t)$ is not a function of $j
+k$, as was true in the stationary case.

It can be easily seen that the $c_{j k}(t)$ from Eq.~\eqref{eq:43} - strictly defined as time-domain covariances --can also be given a frequency-domain interpretation. These parameters are zero-order moments
of the one-sided auto- and cross-spectra of the process $X(t)$ and its derivatives. In particular, for the first four spectral characteristics one can write
\begin{align}
c_{00}(t) &=0.5 K_{\Psi \Psi}(t, t)=2 \int_{0}^{\infty} G_{X X}(t, \omega) \mathrm{d} \omega=\sigma_{X}^{2}(t) \nonumber \\
c_{11}(t) &=0.5 K_{\dot{\psi} \dot{\psi}}(t, t)=2 \int_{0}^{\infty} G_{\dot{X} \dot{X}}(t, \omega) \mathrm{d} \omega=\sigma_{\dot{X}}^{2}(t) \nonumber \\
c_{01}(t) &=c_{10}^{*}(t)=-0.5 i K_{\Psi \dot{\psi}}(t, t)=-2 i \int_{0}^{\infty} G_{X \dot{X}}(t, \omega) \mathrm{d} \omega
\label{eq:44}
\end{align}

\section*{5. Spectra of an evolutionary process and its derivatives}

As previously noted, the problem with the spectral characteristics defined by Di Paola~\cite{DiPaola1985} is not mathematical, but may be related to interpretation. The introduction of the complex pre-envelope process is not intuitively obvious, and this may be the major factor inhibiting widespread adoption of this model to characterize evolutionary processes. On the other hand, it is intuitively obvious that all the spectral properties of an evolutionary process and its derivatives must be reflected in the autospectra and cross-spectra of those processes. It is, thus, quite possible to define spectral characteristics of an evolutionary process based on computations with these spectra, without ever defining a pre-envelope~\cite{Michaelov1997}. This approach will be reviewed here.

The auto- and cross-spectra for a stationary $X_{S}(t)$ process can be expressed in terms of the PSD $S_{X X}(\omega)$ as
\begin{equation}
S_{X^{(j)} X^{(k)}}(\omega)=(-1)^{j} i^{j+k} \omega^{(j+k)} S_{X X}(\omega)
\label{eq:45}
\end{equation}

Clearly the right-hand side of this equation contains the $\omega^{n} S_{X X}(\omega)$ term which is needed in Eq.~\eqref{eq:13} in defining the stationary spectral moments. Thus, one can rewrite the expression for these moments as
\begin{equation}
\lambda_{j+k}=(-1)^{k} i^{j+k} 2 \int_{0}^{\infty} S_{X^{(j)} X^{(k)}}(\omega) \mathrm{d} \omega
\label{eq:46}
\end{equation}

Therefore, based on exactly the same arguments as those presented in the previous section, one can define nonstationary spectral characteristics as
\begin{equation}
c_{j k}(t)=(-1)^{k} i^{j+k} 2 \int_{0}^{\infty} G_{X^{(j)} X^{(k)}}(t, \omega) \mathrm{d} \omega
\label{eq:47}
\end{equation}

It can be seen that the $c_{j k}(t)$ from Eq.~\eqref{eq:47} are identical to those defined by Di Paola~\cite{DiPaola1985} in Eq.~\eqref{eq:43}. This is confirmed by an examination of Eq.~\eqref{eq:44} for the first four spectral characteristics. The present approach is definitely simpler than the one based on pre-envelope covariances, yet the arguments for both definitions are similar. Note also that it is not easy [although it is not impossible, if one considers the auxiliary process $Y(t)$ from Eq.~\eqref{eq:26}] to deduce the time-domain
interpretation [Eq.~\eqref{eq:43}] from Eq.~\eqref{eq:47}. At the same time, Eq.~\eqref{eq:44} demonstrates that it is relatively easy to deduce the frequency-domain definition [Eq.~\eqref{eq:47}] from the time-domain definition [Eq.~\eqref{eq:43}].

\section*{6. Central frequency and bandwidth factor for evolutionary processes}

The previous two sections demonstrate that spectral characteristics for nonstationary processes can be consistently defined without geometric analogics. Moreover, both time-domain and fre-quency-domain interpretation of the nongeometric spectral characteristics have been established. It has been demonstrated that these nongeometric spectral characteristics include the variance of the nonstationary response and its derivatives, with $c_{k k}(t)$ being the variance of $X^{(k)}(t)$. Also the characteristics become identical to spectral moments for the special case of a stationary process, for which such spectral moments have been found to be very useful. The major motivation for using these alternative evolutionary spectral characteristics, of course, is their convergence, with $c_{j k}(t)$ being convergent so long the variances of $X^{(j)}(t)$ and $X^{(k)}(t)$ are finite. However, it is not clear why and how the $c_{j k}(t)$ values can be used to define physical concepts such as "central frequency" and "bandwidth" of evolutionary processes. In particular, it is known that concepts from stationary processes may not work impeccably when directly applied to nonstationary processes, as demonstrated by the nonconvergent evolutionary spectral moments. These topics of central frequency and bandwidth factor will now be investigated.

As was already pointed out, the geometric bandwidth characteristics of the PSD of a stationary process are directly related to the characteristic signature of the time histories of a random process; that is, they reveal weather the process is narrowband or broadband, low-frequency or highfrequency. Because of this relationship, "central frequency" and "bandwidth factor" are worth investigating from a perspective other than one that relies on the geometric properties of the EPSD shape. Based on this perspective, one can then evaluate the most appropriate definition of nonstationary spectral characteristics. This approach, which one may deem "physical" as compared to the "geometric" approach, is considered in the following part of the article.

A perspective on bandwidth and central frequency can certainly be gained from an investigation of the envelope and phase of an evolutionary process. The envelope $V(t)$ was already defined in a previous section as the modulus of the complex-valued pre-envelope process $\Psi(t)$ [Eq.~\eqref{eq:29}]. This definition also suggests that the processes $X(t)$ and $Y(t)$ can be expressed in the form of
\begin{equation}
X(t)=V(t) \cos (U(t))
\label{eq:48}
\end{equation}
and
\begin{equation}
Y(t)=V(t) \sin (U(t))
\label{eq:49}
\end{equation}
where $U(t)$ is the phase process.
The bandwidth properties of $X(t)$ would be reflected in the properties of $V(t)$ and $U(t)$. For a narrowband, stationary $X(t)$, for example, both the amplitude $V(t)$ and the phase $U(t)$ would be "slowly varying", the former around some average amplitude and the latter around some $\omega_{c} t$,
where $\omega_{c}$ has the meaning of central frequency. That is why it is worth investigating the probability structure of $V(t)$ and $U(t)$ from which the parameters quantifying these "slowly-varying" behaviors can be deduced.

Before beginning this investigation, it is worth noting that an envelope of $X(t)$ can be defined for some auxiliary process $Y(t)$ which is not necessarily equal to the one presented in Eq.~\eqref{eq:26}. Accordingly, for each particular $Y(t)$ there will be different probability distribution of the envelope and the phase, which will result in different formulas for the central frequency and the bandwidth factor. For stationary processes, all $Y_{S(t)}$ suitable for envelope definition can be written as~\cite{LutesSarkani1997}
\begin{equation}
Y_{S}(t)=-i \int_{-\infty}^{\infty} \exp [i \omega t] g(\omega) \mathrm{d} Z(\omega)
\label{eq:50}
\end{equation}
in which $g(\omega)$ is a real-valued odd function of $\omega$. Such a function has two important properties for the envelope definition: (1) $X_{S(t)}$ and $Y_{S(t)}$ are uncorrelated and (2) $\dot{X}_{S(t)}$ and $\dot{Y}_{S}(t)$ are uncorrelated. When the processes are Gaussian the lack of correlation also assures the statistical independence of $X_{S}(t)$ from $Y_{S}(t)$ and of $\dot{X}_{S}(t)$ from $\dot{Y}_{S}(t)$. Furthermore, $g(\omega)$ is also usually required to be such that (3) $X_{S(t)}$ and $Y_{S}(t)$ have the same variance and (4) $\dot{X}_{S(t)}$ and $\dot{Y}_{S}(t)$ have the same variance. If the process $X_{S}(t)$ is narrowband, the last two conditions can be satisfied if $g(\omega)$ is required to be equal to 1 in the neighborhood of the central frequency $\omega_{c}$. Mathematically, the four conditions for the auxiliary process $Y_{S}(t)$ are
\begin{array}{ll}
\text { (1) } E\left[X_{S(t)} Y_{S(t)}\right]=0 & \text { (2) } E\left[\dot{X}_{S}(t) \dot{Y}_{S}(t)\right]=0 \\
\text { (3) } \sigma_{X}^{2}=\sigma_{Y}^{2} & \text { (4) } \sigma_{\dot{X}}^{2}=\sigma_{\dot{Y}}^{2}
\end{array}
\label{eq:51}
\end{equation}

Many functions $g(\omega)$ can satisfy the four requirements in Eq.~\eqref{eq:51} for a stationary auxiliary process. The simplest choice is $g(\omega)=\operatorname{sgn}(\omega)$, which corresponds to the Hilbert transform of $X_{S}(t)$. Another popular choice for narrowband processes is $g(\omega)=\omega / \omega_{t}$, which gives and results in the so-called "energy-based" envelope. Other possible choices for a narrowband process are $g(\omega)=\left(\omega / \omega_{c}\right)^{n}$ with $n$ odd. These correspond to a $Y_{S}(t)$ that is proportional to an odd-order derivative of $X_{S}(t)$.

The situation, however, is not as simple for evolutionary processes as it is for stationary. To be sure, one can define a generalized evolutionary $Y(t)$ as
\begin{equation}
Y(t)=-i \int_{-\infty}^{\infty} A(t, \omega) \exp (i \omega t) g(\omega) \mathrm{d} \omega
\label{eq:52}
\end{equation}
whose time derivative is found as
\begin{equation}
\dot{Y}(t)=-i \int_{-\infty}^{\infty} A_{1}(t, \omega) \exp (i \omega t) g(\omega) \mathrm{d} \omega
\label{eq:53}
\end{equation}

Similar to the stationary situation, the above choice assures that (1) and (2) in Eq.~\eqref{eq:51} [with stationary $X_{S}(t)$ and $Y_{S}(t)$ replaced by the corresponding evolutionary $X(t)$ and $Y(t)$] are satisfied. It is not possible, however, to assure that (3) and (4) are satisfied in general for arbitrary $A(t, \omega)$ and $S_{X X}(\omega)$. The only choice that obviously satisfies all conditions in Eq.~\eqref{eq:51} is $g(\omega)=\operatorname{sgn}(\omega)$, which results in the $Y(t)$ already defined in Eq.~\eqref{eq:26}. Thus, the modulated Hilbert transform [Eq.~\eqref{eq:26}] is the only desirable choice for defining the envelope of an evolutionary process. The definitions of "central frequency" and "bandwidth factor" that would result from the envelope corresponding to Eq.~\eqref{eq:26} are the reasonable choices for the evolutionary processes. Accordingly, this is the situation considered here.

The interest hereafter is in the marginal probability distributions of the envelope, $V(t)$, the phase, $U(t)$, and their derivatives, $\dot{V}(t)$ and $\dot{U}(t)$. For a stationary Gaussian $X_{S}(t)$ these distributions are readily available in the literature. The expressions are independent of time and can be written as~\cite{Sveshnikov1966}
\begin{align}
p_{V_{S}}(\nu) &=\frac{\nu}{\sigma_{X}^{2}} \exp \left(-\frac{\nu^{2}}{2 \sigma_{X}^{2}}\right) \quad 0 \leqslant \nu \leqslant \infty \label{eq:54} \\
p_{U_{S}}(u) &=\frac{1}{2 \pi} \quad 0 \leqslant u \leqslant 2 \pi \label{eq:55} \\
p_{\dot{V}_{S}}(\dot{\nu}) &=\frac{1}{\sqrt{2 \pi} \sigma_{\dot{X}} q} \exp \left(-\frac{\dot{\nu}^{2}}{2 \sigma_{\dot{X}}^{2} q^{2}}\right) \quad-\infty \leqslant \dot{\nu} \leqslant \infty \label{eq:56} \\
p_{\dot{U}_{S}}(\dot{u}) &=\frac{\sigma_{\dot{X}}^{2} q^{2}}{\sigma_{X}^{2}}\left[\frac{\sigma_{\dot{X}}^{2} q^{2}}{\sigma_{X}^{2}}+\left(\dot{u}-\omega_{c}\right)^{2}\right]^{-\frac{3}{2}} \quad-\infty \leqslant \dot{u} \leqslant \infty \label{eq:57}
\end{align}

In these equations, $\sigma_{X}^{2}, \sigma_{\dot{X}}^{2}, \omega_{c}$, and $q$ are the variance of $X_{S}(t)$, the variance of $\dot{X}_{S}(t)$, the central frequency defined in Eq.~\eqref{eq:15}, and the bandwidth factor defined in Eq.~\eqref{eq:17}, respectively. Among the four PDFs, Eq.~\eqref{eq:54} demonstrates that the envelopc, $V_{S}(t)$, is Rayleigh distributed and Eq.~\eqref{eq:55} shows that the phase, $U_{S}(t)$, is uniformly distributed, over the interval $[0,2 \pi]$. In neither of these equations, however, do the parameters $\omega_{c}$ and $q$ appear.

The central frequency appears in the PDF of $\dot{U}_{S}(t)$ only. Examination of $p_{\dot{U}_{S}}(\dot{u})$ reveals that it is symmetric with respect to $\omega_{c}$. Thus the mean value of $\dot{U}_{s}(t)$ is
\begin{equation}
E\left[\dot{U}_{S}(t)\right]=\omega_{c}
\label{eq:58}
\end{equation}
which can be considered to be the definition of $\omega_{c}$. The central frequency is, in fact, the mean value of the phase derivative.

The bandwidth factor appears in the PDFs of both $\dot{V}_{S}(t)$ and $\dot{U}_{S}(t)$. Eq.~\eqref{eq:56} shows that the distribution of $\dot{V}_{S(t)}$ is Gaussian with mean zero and with standard deviation equal to $\sigma_{\dot{X}} q$. Thus,
the bandwidth factor of a stationary Gaussian process scales the standard deviation of the derivative of its envelope. For fixed values of other parameters such as $\sigma_{X}$ and $\sigma_{\dot{X}}$, a process having a lower bandwidth factor also has a smaller variance of $\dot{V}_{S}(t)$. Therefore, the PDF of $\dot{V}_{S}(t)$ is more bounded around its (zero) mean value, and there is very little probability that $\dot{V}_{S}(t)$ takes on large values. Since its derivative is small, the amplitude of the process, $V_{S}(t)$, cannot change drastically over short periods of time in any time history. That is, $V_{S}(t)$ must be slowly varying.

Similar considerations hold for the PDF of $\dot{U}_{S}(t)$. Even though the second moment, $E\left[\dot{U}_{S}^{2}(t)\right]$ and, as a result, the standard deviation, $\sigma_{\dot{U}_{S}}$, are unbounded it can be seen that the dispersion of this PDF around its mean value is again controlled by the $q$ factor (for fixed $\sigma_{X}$ and $\sigma_{\dot{X}}$ ). Thus, the probability that $\dot{U}(t)$ deviates from the mean $\omega_{c}$ is lower for a process with lower $q$ factor. As a result, a time history of the phase $U_{S}(t)$ would also be slowly varying around $\omega_{c} t$.

Thus, the bandwidth factor of a stationary Gaussian process can be quantified from the dispersion of the probability distributions of the derivatives of the envelope and the phase, $\dot{V}_{S}(t)$ and $\dot{U}_{S}(t)$, respectively. It should be noted, though, that the bandwidth factor can be considered a characteristic of $X_{S}(t)$ just as much as it is a characteristic of $\dot{X}_{S}(t)$.

It seems advantageous to identify the definitions suitable for "central frequency" and "bandwidth factor" for evolutionary processes based on an analysis similar to that given for stationary processes. The probability distributions of the envelope and the phase of an evolutionary Gaussian $X(t)$ with auxiliary $Y(t)$ in the form of Eq.~\eqref{eq:26} have been studied by a number of investigators (e.g.~\cite{Muscolino1988,Yang1972}). The expressions of all marginal PDFs, however, are usually not provided. For completeness and to present the PDFs in the form most appropriate for this analysis, a technique for deriving all formulas of interest is presented in Appendix A. The corresponding marginal PDFs are
\begin{align}
p_{V}(\nu, t) &=\frac{v}{\sigma_{X}^{2}(t)} \exp \left(-\frac{v^{2}}{2 \sigma_{X}^{2}(t)}\right) \label{eq:59} \\
p_{U}(u, t) &=\frac{1}{2 \pi} \quad 0 \leqslant u \leqslant 2 \pi \label{eq:60}
\end{align}
\begin{align}
p_{\dot{V}}(\dot{\nu}, t) &=\frac{\Delta(t)}{\sqrt{2 \pi}\left(\Delta^{2}(t)+\rho_{X \dot{X}}^{2}(t)\right) \sigma_{\dot{X}}(t)} \exp \left[-\frac{\rho_{X \dot{X}}^{2}(t) \dot{\nu}^{2}}{2\left(\Delta^{2}(t)+\rho_{X \dot{X}}^{2}(t)\right) \sigma_{\dot{X}}^{2}(t)}\right] \nonumber \\
&\times\left\{\exp \left[-\frac{\sqrt{2 \pi} \rho_{X \dot{X}}(t) \dot{\nu}}{2\left(\Delta^{2}(t)+\rho_{X \dot{X}}^{2}(t)\right) \sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)}\right]+\frac{\rho_{X \dot{X}}(t) \dot{\nu}}{\sqrt{\Delta^{2}(t)+\rho_{X \dot{X}}^{2}(t)} \sigma_{\dot{X}}(t) \Delta(t)} \right. \nonumber \\
&\left.\Phi\left(\frac{\sqrt{\Delta^{2}(t)+\rho_{X \dot{X}}^{2}(t)} \sigma_{\dot{X}}(t) \Delta(t)}{}\right)\right\} \label{eq:61}
\end{align}
\begin{equation}
p_{\dot{U}}(\dot{u}, t)=\frac{\sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)}{2 \sigma_{X}^{2}(t)}\left[\frac{\sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)}{\sigma_{X}^{2}(t)}+(\dot{u}-\Omega(t))^{2}\right]^{-\frac{3}{2}}
\label{eq:62}
\end{equation}

In the above equations, $\sigma_{X}^{2}(t), \sigma_{\dot{X}}^{2}(t)$, and $\rho_{X \dot{X}}(t)$ are the nonstationary variances and correlation coefficient of $X(t)$ and $\dot{X}(t)$. The other two parameters appearing in the expressions are
\begin{equation}
\Omega(t)=\frac{Q(t)}{\sigma_{X}^{2}(t)}
\label{eq:63}
\end{equation}
and
\begin{equation}
\Delta(t)=\sqrt{1-\frac{R^{2}(t)+Q^{2}(t)}{\sigma_{X}^{2}(t) \sigma_{\dot{X}}^{2}(t)}}=\sqrt{1-\rho_{X \dot{X}}^{2}(t)-\rho_{X \dot{Y}}^{2}(t)}
\label{eq:64}
\end{equation}
where $R(t) \equiv K_{X \dot{X}}(t, t)$ is the covariance of $X(t)$ and $\dot{X}(t)$ and $Q(t) \equiv K_{X \dot{Y}}(t, t)$ and $\rho_{X \dot{Y}}(t)$ are the covariance and the correlation coefficient of $X(t)$ and, $\dot{Y}(t)$ respectively.

Again, it can be seen that the distributions of the amplitude and the phase are Rayleigh and uniform, respectively. It may be noted that the Rayleigh distribution for an evolutionary envelope has also been found in the past by quite different methods. In particular, an approximate Fok-ker-Planck equation was derived for an energy-based envelope by modeling that envelope as a Markov process, and it was shown that the evolutionary Rayleigh distribution was the solution of that Fokker-Planck equation~\cite{SpanosLutes1980,SolomosSpanos1982,SpanosSolomos1983}. The distribution of the phase derivative $\dot{U}(t)$ is similar to that in Eq.~\eqref{eq:57} for the stationary process but this time its expected value, $E[\dot{U}(t)]$, is equal to the parameter $\Omega(t)$. Based on the comments regarding the stationary case, this is the parameter that should be termed "central frequency".

The distribution of the envelope derivative, $\dot{V}(t)$ represents an interesting case. At first glance, the expression in Eq.~\eqref{eq:61} looks quite a bit more complex than the simple Gaussian expression in the stationary case. The reason for this complexity is the non-zero correlation between the evolutionary process and its derivative. In particular, if $\rho_{X \dot{X}}(t)=0$ is put into this equation, then the resulting distribution becomes Gaussian. Under a more careful examination, however, the PDF of $\dot{V}(t)$ can be recognized as the so-called "Rice distribution", which is usually used for the peaks of a Gaussian process. It can be shown that a Rice-distributed random variable can always be represented as the sum of two independent random variables, one of which is zero-mean Gaussian and the other of which is Rayleigh distributed. For the envelope derivative, these two variables are such that the variance of the Gaussian distribution is $\Delta^{2}(t) \sigma_{\dot{X}}^{2}(t)$ and the parameter of the Rayleigh distribution is $\rho_{X \dot{X}}^{2}(t) \sigma_{\dot{X}}^{2}(t)$. From this, using simple expectation relationships, one can show that
\begin{align}
E[\dot{V}(t)] &=\sqrt{0.5 \pi} \rho_{X \dot{X}}(t) \sigma_{\dot{X}}(t) \nonumber \\
E\left[\dot{V}^{2}(t)\right] &=\left[\Delta^{2}(t)+2 \rho_{X \dot{X}}^{2}(t)\right] \sigma_{\dot{X}}^{2}(t) \nonumber \\
\sigma_{\dot{V}}^{2}(t) &=\left[\Delta^{2}(t)+0.43 \rho_{X \dot{X}}^{2}(t)\right] \sigma_{\dot{X}}^{2}(t)
\label{eq:65}
\end{align}

The parameter controlling the dispersion of $p_{\dot{V}}(\dot{v}, t)$, and thus the slow variation of $\dot{V}(t)$ around its mean value, is the standard deviation of $\dot{V}(t)$ equal to $\left[\Delta^{2}(t)+0.43 \rho_{X \dot{X}}^{2}(t)\right]^{1/2} \sigma_{\dot{X}}(t)$.

An examination of the phase derivative PDF in Eq.~\eqref{eq:62} reveals that its second moment is again unbounded and that the parameter $\Delta(t)$ now controls the dispersion of the PDF, performing the function of the bandwidth factor in the stationary case. Evidently, an evolutionary process generally does not have a single parameter influencing the dispersion of the PDFs of the derivatives of both envelope and phase.

It can be seen, that all parameters needed to characterize the probability distribution of the envelope and the phase processes can be derived from the spectral characteristics defined in Eq.~\eqref{eq:43}. The variances of $X(t)$ and $\dot{X}(t)$ are equal to $c_{00}(t)$ and $c_{11}(t)$, respectively. Additionally, the cross-covariances between $X(t)$ and $\dot{X}(t)$, and between $X(t)$ and $\dot{Y}(t)$ can be expressed as
\begin{equation}
R(t)=K_{X \dot{X}}(t, t)=-\operatorname{Im}\left[c_{01}(t)\right], \quad Q(t)=K_{X \dot{Y}}(t, t)=\operatorname{Re}\left[c_{01}(t)\right]
\label{eq:66}
\end{equation}

Accordingly, the correlation coefficient between $X(t)$ and $\dot{X}(t)$ is expressed as
\begin{equation}
\rho_{X \dot{X}}(t)=\frac{-\operatorname{Im}\left[c_{01}(t)\right]}{\sqrt{c_{00}(t) c_{11}(t)}}
\label{eq:67}
\end{equation}

The evolutionary central frequency defined as the expected value of the PDF in Eq.~\eqref{eq:62} is expressed in terms of spectral parameters as
\begin{equation}
\omega_{c}(t)=\Omega(t)=\frac{\operatorname{Re}\left[c_{01}(t)\right]}{c_{00}(t)}
\label{eq:68}
\end{equation}

The parameter $\Delta(t)$ is expressed as
\begin{equation}
\Delta(t)=\sqrt{1-\frac{\left(\operatorname{Re}\left[c_{01}(t)\right]\right)^{2}}{c_{00}(t) c_{11}(t)}-\frac{\left(\operatorname{Im}\left[c_{01}(t)\right]\right)^{2}}{c_{00}(t) c_{11}(t)}}=\sqrt{1-\frac{\left|c_{01}(t)\right|^{2}}{c_{00}(t) c_{11}(t)}}
\label{eq:69}
\end{equation}

As previously explained, $\Delta(t)$ or $\sigma_{\dot{V}}(t) / \sigma_{\dot{X}}(t)$ might be nominated as the "bandwidth factor" of an evolutionary process. There are two problems with these parameter which are both due to their functional dependance on the correlation coefficient, $\rho_{X \dot{X}}(t)$ as demonstrated by Eqs.~\eqref{eq:64} and~\eqref{eq:65}. The first problem is wether it should be accepted that the bandwidth properties of a process are influenced by this correlation coefficient. Note that for stationary processes such a question does not exist, since $\rho_{X \dot{X}}(t) \equiv 0$ and both $\Delta(t)$ and $\sigma_{\dot{V}}(t) / \sigma_{\dot{X}}(t)$ are identical to the stationary bandwidth factor $q$.

The second problem relates to special evolutionary processes whose first three transient spectral moments are finite so that it is possible to base a bandwidth factor on the geometric definition [Eq.~\eqref{eq:22}]. In such a case, it would be desirable for the geometric and nongeometric bandwidth factors to render similar values. The most typical example for this situation is a modulated stationary process which is an evolutionary process whose modulating function varies in time but does not vary with frequency [i.e. $A(t, \omega)=A(t)$]. The EPSD of the modulated stationary process is
$G_{X X}(t, \omega)=A^{2}(t) S_{X X}(\omega)$. It can be easily seen that the transient spectral moments of such a process are $A^{2}(t)$ times the spectral moments of $X_{S}(t)$, so that its geometric bandwidth factor is constant and equal to the bandwidth factor of $X_{S}(t)$. At the same time, the time derivative $\dot{A}(t)$ is nonzero, resulting in a nonzero correlation coefficient. Therefore, $\Delta(t)$ or $\sigma_{\dot{V}}(t) / \sigma_{\dot{X}}(t)$ in this case cannot be equal to the geometric bandwidth factor.

Based on the previous arguments, it seems reasonable to completely exclude the correlation coefficient $\rho_{X \dot{X}}(t)$ from the bandwidth factor definition. Accordingly, the bandwidth factor of an evolutionary process can be defined as dependent only on the correlation coefficient $\rho_{X \dot{Y}}(t)$, and written as
\begin{equation}
q(t)=\sqrt{1-\frac{\left(\operatorname{Re}\left[c_{01}(t)\right]\right)^{2}}{c_{00}(t) c_{11}(t)}}=\sqrt{1-\rho_{X \dot{Y}}^{2}(t)}
\label{eq:70}
\end{equation}

Note that for a modulated stationary process, this definition renders results identical to those of the geometric definition.

The other two bandwidth-related parameters, $\Delta(t)$ and $\sigma_{\dot{V}}(t) / \sigma_{\dot{X}}(t)$, can now be expressed as
\begin{equation}
\Delta(t)=\sqrt{q^{2}(t)-\rho_{X \dot{X}}^{2}(t)}, \quad \sigma_{\dot{V}}(t) / \sigma_{\dot{X}}(t)=\sqrt{q^{2}(t)-0.57 \rho_{X \dot{X}}^{2}(t)}
\label{eq:71}
\end{equation}

By using Schwartz inequality properties one can show that $0 \leqslant \Delta(t) \leqslant 1$ always. From the properties of $\Delta(t)$ and $\rho_{X \dot{X}}(t)$ one can conclude that $0 \leqslant\left|\rho_{X \dot{X}}(t)\right| \leqslant q(t) \leqslant 1$.

\section*{7. Concluding remarks}

The conceptual analysis of spectral characteristics of random processes presented in this article reveals the ways in which the problem is more complex for nonstationary (evolutionary) processes than for stationary processes. The spectral characteristics found to be very useful for stationary processes - Vanmarke's spectral moments~\cite{Vanmarke1972} - can be readily defined for evolutionary processes, but one should be aware of two potential problems plaguing their use. First, the variances of derivatives of the evolutionary process are not equal to the even-order spectral moments. Only if the modulating function of the process varies slowly in time, can these spectral moments be used as approximations, avoiding the need to find derivatives of the modulating function to compute the exact variances. This approximation can be utilized for slowly varying modulating functions as long as the second potential problem does not appear. This second problem is nonconvergence of the integrals for low-order evolutionary spectral moments. One cannot expect a spectral moment of an arbitrarily large order to be convergent, but if the variance of a particular derivative of the process is finite, then it is desirable to characterize the process by using spectral parameters which are finite up to this order.

It has been shown that meaningful spectral parameters for an evolutionary process can be defined in a simple way as integrals of the one-sided autospectra and cross-spectra of the process and its derivatives. These parameters are equivalent to those defined earlier by Di Paola~\cite{DiPaola1985}, in a
more complex manner, as autocovariances and cross-covariances of the pre-envelope process and its derivatives. These characteristics do not exhibit either of the problems encountered with spectral moments. Moreover, they offer two useful advantages. The first advantage is that they are related to the statistics of the envelope process and therefore have a more "physical" significance for the process than do the spectral moments. The second advantage is that they can be computed either through the frequency domain or through the time domain, whichever is more appropriate in a particular application.

The nongeometric spectral characteristics do not allow direct definition of bandwidth properties as can be done for spectral moments of the evolutionary processes. To overcome this difficulty, the probability distributions of the derivatives of the envelope and the phase have been analyzed. This analysis reveals that for stationary as well as nonstationary processes "central frequency" can be defined as the expected value of the phase derivative. At the same time, the suitable "bandwidth factor" can be deduced from the property of a narrowband process to possess envelope and phase that are slowly varying functions of time. While the definition of "central frequency" derived through this approach seems to be unambiguous, different possibilities exist for the evolutionary "bandwidth factor". Moreover, the analysis suggests that the slow variation of the derivatives of the envelope and the phase is influenced by the correlation coefficient of the evolutionary process and its derivative - a parameter that is not usually associated with a geometric definition of bandwidth. For consistency with the situation arising in modulated stationary processes, the bandwidth factor definition suggested in this study does not depend on this correlation coefficient.

\section*{Appendix A: Probability distribution of envelope and phase of evolutionary processes}

Consider the evolutionary, zero-mean random vector $\mathbf{X}=[X(t), \dot{X}(t), Y(t), \dot{Y}(t)]^{T}$, in which the scalar processes $X(t)$ and $Y(t)$ defined by Eqs.~\eqref{eq:1} and~\eqref{eq:26}, and the corresponding random vector $\mathbf{V}=[V(t), \dot{V}(t), U(t), \dot{U}(t)]^{T}$ which is related to $\mathbf{X}$ by Eqs.~\eqref{eq:48} and~\eqref{eq:49}. The PDF of $\mathbf{X}$ can be written in the standard form of
\begin{equation}
p_{\mathbf{X}}(\mathbf{x}, t)=\frac{1}{4 \pi^{2}|\mathbf{K}|^{1 / 2}} \exp \left(-\frac{1}{2} \mathbf{x}^{T} \mathbf{K}^{-1} \mathbf{x}\right)
\label{eq:A1}
\end{equation}
in which $\mathbf{K}=E\left[\mathbf{X}\mathbf{X}^{T}\right]$ is the covariance matrix for $\mathbf{X}$. Using, $R(t) \equiv K_{X \dot{X}}(t, t), Q(t) \equiv K_{X \dot{Y}}(t, t)$ and the usual notation for variance, one can write $\mathbf{K}$. its determinant, and its inverse as
\begin{equation}
\mathbf{K}=\left[\begin{array}{cccc}
\sigma_{X}^{2}(t) & R(t) & 0 & Q(t) \\
R(t) & \sigma_{\dot{X}}^{2}(t) & -Q(t) & 0 \\
0 & -Q(t) & \sigma_{X}^{2}(t) & R(t) \\
Q(t) & 0 & R(t) & \sigma_{\dot{X}}^{2}(t)
\end{array}\right],|\mathbf{K}|=P^{4}, \mathbf{K}^{-1}=\frac{1}{P^{2}}\left[\begin{array}{cccc}
\sigma_{\dot{X}}^{2}(t) & -R(t) & 0 & -Q(t) \\
-R(t) & \sigma_{X}^{2}(t) & Q(t) & 0 \\
0 & Q(t) & \sigma_{\dot{X}}^{2}(t) & -R(t) \\
-Q(t) & 0 & -R(t) & \sigma_{X}^{2}(t)
\end{array}\right]
\label{eq:A2}
\end{equation}
in which $P^{2}=\sigma_{X}^{2}(t) \sigma_{\dot{X}}^{2}(t)-R(t)^{2}-Q(t)^{2}$. The PDF of $\mathbf{V}$ is then found from the standard transformation formula
\begin{equation}
p_{\mathbf{V}}(\mathbf{v}, t)=p_{\mathbf{X}}(\mathbf{x}, t)|J|
\label{eq:A3}
\end{equation}
in which the components of $\mathbf{x}$ and $\mathbf{v}$ are related to each other in the same way as are those of $\mathbf{X}$ and $\mathbf{V}$ by Eqs.~\eqref{eq:48} and~\eqref{eq:49}. The Jacobian of the transformation is
\begin{equation}
J=\left|\frac{\partial \mathbf{x}}{\partial \mathbf{v}}\right|=v^{2}
\label{eq:A4}
\end{equation}

Furthermore, it can be found that, $x^{2}+y^{2}=v^{2}, \dot{x}^{2}+\dot{y}^{2}=\dot{v}^{2}+v \dot{u}^{2}, x \dot{x}+y \dot{y}=v \dot{v}$, and $x \dot{y}-\dot{x} y=v^{2} \dot{u}$. Substituting these relationships into Eq.~\eqref{eq:A3} gives
\begin{equation}
p_{\mathbf{V}}(\mathbf{v}, t)=\frac{v^{2}}{4 \pi^{2} P^{2}} \exp \left\{-\frac{1}{2 P^{2}}\left[\sigma_{\dot{X}}^{2}(t) v^{2}+\sigma_{X}^{2}(t)\left(\dot{v}^{2}+v^{2} \dot{u}^{2}\right)-2 R(t) v \dot{v}-2 Q(t) v^{2} \dot{u}\right]\right\}
\label{eq:A5}
\end{equation}
which can then be rewritten as
\begin{align}
p_{\mathbf{V}}(\mathbf{v}, t) &=\frac{2}{4 \pi^{2} \sigma_{X}^{2}(t) \sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)} \exp \left\{-\frac{1}{2}\left[\left(1+\frac{\rho_{X \dot{X}}^{2}(t)}{\Delta^{2}(t)}\right) \frac{v^{2}}{\sigma_{X}^{2}(t)}+\frac{v^{2}(\dot{u}-\Omega(t))^{2}}{\sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)}-\right.\right. \nonumber \\
&\left.\left.-2 \frac{v}{\sigma_{X}(t)} \frac{\dot{v}}{\sigma_{\dot{X}}(t) \Delta(t)} \frac{\rho_{X \dot{X}}(t)}{\Delta(t)}+\frac{\dot{v}^{2}}{\sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)}\right]\right\}
\label{eq:A6}
\end{align}
where $\rho_{X \dot{X}}(t)$ denotes the correlation coefficient of $X(t)$ and $\dot{X}(t)$, and $\Omega(t)$ and $\Delta(t)$ arc given by Eqs.~\eqref{eq:63} and~\eqref{eq:64}, respectively.

One can now find the distribution of the individual components of $\mathbf{V}$ by integrating the joint PDF in Eq.~\eqref{eq:A6}. Since the phase $U(t)$ has been taken to have a range of $[0,2 \pi]$, and the dummy value $u$ does not appear in Eq.~\eqref{eq:A6}, it is clear that $U(t)$ is independent of the other components, and its marginal distribution is as given in Eq.~\eqref{eq:60}. Performing the appropriate integrations on Eq.~\eqref{eq:A6} gives the joint distributions for $\{V(t), \dot{V}(t)\}$ and $\{V(t), \dot{U}(t)\}$, respectively as
\begin{align}
p_{V \dot{V}}(v, \dot{v}, t) &=\frac{v}{\sqrt{2 \pi} \sigma_{X}^{2}(t) \sigma_{\dot{X}}(t) \Delta(t)} \exp \left\{-\frac{1}{2}\left[\left(1+\frac{\rho_{X \dot{X}}^{2}(t)}{\Delta^{2}(t)}\right) \frac{v^{2}}{\sigma_{X}^{2}(t)}-2 \frac{v}{\sigma_{X}(t)} \frac{\dot{v}}{\sigma_{\dot{X}}(t) \Delta(t)} \frac{\rho_{X \dot{X}}(t)}{\Delta(t)}\right.\right. \nonumber \\
&\left.\left.+\frac{\dot{v}^{2}}{\sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)}\right]\right\} \label{eq:A7} \\
p_{V \dot{U}}(v, \dot{u}, t) &=\frac{v^{2}}{\sqrt{2 \pi} \sigma_{X}^{2}(t) \sigma_{\dot{X}}(t) \Delta(t)} \exp \left\{-\frac{1}{2}\left[\frac{v^{2}}{\sigma_{X}^{2}(t)}+\frac{v^{2}(\dot{u}-\Omega(t))^{2}}{\sigma_{\dot{X}}^{2}(t) \Delta^{2}(t)}\right]\right\}
\label{eq:A8}
\end{align}
and further integration gives the remaining marginal distributions as in Eqs.~\eqref{eq:59},~\eqref{eq:61}, and~\eqref{eq:62}.

\begin{thebibliography}{99}
\bibitem{Vanmarke1972}
Vanmarke EH. Properties of spectral moments with applications to random vibrations. J Eng Mech Div, ASME 1972;42:215--20.
\bibitem{BendatPiersol1986}
Bendat J, Piersol AG. Random data: analysis and measurement procedures. New York: Wiley, 1986.
\bibitem{Priestley1988}
Pricstley MB. Non-linear and non-stationary time series analysis. London, San Diego: Academic Press, 1988.
\bibitem{Michaelov1997}
Michaelov G. Nonstationary extreme response of simple oscillators. Doctoral dissertation, The George Washington University, Washington, DC, 1997.
\bibitem{Corotis1972}
Corotis RB, Vanmarke FH. Cornell CA. First passage of nonstationary random processes. J Eng Mech Div, ASME 1972;98(EM2):401--14.
\bibitem{DiPaola1985}
Di Paola M. Transient spectral moments of linear systems. SM Archives 1985;10:225--43.
\bibitem{NigamNarayanan1994}
Nigam NC, Narayanan S. Applications of random vibrations. Berlin, New York, New Delhi: Springer-Verlag, 1994.
\bibitem{SoongGrigoriu1993}
Soong TT, Grigoriu M. Random vibrations of mechanical and structural systems. Englewood Cliffs NJ: Prentice Hall, 1993.
\bibitem{Priestley1965}
Priestley MB. Evolutionary spectra and nonstationary processes. J Roy Stat Soc 204307.
\bibitem{Arens1957}
Arens R. Complex processes for envelopes of normal noise. IRE Transaction of Information Theory 1957;3:204--7.
\bibitem{Dugundji1958}
Dugundji J. Envelope and pre-envelope of real waveforms. IRE Transaction of Information Theory 1958:4:53--7.
\bibitem{Muscolino1988}
Muscolino G. Nonstationary envelope in random vibration theory. Journal of Engng Mech Div 1988;109(EM1):263--77.
\bibitem{DiPaolaPetrucci1990}
Di Paola M, Petrucci G. Spectral moments and pre-envelope covariances of nonseparable processes. Journal of Appl Mech 1990;57:218--24.
\bibitem{LutesSarkani1997}
Lutes LD, Sarkani S. Stochastic analysis of structural and mechanical vibrations. Englewood Cliffs NJ: Prentice Hall, 1997.
\bibitem{Sveshnikov1966}
Sveshnikov AA. Applied methods of the theory of random functions. Oxford, New York: Pergamon Press, 1966.
\bibitem{Yang1972}
Yang J-N. Nonstationary envelopc process and first excursion probability. J Struct Mech 1972; 1(2):231--49.
\bibitem{SpanosLutes1980}
Spanos P-TD, Lutes LD. Probability of response to evolutionary excitation. J Eng Mech Div 1980;106(EM2):213--24.
\bibitem{SolomosSpanos1982}
Solomos GP, Spanos P-TD. Solution to the backward-Kolmogorov equation for a nonstationary oscillation problem. J Appl Mech, ASME 1982;49:923--5.
\bibitem{SpanosSolomos1983}
Spanos P-TD. Solomos GP. Markov approximation to transient vibration. J Eng Mech, ASCE 1983;109(4):1134--50.
\end{thebibliography}
