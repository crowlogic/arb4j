\documentclass{article}
\usepackage[english]{babel}
\usepackage{geometry,amsmath,amssymb,latexsym}
\geometry{letterpaper}

%%%%%%%%%% Start TeXmacs macros
\newcommand{\assign}{:=}
\newcommand{\tmaffiliation}[1]{\\ #1}
\newenvironment{proof}{\noindent\textbf{Proof\ }}{\hspace*{\fill}$\Box$\medskip}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
%%%%%%%%%% End TeXmacs macros

\begin{document}

\title{Delta Functions, Heaviside Steps, and Level Crossing Counts for
Differentiable Paths}

\author{
  Stephen Crowley
  \tmaffiliation{September 14, 2025}
}

\date{}

\maketitle

{\tableofcontents}

\section{Foundations of Distributions on Real Line}

\begin{definition}
  [Schwartz Test Function Space] The Schwartz space $\mathcal{S} (\mathbb{R})$
  is the space of all infinitely differentiable functions $\phi : \mathbb{R}
  \to \mathbb{R}$ such that for every pair of nonnegative integers $m, n$,
  \begin{equation}
    \sup_{x \in \mathbb{R}} |x^m \phi^{(n)} (x) | < \infty
  \end{equation}
  Functions in $\mathcal{S} (\mathbb{R})$ are called rapidly decreasing smooth
  test functions.
\end{definition}

\begin{definition}
  [Tempered Distribution] A tempered distribution is a continuous linear
  functional
  \begin{equation}
    T : \mathcal{S} (\mathbb{R}) \to \mathbb{R}
  \end{equation}
\end{definition}

\begin{definition}
  [Dirac Delta Distribution] The Dirac delta distribution $\delta_a \in
  \mathcal{S}' (\mathbb{R})$ centered at $a \in \mathbb{R}$ is defined by
  \begin{equation}
    \langle \delta_a, \phi \rangle = \phi (a)
  \end{equation}
  for all $\phi \in \mathcal{S} (\mathbb{R})$. When $a = 0$, one writes
  $\delta = \delta_0$.
\end{definition}

\begin{definition}
  [Heaviside Step Function] The Heaviside step function $H : \mathbb{R} \to
  \{0, 1\}$ is defined by
  \begin{equation}
    H (x) = \left\{\begin{array}{ll}
      1 & \text{if } x > 0\\
      0 & \text{if } x \leq 0
    \end{array}\right.
  \end{equation}
\end{definition}

\begin{definition}
  [Distributional Derivative] For a tempered distribution $T \in \mathcal{S}'
  (\mathbb{R})$, its distributional derivative $T' \in \mathcal{S}'
  (\mathbb{R})$ is defined by
  \[ \langle T', \phi \rangle = - \langle T, \phi' \rangle \]
  for all $\phi \in \mathcal{S} (\mathbb{R})$.
\end{definition}

\section{Basic Identities}

\begin{theorem}
  [Heaviside Derivative] The Heaviside step function $H$ satisfies
  \begin{equation}
    H' = \delta
  \end{equation}
  as distributions on $\mathcal{S}' (\mathbb{R})$.
\end{theorem}

\begin{proof}
  For all $\phi \in \mathcal{S} (\mathbb{R})$,
  
  \begin{align}
    \langle H', \phi \rangle & = - \langle H, \phi' \rangle \\
    & = - \int_{- \infty}^{\infty} H (x) \phi' (x)  \hspace{0.17em} dx \\
    & = - \int_0^{\infty} \phi' (x)  \hspace{0.17em} dx \\
    & = - [\phi (x)]_0^{\infty} \\
    & = - (\lim_{x \to \infty} \phi (x) - \phi (0)) \\
    & = \phi (0) 
  \end{align}
  
  where the limit vanishes since $\phi \in \mathcal{S} (\mathbb{R})$ decays
  rapidly at infinity. Thus
  \begin{equation}
    \langle H', \phi \rangle = \phi (0) = \langle \delta, \phi \rangle
  \end{equation}
\end{proof}

\begin{theorem}
  [Integral of Delta] For any $a \in \mathbb{R}$ and $T \in \mathbb{R}$,
  \begin{equation}
    \int_{- \infty}^T \delta (t - a)  \hspace{0.17em} dt = H (T - a)
  \end{equation}
\end{theorem}

\begin{proof}
  Define
  \begin{equation}
    F (T) = \int_{- \infty}^T \delta (t - a)  \hspace{0.17em} dt
  \end{equation}
  Taking the distributional derivative with respect to $T$:
  \begin{equation}
    F' (T) = \frac{d}{dT}  \int_{- \infty}^T \delta (t - a)  \hspace{0.17em}
    dt = \delta (T - a)
  \end{equation}
  Since $F (- \infty) = 0$ and
  \begin{equation}
    F' (T) = \delta (T - a) = H'  (T - a)
  \end{equation}
  from the previous theorem, one has
  \begin{equation}
    F (T) = H (T - a) + C
  \end{equation}
  for some constant $C$. The boundary condition
  \begin{equation}
    F (- \infty) = 0 = H (- \infty) + C
  \end{equation}
  implies $C = 0$, thus
  \begin{equation}
    F (T) = H (T - a)
  \end{equation}
\end{proof}

\section{Delta of a Smooth Function}

\begin{theorem}
  [Delta under Change of Variables] Let $g : \mathbb{R} \to \mathbb{R}$ be
  continuously differentiable with isolated, simple zeros $\{x_i \}$ such that
  $g (x_i) = 0$ and $g' (x_i) \neq 0$. Then the identity
  \begin{equation}
    \delta (g (x)) = \sum_i \frac{\delta (x - x_i)}{|g' (x_i) |}
  \end{equation}
  holds in $\mathcal{S}' (\mathbb{R})$.
\end{theorem}

\begin{proof}
  For $\phi \in \mathcal{S} (\mathbb{R})$,
  \begin{equation}
    \langle \delta (g (x)), \phi \rangle = \int_{- \infty}^{\infty} \phi (x)
    \delta (g (x))  \hspace{0.17em} dx
  \end{equation}
  Near each zero $x_i$, where $g$ is locally monotone by the implicit function
  theorem, the change of variables $u = g (x)$ gives
  \begin{equation}
    \begin{array}{ll}
      \int_{I_i} \phi (x) \delta (g (x))  \hspace{0.17em} dx & = \int_{g
      (I_i)} \hspace{0.17em} \frac{\phi (g^{- 1} (u)) }{|g' (g^{- 1} (u)) |}
      \delta (u)  \hspace{0.17em} du\\
      & = \frac{\phi (x_i)}{|g' (x_i) |}
    \end{array}
  \end{equation}
  by the sifting property of $\delta$. Summing over all zeros yields
  \begin{equation}
    \langle \delta (g (x)), \phi \rangle = \sum_i \frac{\phi (x_i)}{|g' (x_i)
    |} = \left\langle \sum_i \frac{\delta (x - x_i)}{|g' (x_i) |}, \phi
    \right\rangle
  \end{equation}
  Since this holds for all $\phi \in \mathcal{S} (\mathbb{R})$, the
  distributional equality follows.
\end{proof}

\section{Counting Function for Level Crossings}

Let $x : \mathbb{R} \to \mathbb{R}$ be continuously differentiable, and fix $u
\in \mathbb{R}$. Assume the zeros of $g (t) \assign x (t) - u$ are isolated
and simple; that is, for every zero $t_i$,
\begin{equation}
  g' (t_i) = x' (t_i) \neq 0
\end{equation}
\begin{definition}
  \label{N}[Level Crossing Counting Function] Define the counting function
  \begin{equation}
    N (T) \assign \text{the number of zeros } t_i  \text{of } x (t) - u
    \text{with } t_i \leq T
  \end{equation}
\end{definition}

\begin{theorem}
  [Counting Function as Integral Over Delta] For every $T \in \mathbb{R}$,
  \begin{equation}
    N (T) = \int_{- \infty}^T |x' (t) | \delta (x (t) - u)  \hspace{0.17em} dt
  \end{equation}
\end{theorem}

\begin{proof}
  Using the delta change of variables theorem with
  \begin{equation}
    g (t) = x (t) - u
  \end{equation}
  one finds that
  
  \begin{align}
    |x' (t) | \delta (x (t) - u) & = |x' (t) |  \sum_i \frac{\delta (t -
    t_i)}{|x' (t_i) |} \\
    & = \sum_i |x' (t) | \frac{\delta (t - t_i)}{|x' (t_i) |} 
  \end{align}
  
  Since $x' (t_i) \neq 0$ by assumption, and $\delta (t - t_i)$ picks out the
  value at $t = t_i$,
  \begin{equation}
    \begin{array}{ll}
      |x' (t) | \delta (x (t) - u) & = \sum_i \frac{|x' (t_i) |}{|x' (t_i) |}
      \delta (t - t_i)\\
      & = \sum_i \delta (t - t_i)
    \end{array}
  \end{equation}
  Therefore,
  \begin{equation}
    \begin{array}{ll}
      \int_{- \infty}^T |x' (t) | \delta (x (t) - u)  \hspace{0.17em} dt & =
      \sum_i \int_{- \infty}^T \delta (t - t_i)  \hspace{0.17em} dt\\
      & = \sum_{t_i \leq T} 1\\
      & = N (T)
    \end{array}
  \end{equation}
  
\end{proof}

\begin{theorem}
  [Counting Function as Sum of Heaviside Steps] The counting function
  (\ref{N}) is given by
  \begin{equation}
    N (T) = \sum_i H (T - t_i) \forall T \in \mathbb{R}
  \end{equation}
  where the sum runs over all zero crossing times $t_i$.
\end{theorem}

\begin{proof}
  By definition of the Heaviside function,
  \begin{equation}
    H (T - t_i) = 1
  \end{equation}
  if and only if $T \geq t_i$, and
  \begin{equation}
    H (T - t_i) = 0
  \end{equation}
  otherwise. Therefore,
  \begin{equation}
    \begin{array}{ll}
      \sum_i H (T - t_i) & = \sum_{t_i \leq T} 1\\
      & = N (T)
    \end{array}
  \end{equation}
  
\end{proof}

\begin{theorem}
  [Equivalence of Representations] The delta integral representation and the
  Heaviside step sum representation are equivalent:
  \begin{equation}
    \int_{- \infty}^T |x' (t) | \delta (x (t) - u)  \hspace{0.17em} dt =
    \sum_i H (T - t_i)
  \end{equation}
\end{theorem}

\begin{proof}
  This follows immediately from the two previous theorems, since both
  expressions equal $N (T)$.
\end{proof}

\end{document}
