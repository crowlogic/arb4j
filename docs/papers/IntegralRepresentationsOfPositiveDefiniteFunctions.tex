\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{enumitem}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}

\title{INTEGRAL REPRESENTATIONS OF POSITIVE DEFINITE FUNCTIONS}
\author{A. DEVINATZ\footnote{Parts of this paper are taken from the author's Harvard dissertation. I would like to express my appreciation to Prof. N. Aronszajn for allowing me to read his paper Theory of reproducing kernels \cite{aronszajn2} before it was published.}}
\date{}

\begin{document}

\maketitle

\section{Introduction}

During the last decade a school of Russian mathematicians including Krein \cite{krein1,krein2,krein3}\footnote{Numbers in brackets refer to the references at the end.}, Krein and Krasnoselskiï \cite{krein-krasnoselskii}, Livshitz \cite{livshitz}, and Neumark \cite{neumark} have made contributions to the theory of moments and related problems\footnote{For an extensive bibliography of such problems see Shohat and Tamarkin \cite{shohat-tamarkin}.} by the methods of operators in Hilbert space. Before this Carleman \cite{carleman} had used the theory of integral equations to develop the theory and Stone \cite{stone} had connected the theory with infinite Jacobi matrices, which method has been elaborated by various other authors.

In this paper we make systematic use of the theory of reproducing kernels, as developed by N. Aronszajn \cite{aronszajn1,aronszajn2}, to obtain integral representations for positive definite functions. A function $K(x, y)$, defined over a Cartesian product set $E \times F$, was termed by E. H. Moore a positive Hermitian matrix if for every finite set, $\{a_1, \ldots, a_n\}$, of complex numbers and points $\{y_1, \ldots, y_n\} \subset E$, 
\begin{equation}
\sum_{i,j=1}^n a_i \overline{a_j} K(y_i, y_j) \geq 0.
\label{eq:positive-hermitian}
\end{equation}
This terminology has been shortened by N. Aronszajn \cite{aronszajn2} to positive matrix, which we shall use here.

A positive definite function shall be defined as a complex-valued function $f(x, y)$, with domain a set $E = S \times G$, where $S$ is a semi-group and $G$ is a group, such that $K((x_1, y_1), (x_2, y_2)) = f(x_1 - x_2, y_1 - y_2^{-1})$ is a positive matrix.

Here, we shall be concerned only with the case in which $S$ is a semi-group and $G$ is a group in Euclidean space. Our main theorem (Theorem~\ref{thm:main}) contains extensions, to higher dimensions, of results which have already been obtained, in a different way, for the one-dimensional case and also contains results which are new.

The readers of this paper are expected to have some acquaintance with the papers of N. Aronszajn \cite{aronszajn1,aronszajn2} and with the general theory of Hilbert space. The notations used in this paper for the general theory of Hilbert space have been taken from the excellent book by Béla v. Sz. Nagy \cite{nagy}.

\section{Preliminaries}
\label{sec:preliminaries}

If $K(x, y)$ is a positive matrix (p.m.), defined on $E \times E$, then there exists a Hilbert space $\mathcal{J}$, of functions defined on $E$, for which $K(x, y)$ acts as a reproducing kernel (r.k.) (i.e. $f(y) = (f(x), K(x, y))$ for every $f \in \mathcal{J}$). The space $\mathcal{J}$ will be called a reproducing kernel space (r.k.s.). $\mathcal{J}$ is the closure of the set $\mathcal{J}'$ of functions of the form $g(x) = \sum_{i=1}^n a_i K(x, y_i)$, where $a_i$, $i = 1, \ldots, n$, is a complex number. In the future $\mathcal{J}$ will always denote the r.k.s. of the p.m. we are considering at that time and $\mathcal{J}'$ will always denote the set as given above for that p.m.

Aronszajn \cite{aronszajn2} has shown that if $T$ is a bounded linear operator defined on $\mathcal{J}$, then there exists a function $M(x, y)$, defined over $E \times E$, which, for every $y \in E$, belongs to $\mathcal{J}$ and such that for every $f \in \mathcal{J}$, $Tf(y) = (f(x), M(x, y))$. The function $M(x, y)$ is given by $T^*K(x, y)$. The operator $T$ is said to correspond to the function $M(x, y)$ and we shall denote this by $T \leftrightarrow M(x, y)$.

The following facts are given by Aronszajn \cite{aronszajn2} and may be checked without too much difficulty:
\begin{enumerate}[label=(\alph*)]
\item $T^* \leftrightarrow M^*(x,y) = M(y,x)$.
\item If $T_1 \leftrightarrow M_1(x, y)$, $T_2 \leftrightarrow M_2(x, y)$, then
\begin{equation}
T_1T_2 \leftrightarrow M(x, y) = (M_1(z, y), M_2^*(z, x)).
\label{eq:operator-product}
\end{equation}
\item If $T \leftrightarrow M(x, y)$, then the symmetry of $T$ is equivalent to the Hermitian symmetry of $M(x, y)$ (i.e. $M(y, x) = \overline{M(x, y)}$).
\item If $T \leftrightarrow M(x, y)$, then $T$ is positive if and only if $M(x, y)$ is a p.m.
\end{enumerate}

We find it necessary to extend the concept of correspondence between operators and kernels to unbounded operators. Let $T$ denote an arbitrary operator in $\mathcal{J}$, $D_T$ its domain, and $M(x, y) \in \mathcal{J}$ for every $y$ in $E$.

\begin{definition}
\label{def:correspondence}
$T$ is said to correspond to the kernel $M(x, y)$, in symbol $T \sim M(x, y)$, if for every $f \in D_T$, $Tf(y) = (f(x), M(x, y))$. $T$ is said to correspond to $M(x, y)$ in the maximal sense, in symbol $T \doteq M(x, y)$, if $D_T$ consists of all the elements $f$ in $\mathcal{J}$ such that $(f(x), M(x, y))$ is again an element of $\mathcal{J}$, when considered as a function of $y$ and for every $f \in D_T$, $Tf(y) = (f(x), M(x, y))$.
\end{definition}

Let us notice that, according to this definition, to a given kernel there may correspond many operators. However, to any given kernel there exists one and only one linear operator which corresponds to it in the maximal sense. Bounded linear operators always correspond to kernels in the maximal sense.

The question arises as to which operators correspond to kernels. To answer this we consider an operator $T_1$ with $D_{T_1} \subset \mathcal{J}$. An operator $T_2$ is said to be adjoint to $T_1$, in symbol $T_1 \perp T_2$, if for every $f \in D_{T_1}$ and $g \in D_{T_2}$ we have $(T_1f, g) = (f, T_2g)$\footnote{Cf. Stone \cite{stone}, p. 41.}.

\begin{theorem}
\label{thm:correspondence}
Necessary and sufficient conditions that an operator $T_1$ corresponds to the kernel $M(x, y)$ are that there exists a $T_2$ such that $T_1 \perp T_2$, the r.k. $K(x, y)$ of $\mathcal{J}$ belongs to $D_{T_1}$ for every $y$ of $E$, and $M(x, y) = T_2K(x, y)$. If $T \doteq M(x, y)$, a sufficient condition that $T$ have an inverse is that the linear manifold determined by the functions $M(x, y)$ be dense in $\mathcal{J}$. If $T \doteq M(x, y)$, the condition is also necessary.
\end{theorem}

\begin{proof}
That the conditions of the first statement are sufficient is quite obvious. For $T_1f(y) = (T_1f(x), K(x, y)) = (f(x), T_2K(x, y))$ and consequently $T_1 \sim M(x, y) = T_2K(x,y)$.

For the necessity, we suppose $f \in D_{T_1}$ and we have $T_1f(y) = (f(x), M(x, y)) = (T_1f(x), K(x, y))$. Consequently, we define a transformation $T_2$, with $D_{T_2}$ equal to the class $\{K(x, y)\}$, by the condition $T_2K(x, y) = M(x, y)$. Since $T_1 \perp T_2$ the necessity is proved.

To prove the sufficiency of the second statement we suppose $Tf_1 = Tf_2$. It follows that $Tf_1(y) - Tf_2(y) = (f_1(x) - f_2(x), M(x, y)) = 0$. Since the linear manifold determined by the class $\{M(x, y)\}$ is dense in $\mathcal{J}$ we must have $f_1 = f_2$.

For the third statement, we notice that if the linear manifold determined by the class $\{M(x, y)\}$ is not dense in $\mathcal{J}$, there exists a nonzero $f \in \mathcal{J}$ such that $(f(x), M(x, y)) = 0$. Since $T \doteq M(x, y)$, $f \in D_T$ and $Tf = 0$. This contradicts the fact that $T$ has an inverse.
\end{proof}

In §\ref{sec:main-theorem} we have occasion to consider the restriction of a r.k. $K(x, y)$, defined over a set $E \times E$, to a set $E_1 \times E_1 \subset E \times E$. The restriction of $K(x, y)$ to $E_1 \times E_1$ is of course a p.m. $K_1(x, y)$ and the r.k.s. $\mathcal{J}_1$ which is associated with $K_1(x, y)$ is obtained in the following way. Let $\mathcal{J}_0$ be the subspace of all $f \in \mathcal{J}$ such that $f(x) = 0$ for $x \in E_1$. If $\mathcal{J}_0^{\perp}$ is the orthogonal complement of $\mathcal{J}_0$, then to every $f \in \mathcal{J}$ there exists an $f_0 \in \mathcal{J}_0^{\perp}$ such that the restriction of $f$ and $f_0$ to $E_1$ are the same. Consequently, define $\mathcal{J}_1$ as the set of functions in $\mathcal{J}$ restricted to $E_1$ with the norm of any element $f_1 \in \mathcal{J}_1$ given by the norm of that element $f_0$ in $\mathcal{J}_0^{\perp}$ for which the restriction of $f_0$ to $E_1$ is $f_1$. The pertinent theorem here is as follows.

\begin{theorem}[A]
\label{thm:restriction}
If $K$ is the reproducing kernel of the space $\mathcal{J}$ of functions defined on the set $E$ with norm $\|\cdot\|$, then $K$ restricted to the subset $E_1 \times E_1 \subset E \times E$ is the reproducing kernel of the class $\mathcal{J}_1$ of all restrictions of functions of $\mathcal{J}$ to the subset $E_1$. For any such restriction, $f_1 \in \mathcal{J}_1$, the norm $\|f_1\|_1$ is the minimum of $\|f\|$ for all $f \in \mathcal{J}$ whose restriction to $E_1$ is $f_1$.
\end{theorem}

\section{Semi-bounded and real operators}
\label{sec:semi-bounded}

In this section we wish to extend a theorem of Aronszajn to semi-bounded operators and, for spaces which correspond to real spaces\footnote{These are spaces for which the r.k. is real. Cf. Aronszajn \cite{aronszajn2}, p. 354.}, to unbounded operators. Following Aronszajn we write $M_1(x, y) \leq_K M_2(x, y)$ if $M_2(x, y) - M_1(x, y)$ is a p.m. In the following two theorems $K(x, y)$ is the r.k. of the r.k.s. $\mathcal{J}$.

\begin{theorem}
\label{thm:semi-bounded}
Let $M(x, y)$ be a Hermitian symmetric function (i.e. $M(x, y) = \overline{M(y, x)}$) defined over $E \times E$ which belongs to $\mathcal{J}$ when considered as a function of $x$, for every $y \in E$.
\begin{enumerate}[label=(\alph*)]
\item If $T \doteq M(x, y)$, then $T^*$ and $T^{**}$ exist and $T^{**} = T$. $T^*$ is a symmetric operator and is the closure of the restriction of $T$ to $\mathcal{J}'$; every self-adjoint operator which corresponds to $M(x, y)$ is an extension of $T^*$. A necessary and sufficient condition that $T$ be self-adjoint is that the linear manifold determined by the class $\{M(x, y) + iK(x, y)\}$ is dense in $\mathcal{J}$.
\item A necessary and sufficient condition that there exists a self-adjoint operator $H \sim M(x, y)$ which is bounded below (above) by the finite number $c$ is that $M(x, y) \geq_K cK(x, y)$ ($M(x, y) \leq_K cK(x, y)$). A necessary and sufficient condition that there exists a self-adjoint $H \doteq M(x, y)$ with lower bound $\geq \alpha > -\infty$ and upper bound $\leq \beta < +\infty$ is that
\begin{equation}
\alpha K(x, y) \leq_K M(x, y) \leq_K \beta K(x, y).
\label{eq:bounded-operator}
\end{equation}
\end{enumerate}
\end{theorem}

\begin{proof}
To prove (a) we consider the operator $T \doteq M(x, y)$. From the fact that $M(z,y) = (K(x, z), M(x, y)) = \overline{M(y, z)}$ we conclude that $(K(x, z), M(x, y))$ is an element of $\mathcal{J}$, when considered as a function of $y$, for every $z \in E$, and consequently $\mathcal{J}' \subset D_T$. Therefore, $D_T$ is dense in $\mathcal{J}$, which implies $T^*$ exists.

Since $T \doteq M(x, y)$, it follows that $T$ is a closed linear operator and from the fact that $D_T$ is dense in $\mathcal{J}$, it follows that $T^{**} = T$\footnote{This remark is due to the referee. It slightly simplifies the original proof. For the pertinent theorem see Nagy \cite{nagy}, p. 29.}. Therefore,
\begin{align}
T^* &\sim M^*(x, y) = \overline{TK(x,y)} = (TK(z, y), K(z, x)) \nonumber \\
&= (K(z, y), T^*K(z, x)) = (M(z, x), K(z, y)) = M(y, x) = \overline{M(x, y)}.
\label{eq:adjoint-correspondence}
\end{align}

This shows $T^* \subset T$ and consequently $T^*$ is a closed symmetric operator.

Let now $T'$ be the restriction of $T$ to $\mathcal{J}'$. We have, by Theorem~\ref{thm:correspondence}, $T' \subset T^* \subset T'^{**}$. Therefore $T'^* \subset T \subset T'^{**}$, which implies $T'^{**}$ exists. Since $T' \subset T'^{**}$, we get, by Theorem~\ref{thm:correspondence}, $T'^{**} \sim M(x, y)$. It follows that $T = T'^{**}$. If $T''$ is the closure of $T'$, then by general Hilbert space theory, $T'' = T'^{**}$. This shows that $T'' = T^*$. Further, if $H$ is any self-adjoint operator such that $H \sim M(x, y)$, then $H \subset T$ and consequently $T^* \subset H$.

Consider now the Cayley transform, $V$, of $T^*$. The domain of $V$ consists of elements of the form $(T^* + iI)g$, where $g \in D_{T^*}$. Since $T^*$ is the closure of $T'$, the domain of $V$ is the closure of the linear manifold determined by the set $\{M(x, y) + iK(x, y)\}$. Consequently, $T^*$ is self-adjoint if and only if the linear manifold determined by this set is dense in $\mathcal{J}$. Since $T^{**} = T$, $T^*$ is self-adjoint if and only if $T$ is self-adjoint.

Let us now prove part (b) for the semi-bounded case. The bounded case will follow by similar reasoning. Suppose then that $H$ is self-adjoint, $H \sim M(x, y)$, and $H \geq cI$. Then, the self-adjoint operator $H_1 = H - cI$ is positive. Since $H_1$ is self-adjoint and $H_1 \sim M_1(x, y) = M(x, y) - cK(x, y)$, by Theorem~\ref{thm:correspondence}, $\mathcal{J}' \subset D_{H_1}$ and consequently,
\begin{align}
\sum_{i,j=1}^n a_i \overline{a_j} M_1(y_j, y_i) &= \sum_{i,j=1}^n a_i \overline{a_j} (H_1K(x, y_j), K(x, y_i)) \nonumber \\
&= \left(H_1\sum_{i=1}^n a_i K(x, y_i), \sum_{i=1}^n a_i K(x, y_i)\right) \geq 0.
\label{eq:positivity}
\end{align}

This establishes the necessity of (b).

To prove the sufficiency of (b) suppose that $g \in \mathcal{J}'$ is given by $g(x) = \sum_{i=1}^n a_i K(x, y_i)$. If $T \doteq M(x, y)$, then by hypothesis,
\begin{align}
(T^*g, g) &= \sum_{i,j=1}^n a_i \overline{a_j} T^*K(y_j, y_i) = \sum_{i,j=1}^n a_i \overline{a_j} M(y_j, y_i) \nonumber \\
&\geq c\sum_{i,j=1}^n a_i \overline{a_j} K(y_j, y_i) = c(g,g).
\label{eq:lower-bound}
\end{align}

By part (a) we know that for any $f \in D_{T^*}$ there exists a sequence $\{f_n\} \subset \mathcal{J}'$ such that $f_n \to f$ and $T^*f_n \to T^*f$. Therefore, for any $f \in D_{T^*}$, $(T^* f, f) \geq c(f, f)$, which shows that $T^*$ is bounded below by $c$. Since $T^*$ is closed and symmetric, by a well known theorem of the general theory of Hilbert space, it may be extended to a self-adjoint operator $H$ with the same lower bound\footnote{Cf. Nagy \cite{nagy}, p. 35.}.
\end{proof}

\begin{theorem}
\label{thm:real-operators}
Let $\mathcal{J}$ be a space which corresponds to a real space\footnote{These are spaces for which the r.k. is real. Cf. Aronszajn \cite{aronszajn2}, p. 354.}. Let $M(x, y)$ be a real symmetric function defined over $E \times E$, which for every $y \in E$ belongs to $\mathcal{J}$, when considered as a function of $x$.
\begin{enumerate}[label=(\alph*)]
\item The same statement as in Theorem~\ref{thm:semi-bounded}(a) is true here.
\item There exists a real self-adjoint operator $H$ such that $H \sim M(x, y)$.
\end{enumerate}
\end{theorem}

\begin{proof}
The proof of part (a) is the same as in Theorem~\ref{thm:semi-bounded}.

To prove (b), we notice that since $\mathcal{J}$ corresponds to a real space, $g \in \mathcal{J}$ implies $\overline{g} \in \mathcal{J}$. Consider then $T \doteq M(x, y)$; $T$ is a real operator. For suppose $g \in D_T$; then $Tg(y) = (g(x), M(x, y))$ is an element of $\mathcal{J}$ and consequently $\overline{Tg(y)} \in \mathcal{J}$.

Further,
\begin{equation}
\overline{Tg(y)} = \overline{(g(x), M(x, y))} = (\overline{g(x)}, M(x, y)) = T\overline{g}(y).
\label{eq:real-operator}
\end{equation}

Since $T$ is real $T^*$ is a real closed symmetric operator and consequently may be extended to a real self-adjoint operator\footnote{Cf. Nagy \cite{nagy}, p. 40.} $H$, with $H \sim M(x, y)$.
\end{proof}

\section{Positive matrices represented by integrals}
\label{sec:integral-representation}

N. Aronszajn \cite{aronszajn2} has shown that given any p.m. $K(x, y)$, for which $\mathcal{J}$ is either a finite-dimensional space or a separable Hilbert space, there always exists a resolution of the identity $\{E_\lambda\}$, a set of functions $\{k(x, \lambda)\}$, and an element $f_0 \in \mathcal{J}$ such that $\int |k(x, \lambda)|^2 d(E_\lambda f_0, f_0) < \infty$\footnote{Here and in what follows there will be no loss in generality if we assume that the functions being integrated are Borel measurable and finite at every real number so that the statements we shall make about integration with respect to a resolution of the identity have meaning. Absence of limits of integration shall always indicate that the integral is being taken from $-\infty$ to $+\infty$.} and
\begin{equation}
K(x, y) = \int k(x, \lambda) \overline{k(y, \lambda)} d(E_\lambda f_0, f_0).
\label{eq:aronszajn-representation}
\end{equation}

The problem in which we are interested here is to determine the space $\mathcal{J}$ associated with the p.m. given by the integral $A(x, y) = \int a(x, \lambda) \overline{a(y, \lambda)} dV(\lambda)$, where $\int |a(x, \lambda)|^2 dV(\lambda) < \infty$ and $V(\lambda)$ is a bounded monotone increasing function which may be normed by the relations $V(-\infty) = 0$, $V(+\infty) = V(\lambda)$. The function $V(\lambda)$ gives rise to a measure and we are considering the integral in the Lebesgue-Radon-Stieltjes sense.

Designate by $L^2_\mathcal{C}(V)$ the Hilbert space which consists of equivalence classes of complex-valued measurable functions $f(\lambda)$ (with respect to the measure generated by $V$) such that $\int |f(\lambda)|^2 dV(\lambda) < \infty$. We shall designate any equivalence class in $L^2_\mathcal{C}(V)$ by any one of its elements. An inner product in $L^2_\mathcal{C}(V)$ is then of course given by $(f, g) = \int f(\lambda) \overline{g(\lambda)} dV(\lambda)$.

Let $L_0$ be the subspace of $L^2_\mathcal{C}(V)$ which consists of those elements $\phi$ such that $\int a(x, \lambda) \phi(\lambda) dV(\lambda) = 0$ for every $x \in E$. Let $L_0^{\perp}$ be the orthogonal complement of $L_0$.

\begin{theorem}
\label{thm:integral-space}
Let $A(x, y)$ have an integral representation as above. Then, the space $\mathcal{F}$ associated with $A(x, y)$ is given by all functions of the form
\begin{equation}
f(x) = \int a(x, \lambda) \phi(\lambda) dV(\lambda), \quad \phi \in L_0^{\perp}(V).
\label{eq:function-representation}
\end{equation}
Further,
\begin{equation}
\|f\|^2 = \min \int |\phi(\lambda)|^2 dV(\lambda),
\label{eq:norm-representation}
\end{equation}
where the minimum is taken over all $\phi \in L_0^{\perp}(V)$ such that $f(x) = \int a(x, \lambda) \phi(\lambda) dV(\lambda)$.

Necessary and sufficient conditions that $L_0$ consists of the zero element only are that there exists a resolution of the identity $\{E_\lambda\}$ over $\mathcal{F}$ and an element $f_0 \in \mathcal{F}$ such that $V(\lambda) = (E_\lambda f_0, f_0)$ and $A(x, y) = \int \overline{a(y, \lambda)} dE_\lambda f_0(x)$.
\end{theorem}

\begin{proof}
Consider the space $\mathcal{J}_1$ given by all functions of the form $f(x) = \int a(x, \lambda) F(\lambda) dV(\lambda)$, with $F(\lambda) \in L^2_\mathcal{C}$. If $g(x) = \int a(x, \lambda) G(\lambda) dV(\lambda)$, with $G(\lambda) \in L^2_\mathcal{C}$, define an inner product by $(f, g) = \int F(\lambda) \overline{G(\lambda)} dV(\lambda)$. This defines $(f, g)$ uniquely.

By the very definition of the class $L_0$ it is clear that $a(x, \lambda) \in L_0^{\perp}$ for every $x \in E$. Therefore, $A(x, y) = \int a(x, \lambda) \overline{a(y, \lambda)} dV(\lambda)$ belongs to $\mathcal{J}_1$ for all $y$ and if $f \in \mathcal{J}_1$, $f(y) = \int a(y, \lambda) F(\lambda) dV(\lambda) = (f(x), A(x, y))$. Since $\mathcal{J}' \subset \mathcal{J}_1$ and $A(x, y)$ acts as a r.k. for $\mathcal{J}$ and $\mathcal{J}_1$ we must have $\mathcal{J}_1 = \mathcal{J}$. The first part of our theorem is now an immediate consequence of this fact.

To prove the necessity of the second part of the theorem we suppose $L_0$ consists only of the zero element. If $g(x) = \int a(x, \lambda) G(\lambda) dV(\lambda)$, with $G(\lambda) \in L^2_\mathcal{C}(V)$, define
\begin{equation}
E_T g(x) = \int a(x, \lambda) G_T(\lambda) dV(\lambda),
\label{eq:resolution-definition}
\end{equation}
where
\begin{equation}
G_T(\lambda) = \begin{cases}
G(\lambda) & \text{for } -\infty \leq \lambda \leq T, \\
0 & \text{for } T < \lambda \leq \infty.
\end{cases}
\label{eq:cutoff-function}
\end{equation}

It is easy to verify that $\{E_T\}$ is a resolution of the identity. Now, if $F_0(\lambda) = 1$, then since $V(\lambda)$ is bounded, $F_0(\lambda) \in L^2_\mathcal{C}(V)$. Consequently, if we set $f_0(x) = \int a(x, \lambda) F_0(\lambda) dV(\lambda)$, then $(E_T f_0, f_0) = V(\lambda)$ and $A(x, y) = \int \overline{a(y, \lambda)} dE_\lambda f_0(x)$.

To prove the sufficiency, we suppose that $V(\lambda) = (E_\lambda f_0, f_0)$. Let $\phi(\lambda) \in L_0$ and consider the normal operator $T = \int \phi(\lambda) dE_\lambda$. We know that $f_0 \in D_T$ since $\int |\phi(\lambda)|^2 d(E_\lambda f_0, f_0) < \infty$. Consider also the Abelian system of normal operators\footnote{An Abelian system of normal operators is a set of normal operators which commute with each other.} $T_x = \int a(x, \lambda) dE_\lambda$. It is clear that $f_0 \in D_{T_x}$ and further, by hypotheses, $T_x f_0(y) = A(x, y)$. We have then, for every $x \in E$, $(Tf_0, T_x f_0) = \int a(x, \lambda) \phi(\lambda) d(E_\lambda f_0, f_0) = 0$. It follows that since the linear manifold determined by the set $\{T_x f_0\}$ is dense in $\mathcal{J}$, $Tf_0 = 0$. Consequently, if $\lambda_1 < \lambda_2$, $((E_{\lambda_2} - E_{\lambda_1})Tf_0, f_0) = \int_I \phi(\lambda) d(E_\lambda f_0, f_0) = 0$, where $I$ is the half open interval $(\lambda_1, \lambda_2]$. This means that $\phi(\lambda)$ must be zero almost everywhere (with respect to the measure generated by $V(t)$).
\end{proof}

\section{The main theorem}
\label{sec:main-theorem}

In this section we shall work with special types of positive matrices, namely positive definite functions which we described in the introduction. Before we state and prove our main theorem we shall say a few words about the notations used.

We shall designate vectors in an $n$-dimensional Euclidean space, $E_n(u)$, by the lower case latin letters $a, b, c, d$ and $s, t, u, x, y$ and the components by corresponding latin letters with superscripts (e.g. $x^{(n)} = (x^{(1)}, x^{(2)}, \ldots, x^{(n)})$). The "unit" vectors $u_k$ will be those for which $u_k^{(i)} = \delta_{jk}$, where $\delta_{jk}$ is the Kronecker symbol. Real numbers will be designated either by the lower case latin letters given above the superscripts (as for the components) or by lower case greek letters. The scalar or dot product of two vectors we shall designate by $x \cdot y$ and shall write $x \geq y$ if $x^{(i)} \geq y^{(i)}$ for $i = 1, \ldots, n$. If $t$ is the vector $t = (t^{(1)}, \ldots, t^{(n)})$, by $t^s$ we shall mean the product $\prod_{i=1}^n (t^{(i)})^{s^{(i)}}$.

If $V(t) = V(t^{(1)}, \ldots, t^{(n)})$ is a real-valued function with domain $E_n$, we shall say that $V(t)$ is monotone increasing if for any interval $I$, defined by all $t$ such that $a < t < b$, we have
\begin{equation}
\nu(I) = \sum_{\epsilon_1, \ldots, \epsilon_{n-1}, 2} (-1)^{\epsilon_1 + \cdots + \epsilon_n} V(c^{(\epsilon_1)}, \ldots, c^{(\epsilon_n)}) \geq 0,
\label{eq:monotone-increasing}
\end{equation}
where $c^{(i)} - a^{(i)}$, $c^{(i)} = b^{(i)}$. The interval function $\nu(I)$ is an additive function of an interval and consequently it defines a corresponding Lebesgue-Radon-Stieltjes measure\footnote{For a discussion of such functions see J. V. Neumann \cite{neumann}, pp. 160-172.}. When we write $\int_Q F(t) dV(t)$ we shall mean the Lebesgue-Radon-Stieltjes integral with respect to this measure over some measurable set $Q$. When we write $\int_a^b F(t) dV(t)$ we shall always mean that the integral is taken over the closed interval $a \leq t \leq b$. We shall say that two monotone increasing functions are substantially equal if they both generate the same measure function. The spectrum of the function $V(t)$ is the set of points $t \in E_n$ such that $\nu(I) \neq 0$ for every open interval $I$ containing $t$.

In §\ref{sec:semi-bounded} we used the notation $M_1(x, y) \leq_K M_2(x, y)$. In this section we shall have occasion to use the condition $\alpha K(x, y) \leq_K M(x, y) \leq_K \beta K(x, y)$. Let us agree that if $\alpha = -\infty$ or $\beta = +\infty$, then the respective inequalities $\alpha K(x, y) \leq_K M(x, y)$ or $M(x, y) \leq_K \beta K(x, y)$ are always true regardless of the functions $K$ and $M$.

For the following considerations we find it convenient to consider a certain subspace of the $(n + m)$-dimensional unitary space with elements $w = (w^{(-1)}, \ldots, w^{(-n+m)})$, $w^{(j)}$, $j = 1, \ldots, n + m$, a complex number. As before the scalar or dot product of two such vectors $v$ and $w$ will be indicated by $v \cdot w$. We first consider the vectors $x = (x^{(1)}, \ldots, x^{(n)}, 0, \ldots, 0)$ and $y = (0, \ldots, 0, y^{(n+1)}, \ldots, y^{(n+m)})$. We shall then consider the subspace which consists of elements of the form $z = x + iy$, $i = (-1)^{1/2}$. Using the terminology of the complex number system we shall call $x$ the real part of $z$, $y$ the imaginary part of $z$, and write $R(z) = x$, $I(z) = y$, $\overline{z} = x - iy$.

In the theorem which follows we use the following notation: $a = (a^{(1)}, \ldots, a^{(n)}, -d^{(n+1)}, \ldots, -d^{(n+m)})$, $b = (b^{(1)}, \ldots, b^{(n)}, d^{(n+1)}, \ldots, d^{(n+m)})$, $c = (c^{(1)}, \ldots, c^{(n)}, 0, \ldots, 0)$, $d = (0, \ldots, 0, d^{(n+1)}, \ldots, d^{(n+m)})$, $s = (0, \ldots, 0, s^{(n+1)}, \ldots, s^{(n+m)})$, $t = (t^{(1)}, \ldots, t^{(n+m)})$, where $b^{(i)} \geq 0$ and $a^{(i)} \leq b^{(i)}$. The numbers $a^{(i)}$ may take on the value $-\infty$, $b^{(i)}$ and $d^{(i)}$ the value $+\infty$, and $-\infty \leq c^{(i)} < 0$. The numbers $m$ and $n$ may take on any positive value or 0. The vector $z$ shall be as described above.

\begin{theorem}
\label{thm:main}
Let $f(z)$ be a continuous complex-valued function defined for $R(z) > c$ and $-\infty < I(z) < \infty$. Necessary and sufficient conditions that there exists a bounded monotone increasing function $V(t)$ whose spectrum is contained in the interval $a \leq t \leq b$ and such that
\begin{equation}
f(z) = \int_a^b e^{iz \cdot t} dV(t)
\label{eq:main-representation}
\end{equation}
are:
\begin{enumerate}
\item $f(z_1 + z_2) \geq_0$.
\item $e^{a^{(k)} u_k} f(z_1 + z_2) \leq_K f(z_1 + z_2 + u_k) \leq_K e^{b^{(k)} u_k} f(z_1 + z_2)$, for $k = 1, 2, \ldots, n$.
\item There exists a sequence $s_r \to \infty$ such that $s_r^{(k)} > 0$ if $d^{(k)} < \infty$, $s_r^{(k)} = 0$ if $d^{(k)} = \infty$, $s_r^{(k)} d^{(k)} < \pi$\footnote{Define $0 \cdot \infty = 0$}, and, for $r = 1, 2, \ldots$, and, $k = n+1, \ldots, n+m$,
\begin{equation}
f(z_1 + z_2 - is_r \cdot u_k) + f(z_1 + z_2 + is_r \cdot u_k) \geq_K 2\cos(s_r d^{(k)}) f(z_1 + z_2).
\label{eq:cosine-condition}
\end{equation}
\end{enumerate}

If there exists another bounded monotone function $V_1(t)$ whose spectrum is contained in the interval $a \leq t \leq b$ and which satisfies \eqref{eq:main-representation}, then $V_1(t)$ and $V(t)$ are substantially equal.
\end{theorem}

The proof of this theorem will be constructed from a number of lemmas. In the first five of the following lemmas we shall be working in the 1-dimensional case.

\begin{lemma}
\label{lem:one-dimensional}
Let $f(m)$ be a function defined on the positive integers and zero. Necessary and sufficient conditions that there exists a bounded monotone increasing function, $V(t)$, whose spectrum is contained in the interval $a \leq t \leq b$ ($a$ may take the value $(-\infty)$, $b$ the value $(+\infty)$) and such that
\begin{equation}
f(m) = \int_a^b t^m dV(t)
\label{eq:moment-representation}
\end{equation}
are:
\begin{enumerate}
\item $f(m+n) \geq_0$.
\item $a \cdot u_1 f(m+n) \leq_K f(m+n+1) \leq_K b \cdot u_1 f(m+n)$.
\end{enumerate}

If $T \leftrightarrow f(m+n+1)$, the transformation $T^*$ has either the deficiency index $(1, 1)$ or $(0, 0)$. In case the deficiency index is $(0, 0)$ the function $V(t)$ is substantially unique.
\end{lemma}

\begin{proof}
The necessity of conditions (1) and (2) is quite clear.

To prove the sufficiency of these conditions we note that since $f(m+n)$ and $f(m+n+1)$ are real, then by either Theorem~\ref{thm:semi-bounded} or Theorem~\ref{thm:real-operators} there exists a self-adjoint operator $H \sim f(m+n+1)$ such that $a \cdot u_1 I \leq H \leq b \cdot u_1 I$, where $I$ is the identity operator. Let $\{E_t\}$ be the canonical resolution of the identity which corresponds to $H$. We may then write
\begin{equation}
H^m = \int_a^b t^m dE_t
\label{eq:spectral-representation}
\end{equation}
for any integer $m$.

By Theorem~\ref{thm:correspondence}, $\mathcal{J}' \subset D_H$. Further, since $H f(p+q) \in \mathcal{J}'$ for every $q$, it follows that $\mathcal{J}' \subset D_{H^m}$ and that $H^m f(p+q) = f(p+q+m)$. Consequently, since $f(p+q)$ is a r.k., we have
\begin{equation}
f(m) = (H^m f(p), f(p)) = \int_a^b t^m d(E_t f, f).
\label{eq:moment-formula}
\end{equation}

This completes the proof of the first part of the lemma\footnote{The proof of representation presents familiar arguments in the application of Hilbert space theory to moment problems. Cf. Krein and Krasnoselskiï \cite{krein-krasnoselskii}. We give the proof here for completeness.}.

To prove the second part of the lemma we note that the deficiency spaces of $T^*$ are given respectively by the elements $g$ and $h$ of $\mathcal{J}$ for which $Tg = ig$ or $Th = -ih$. Since $T^*$ is real, the dimensions of the deficiency spaces must be the same. For the case where $Tg = ig$ we get $g(m) = i^m g(0)$. This shows that the deficiency index can at most be $(1,1)$.

Suppose now that the deficiency index of $T^*$ is $(0, 0)$, that is, $T$ is self-adjoint. We wish to show that the $V(t)$ of the lemma is substantially unique. Suppose then that $V(t)$ is such a function and $f(m)$ has the representation
\begin{equation}
f(m) = \int t^m dV(t).
\label{eq:alternative-representation}
\end{equation}

We may further suppose, without loss of generality, that $V(t)$ is normed by the conditions $V(t+0) = V(t)$ and $V(-\infty) = 0$.

By Theorem~\ref{thm:integral-space} we know that $L^2_\mathcal{C}(V)$ may be written as $L^2_\mathcal{C}(V) = L_0 \oplus L_0^{\perp}$ and that every element $g$ of $\mathcal{J}$ is given by
\begin{equation}
g(m) = \int t^m G(t) dV(t),
\label{eq:function-integral}
\end{equation}
where $G(t) \in L_0^{\perp}$. Consider the class $D_H$ of elements $G(t) \in L_0^{\perp}$ such that $tG(t) \in L_0^{\perp}$. By means of the integral in \eqref{eq:function-integral} this class $D$ gives rise to a class $D_H \subset \mathcal{J}$ which certainly contains the linear manifold $\mathcal{J}'$.

If $g \in D_H$ is given by \eqref{eq:function-integral}, define the operator $H$ by the relation
\begin{equation}
Hg(m) = \int t^m \cdot t \cdot G(t) dV(t).
\label{eq:operator-definition}
\end{equation}

It is clear that $H \subset T$ and that $H$ is symmetric. Further $H$ is closed. For suppose there exists a sequence $\{g_r\} \subset D_H$ such that $g_r \to g \in \mathcal{J}$ and $Hg_r$ converges. We have
\begin{align}
g_r(m) &= \int t^m G_r(t) dV(t), \quad G_r(t) \in L_0^{\perp}, \\
g(m) &= \int t^m G(t) dV(t), \quad G(t) \in L_0^{\perp}.
\label{eq:convergence-setup}
\end{align}

Therefore,
\begin{equation}
\|g_r - g\|^2 = \int |G_r(t) - G(t)|^2 dV(t) \to 0 \text{ as } r \to \infty,
\label{eq:norm-convergence}
\end{equation}
and
\begin{equation}
\|H(g_p - g_q)\|^2 = \int |t G_p(t) - t G_q(t)|^2 dV(t) \to 0 \text{ as } p, q \to \infty.
\label{eq:operator-convergence}
\end{equation}

Consequently, there exists a $\Phi(t) \in L_0^{\perp}$ such that
\begin{equation}
\int |t G_r(t) - \Phi(t)|^2 dV(t) \to 0.
\label{eq:limit-function}
\end{equation}

It is clear that
\begin{equation}
\int |t G_r(t) - \Phi(t)| dV(t) = \int_R |t G_r(t) - \Phi(t)|^2 dV(t),
\label{eq:integral-equality}
\end{equation}
where $R$ is the whole real axis minus the point $t = 0$. On $R$ consider the function $\psi(t) = \Phi(t)/t$. Let $\eta > 0$ and $R_\eta$ be the union of the intervals $[-\infty, -\eta]$ and $[\eta, \infty]$. It follows that
\begin{equation}
\eta^2 \int_{R_\eta} |G_r(t) - \psi(t)|^2 dV(t) \leq \int_{R_\eta} |t G_r(t) - \Phi(t)|^2 dV(t).
\label{eq:eta-bound}
\end{equation}

Consequently, $\int_{R_\eta} |G_r(t) - \psi(t)|^2 dV(t) \to 0$ which implies that $\int_{R_\eta} |\psi(t)|^2 dV(t) < \infty$. Further, since $\int_{R_\eta} |G_r(t) - G(t)|^2 dV(t) \to 0$, we must have that $\psi(t)$ and $G(t)$ differ only on a set of measure (generated by $V$) zero on $R_\eta$. Since $\eta$ is arbitrary, this must also be true for $R$.

Define $\psi(0) = G(0)$. With this definition $\psi(t) \in L_0^{\perp}$. Now, $t\psi(t) = \Phi(t)$ for $t \neq 0$. If $V(0+0) - V(0-0) \neq 0$, $\Phi(0) = 0$, $\psi(0)$ is finite and therefore $\psi(t) = \Phi(t)$ for all $t$. Consequently, $t\psi(t) \in L_0^{\perp}$. Therefore, $g \in D_H$ and $Hg_r \to Hg$. This proves that $H$ is closed. Further, since $\mathcal{J}' \subset D_H$, we must have $T^* = T \subset H$ which means $T = H$.

Let $g(m)$ be given as in \eqref{eq:function-integral}. Define
\begin{equation}
B_\lambda g(m) = \int t^m G_\lambda(t) dV(t),
\label{eq:spectral-family}
\end{equation}
where $G_\lambda(t) = G(t)$ for $-\infty \leq t \leq \lambda$, and $G_\lambda(t) = 0$ for $\lambda < t \leq \infty$. It is easily checked that the set $\{B_\lambda\}$, $-\infty < \lambda < \infty$, is a monotone increasing set of bounded self-adjoint operators such that
\begin{equation}
B_{\lambda+0} = B_\lambda, \quad \lim_{\lambda \to -\infty} B_\lambda = 0, \quad \lim_{\lambda \to \infty} B_\lambda = I, \quad \text{and } (B_\lambda f, f) = V(\lambda).
\label{eq:spectral-properties}
\end{equation}

We have $(Tg, h) = \int t d(B_\lambda g, h)$, and consequently we may write, symbolically, $T = \int t dB_\lambda$. $D_T = D_H$ is the set of all $g \in \mathcal{J}$ such that $\int |t|^2 d(B_\lambda g, g) < \infty$. It is clear that if $m$ is an integer, $(T^m g, h) = \int t^m d(B_\lambda g, h)$.

Any operator $B_\lambda$ commutes with $T$. For, if $g \in D_T$, $B_\lambda Tg(m) = \int t^m \cdot t \cdot G_\lambda(t) dV(t)$. Therefore, $B_\lambda Tg(m)$ is $B_\lambda g$ evaluated at the point $m+1$. But since $T \leftrightarrow f(p+q+1)$, $B_\lambda g \in D_T$ and $TB_\lambda g = B_\lambda Tg$.

Since $T$ is self-adjoint, there exist orthogonal subspaces $M_k$, $k = 1, 2, \ldots$, such that $M_k$ reduces $T$ and $T$ may be considered as $\sum_{k=1}^{\infty} \oplus T_k$ where $T_k$ is a bounded self-adjoint operator on $M_k$ and is the restriction of $T$ to $M_k$\footnote{Cf. Nagy \cite{nagy}, pp. 48-49.}. Since $B_\lambda$ commutes with $T$, $M_k$ reduces $B_\lambda$. Let $B_\lambda^{(k)}$ be the restriction of $B_\lambda$ to $M_k$. We may then write, symbolically, $T_k = \int t dB_\lambda^{(k)}$.

Suppose that $\beta_k$ is the upper and $\alpha_k$ the lower bound of $T_k$. Suppose further that $\mu > \nu \geq \beta_k$; then since $B_\lambda^{(k)}(\mu) - B_\lambda^{(k)}(\nu)$ is positive and commutes with $T_k$, we have
\begin{equation}
0 \leq (B_\lambda^{(k)}(\mu) - B_\lambda^{(k)}(\nu)) (\nu I - T_k) = \int_J (\nu - \lambda) dB_\lambda^{(k)} \leq 0,
\label{eq:spectral-bound}
\end{equation}
where $J$ is the interval $(\nu, \mu]$. Consequently, the only possibility is that $B_\lambda^{(k)}(\mu) - B_\lambda^{(k)}(\nu) = 0$. Similarly, if $\nu < \alpha_k$, $B_\lambda^{(k)}(\nu) = 0$. Therefore,
\begin{equation}
T_k = \int_{\alpha_k}^{\beta_k} t dB_\lambda^{(k)} = \int_{\alpha_k}^{\beta_k} t dE_\lambda^{(k)},
\label{eq:reduced-spectral}
\end{equation}
where $\{E_\lambda^{(k)}\}$ is the resolution of the identity associated with $T_k$. If we apply the Weierstrass approximation theorem we get $B_\lambda^{(k)} = E_\lambda^{(k)}$, $k = 1, 2, \ldots$. Since $B_\lambda$ may be considered as $\sum_{k=1}^{\infty} \oplus B_\lambda^{(k)}$, we have $B_\lambda = E_\lambda$, where $\{E_\lambda\}$ is the canonical resolution of the identity of $T$. Consequently $V(\lambda) = (E_\lambda f, f)$, which completes the proof of the lemma.
\end{proof}

Now, let $K(x, y) = f(x+y)$ be a positive matrix defined for $0 \leq x, y < \infty$ and such that $f(x)$ is continuous for $x > 0$.

\begin{lemma}
\label{lem:analytic-extension}
There exists an analytic function $F(z)$ defined in the half-plane $R(z) > 0$ which coincides with $f(x)$ for $x > 0$ and such that $F(z+w) \geq_0$.
\end{lemma}

\begin{proof}
Denote by $S_n$ the semi-groups $\{m/2^n\}_{m=0}^{\infty}$ and let $f_n(m) = f(m/2^n)$. Since $f_n(m+q+1) \geq_0$, by Lemma~\ref{lem:one-dimensional}, there exists a bounded monotone increasing function $V_n(t)$ so that
\begin{equation}
f_n(m) = f(m/2^n) = \int_0^{\infty} t^{m/2^n} dV_n(t).
\label{eq:discrete-representation}
\end{equation}

The function
\begin{equation}
F_n(z) = \int_0^{\infty} t^z dV_n(t)
\label{eq:analytic-function}
\end{equation}
clearly exists and is analytic for $R(z) > 0$. Also, it coincides with $f(x)$ on $S_n$ for $m \leq n$ and $F_n(z+w) \geq_0$. Further, if $p$ is any integer and $0 < x \leq p$, where $x = R(z)$, we have
\begin{align}
|F_n(z)| &\leq \int_0^{\infty} t^x dV_n(t) \leq \int_0^1 dV_n(t) + \int_1^{\infty} t^x dV_n(t) + \int_1^{\infty} t^p dV_n(t) \\
&= f(0) + f(x) + f(p).
\label{eq:uniform-bound}
\end{align}

This implies that the sequence $\{F_n(z)\}$ is uniformly bounded in this strip. Also, for any rational number of the form $p/2^q$, $F_n(p/2^q)$ converges to $f(p/2^q)$. Therefore by the Vitali theorem\footnote{See L. Bieberbach, Lehrbuch der Funktionentheorie, vol. I, Leipzig, 1934, p. 168.} $F_n(z)$ converges to an analytic function $F(z)$ for $R(z) > 0$. Clearly, $F(z+w) \geq_0$, and since $F(z)$ coincides with $f(x)$ on the rational points of the form $p/2^q$, by the continuity of $f(x)$ we must have $F(x) = f(x)$ for all $x > 0$.
\end{proof}

\begin{lemma}
\label{lem:self-adjoint-operators}
The operators $H_{x_0} \leftrightarrow f(x+y+x_0)$ are self-adjoint for $x_0 \geq 0$. If $f(x)$ is continuous at the origin, every operator $H_{x_0}$ has an inverse.
\end{lemma}

\begin{proof}
Let $\mathcal{J}$ be the r.k.s. corresponding to $f(x+y)$ for $x, y \geq 0$, $\mathcal{J}_0$ be the r.k.s. corresponding to $f(x+y)$ for $x, y > 0$, and $\mathcal{J}_1$ the r.k.s. corresponding to $F(z+w)$ of the previous lemma.

Suppose $x_0 > 0$ and that there exists an element $g$ in $\mathcal{J}$ which is in the domain of $H_{x_0}$ and such that $H_{x_0}g = ig$, that is, $g(x+x_0) = ig(x)$ for $x \geq 0$. Let $g_0(x)$ be the restriction of $g(x)$ to the positive real axis, $x > 0$. By Theorem~\ref{thm:restriction}, $g_0 \in \mathcal{J}_0$ and also there exists an element $g_1$ in $\mathcal{J}_1$ such that the restriction of $g_1$ to the positive part of the real axis is $g_0$.

Since $F(z)$ is analytic, from the fact that $\mathcal{J}_1'$ is dense in $\mathcal{J}_1$ and that strong convergence in $\mathcal{J}_1$ implies uniform convergence in every set where $F(z+\overline{z})$ is bounded (see N. Aronszajn \cite{aronszajn2}, p. 344(5)), $g_1(z)$ is analytic for $R(z) > 0$. Therefore since $g_1(x+x_0) = ig_1(x)$ for $x > 0$, we must have $g_1(z+x_0) = ig_1(z)$ for all $R(z) > 0$. Now, $g_1(z)$ is periodic of period $4ix_0$ and consequently may be extended analytically to the whole plane (less $\infty$). Further, since
\begin{equation}
|g_1(z)| = |(g_1(w), F(w + \overline{z}))| \leq \|g_1\| \|f(2R(z))\|^{1/2},
\label{eq:bound-estimate}
\end{equation}
$g_1(z)$ is bounded in any strip $0 < x_1 \leq R(z) \leq x_2 < \infty$. By Liouville's theorem $g_1(z)$ must be a constant, which must of course be zero. Therefore, the element $g_0(x)$ must be zero for $x > 0$. Since $g(x) = ig(0)$, we must have $g(0) = 0$.

We have consequently proved that for $x_0 > 0$ the deficiency index of $H_{x_0}^*$ is $(0, 0)$, which means $H_{x_0}$ is self-adjoint. Since $H_0$ is the identity operator, we have shown that every operator $H_{x_0}$ is self-adjoint.

Suppose now that $f(x)$ is continuous at the origin. Then every element of $\mathcal{J}$ is continuous for $x \geq 0$\footnote{The relevant general theorem is given in N. Aronszajn \cite{aronszajn1}, p. 140.}. We shall show that the linear manifold determined by the functions $f(x+y+x_0)$ is dense in $\mathcal{J}$, which by Theorem~\ref{thm:correspondence} will mean that $H_{x_0}$ has an inverse.

Let $\mathcal{J}_0$ be the set of all elements in $\mathcal{J}$ which are zero for $x \geq x_0$. The linear manifold determined by the functions $\{f(x+y+x_0)\}$ is dense in the orthogonal complement of $\mathcal{J}_0$. If $h \in \mathcal{J}_0$, then from the facts that $h$ is continuous at the origin and is the restriction of an element of $\mathcal{J}_1$ for $x > 0$, we must have $h(x) = 0$ for $x \geq 0$. Therefore, $\mathcal{J}_0$ consists only of the zero element.
\end{proof}

\begin{lemma}
\label{lem:spectral-representation}
There exists a resolution of the identity, $\{E_t\}$, defined on $\mathcal{J}$, such that\footnote{The integral representation for these types of functions was first given by S. Bernstein \cite{bernstein}, where they were called exponentially convex. Also cf. D. V. Widder \cite{widder2} and \cite{widder3}, p. 273.}
\begin{equation}
f(x) = \int_0^{\infty} t^x d(E_t f, f).
\label{eq:spectral-integral}
\end{equation}

The function $V(t) = (E_t f, f)$ is substantially unique and is continuous at the origin if $f(x)$ is continuous there. The operators $H_{x_0} \leftrightarrow f(x+y+x_0)$ are given by
\begin{equation}
H_{x_0} = \int_0^{\infty} t^{x_0} dE_t.
\label{eq:operator-representation}
\end{equation}
\end{lemma}

\begin{proof}
Let $\{E_t\}$ be the canonical resolution of the identity of the self-adjoint operator $H_1$. Since $H_{1/2} H_{1/2} = H_1$ and since both $H_{1/2}$ and $H_1$ are self-adjoint, it follows that $H_{1/2} = H_1^{1/2}$. Further, since $f(x+y+1/2) \geq_0$, by Theorem~\ref{thm:semi-bounded}, $H_{1/2} \geq 0$ and therefore
\begin{equation}
H_{1/2} = \int_0^{\infty} t^{1/2} dE_t.
\label{eq:half-power}
\end{equation}

Similarly, $H_{m/2^n} = \int_0^{\infty} t^{m/2^n} dE_t$. Therefore,
\begin{equation}
f(m/2^n) = (H_{m/2^n} f, f) = \int_0^{\infty} t^{m/2^n} d(E_t f, f).
\label{eq:discrete-spectral}
\end{equation}

For $x$ in the open interval $(0, \infty)$, by the continuity of the function on the left and the integral on the right, we get
\begin{equation}
f(x) = \int_0^{\infty} t^x d(E_t f, f).
\label{eq:continuous-spectral}
\end{equation}

Since it is clear that $f(0) = \int_0^{\infty} t^0 d(E_t f, f)$, we have the representation for all $x \geq 0$.

The uniqueness of $V(t) = (E_t f, f)$ follows by an argument similar to the uniqueness proof of Lemma~\ref{lem:one-dimensional}. If $f(x)$ is continuous at the origin, then $\lim_{t \to 0} E_t = 0$, which implies the continuity of $V(t)$ at the origin.

Consider now the operators
\begin{equation}
T_{x_0} = \int_0^{\infty} t^{x_0} dE_t.
\label{eq:operator-definition-2}
\end{equation}

The operators $T_{m/2^n}$ certainly coincide with $H_{m/2^n}$, where $m$ and $n$ take on the values $0, 1, 2, \ldots$. Since $f(x) = f(x+y) \in D_{H_{m/2^n}}$, $f_y \in D_{T_{x_0}}$ for every $x_0 \geq 0$. Therefore,
\begin{equation}
f(x + y + m/2^n) = (H_{m/2^n} f_x, f_y) = \int_0^{\infty} t^{m/2^n} d(E_t f_x, f_y).
\label{eq:kernel-representation}
\end{equation}

If we choose a sequence of the $m/2^n$ which approach any $x_0 > 0$, we get
\begin{equation}
f(x + y + x_0) = \int_0^{\infty} t^{x_0} d(E_t f_x, f_y) = (T_{x_0} f_x, f_y).
\label{eq:limit-representation}
\end{equation}

Therefore, $T_{x_0} f_y(x) = f(x+y+x_0)$, which means $T_{x_0} \sim f(x+y+x_0)$. Consequently, $T_{x_0} \subset H_{x_0}$ and since both of these operators are self-adjoint we must have $T_{x_0} = H_{x_0}$.
\end{proof}

\textbf{Remark.} With the help of Theorem~\ref{thm:integral-space} and Lemma~\ref{lem:spectral-representation}, we see that for any bounded monotone increasing function $V(t)$ such that $\int_0^{\infty} t^x dV(t) < \infty$ for $x \geq 0$, the linear manifold generated by the set of functions $\{g(t)\} = \{t^x\}$, for $t \geq 0$ and $x \geq 0$, is dense in $L^2(V)$.

\begin{lemma}
\label{lem:unitary-group}
Let $\{U_y\}$, $-\infty < y < \infty$, be a group of unitary operators in the sense that $U_x U_y = U_{x+y}$ and $U_y^* = U_{-y}$. Further suppose $(U_y f, g)$ is a continuous function of $y$ for every $f$ and $g$ in the Hilbert space. Let $H_1 = 2^{-1}(U_1 + U_{-1})$ and $d$ a finite positive real number.

Necessary and sufficient conditions that there exists a resolution of the identity $\{E_t\}$ such that $E_t = 0$ for $t < -d$, $E_t = I$ for $t \geq d$, and such that
\begin{equation}
U_y = \int_{-d}^d e^{iyt} dE_t,
\label{eq:unitary-representation}
\end{equation}
are that there exists a sequence of positive numbers $y_n$ such that $y_n d \leq \pi$ and
\begin{equation}
H_1 \geq \cos(y_n d) I, \quad n = 1, 2, \ldots
\label{eq:cosine-bound}
\end{equation}
\end{lemma}

\begin{proof}\footnote{I am indebted to the referee for a suggestion which materially simplified the original proof.}
To prove the necessity, suppose that $\{U_y\}$ has a representation as above. There exists an integer $n_0$ such that $n_0 d > \pi$. Choose $y_n = 1/(n+n_0)$. For any such $y_n$ we have
\begin{equation}
U_{y_n} = \int_{-d}^d e^{iy_n t} dE_t.
\label{eq:unitary-spectral}
\end{equation}

It follows immediately that $H_{y_n} \geq \cos(y_n d) I$, $n = 1, 2, \ldots$.

To prove the sufficiency we first note that by a well known theorem of M. H. Stone\footnote{Cf. Nagy \cite{nagy}, p. 69.} there exists a resolution of the identity $\{E_t\}$ such that for every $y$,
\begin{equation}
U_y = \int e^{iyt} dE_t.
\label{eq:stone-representation}
\end{equation}

It follows that
\begin{equation}
H_1 = \int \cos(yt) dE_t.
\label{eq:cosine-integral}
\end{equation}

From the fact that $H_1 \geq \cos(y_n d) I$ it follows that $\{E_t\}$ has no spectrum in the intervals where $\cos(y_n t) < \cos(y_n d)$, in particular in $d < t < (2\pi/y_n) - d$ and $(-2\pi/y_n) + d < t < -d$. For $y_n \to 0$ we get that there is no spectrum outside of $-d \leq t \leq d$.
\end{proof}
Let us now consider these problems over higher-dimensional spaces. Let $x$, for $x \geq 0$, and $t_1$, for $-\infty \leq t_1 \leq \infty$, be generic symbols for vectors in $n$-dimensional Euclidean space and $y$, for $-\infty < y < \infty$, and $t_2$, for $-\infty \leq t_2 \leq \infty$, be generic symbols for vectors in $m$-dimensional Euclidean space. Further let $f(x,y)$ be a continuous positive definite function as defined in the introduction, i.e., $\sum_{i,j=1}^N a_i \overline{a_j} f(x_i + x_j, y_i - y_j) \geq 0$.

\begin{lemma}
\label{lem:higher-dimensional}
There exists a bounded monotone increasing function $V(t_1, t_2)$ whose spectrum is contained in the set $0 \leq t_1 < \infty$, $-\infty < t_2 < \infty$ and such that
\begin{equation}
f(x,y) = \int_{E_{n+m}} t_1^x \exp(i t_2 \cdot y) dV(t_1, t_2).
\label{eq:higher-dimensional-representation}
\end{equation}
The function $V(t_1, t_2)$ is substantially unique.
\end{lemma}

\begin{proof}
Consider the operators $T_{u_k} \leftrightarrow f(x_1 + x_2 + u_k, y_1 - y_2)$, $k = 1, 2, \ldots, n$. These operators are self-adjoint. For if $T_{u_k}$ is not self-adjoint there exists a nonzero $g \in \mathcal{J}$ such that $T_{u_k} g = i g$. Since $g$ is not zero, there exists a vector $y_0$ and vectors $x = (x^{(1)}, \ldots, x^{(k-1)}, x^{(k)}, x^{(k+1)}, \ldots, x^{(n)})$, $x$ fixed, $0 \leq x^{(k)} < \infty$, such that the restriction of $g(x,y)$ to the set $(x^{(k)}, y_0)$ is not zero. We have then $g(x^{(k)} + u_k, y_0) = i g(x^{(k)}, y_0)$. But if we consider the restriction of the elements of $\mathcal{J}$ to the set $(x^{(k)}, y_0)$, then Lemma~\ref{lem:self-adjoint-operators} tells us that $g$ cannot satisfy this relation.

Let $\{E_t^{(k)}\}$ be the resolution of the identity associated with $T_{u_k}$. Since $f(x_1 + x_2 + u_k, y_1 - y_2) \geq_{\mathcal{J}} 0$, the spectrum of $\{E_t^{(k)}\}$ lies in the interval $[0, \infty]$.

Consider the operators $T_{x \cdot u_k} = \int_0^{\infty} t^{x \cdot u_k} dE_t^{(k)}$. By methods similar to those used in Lemma~\ref{lem:spectral-representation} we may prove that $T_{x \cdot u_k} \leftrightarrow f(x_1 + x_2 + x \cdot u_k, y_1 - y_2)$.

Let us now prove that the operators $T_{u_j}$ and $T_{u_k}$ commute. It is clear that $T_{x \cdot u_j}$ and $T_{x \cdot u_k}$ commute on $\mathcal{J}'$ for every $x \geq 0$. We have, therefore, for any $g, h \in \mathcal{J}'$,
\begin{equation}
(T_{x \cdot u_j} T_{x \cdot u_k} g, h) = \int_0^{\infty} t^{x \cdot u_j} d(E_t^{(j)} T_{x \cdot u_k} g, h) = \int_0^{\infty} t^{x \cdot u_j} d(E_t^{(j)} g, T_{x \cdot u_k} h).
\label{eq:commutation-step1}
\end{equation}

Consequently,
\begin{equation}
\int_0^{\infty} t^{x \cdot u_j} d[(E_t^{(j)} T_{x \cdot u_k} g, h) - (E_t^{(j)} g, T_{x \cdot u_k} h)] = 0.
\label{eq:commutation-step2}
\end{equation}

Let us write
\begin{equation}
(E_t^{(j)} T_{x \cdot u_k} g, h) - (E_t^{(j)} g, T_{x \cdot u_k} h) = V_1(t) - V_1^*(t) + [V_2(t) - V_2^*(t)],
\label{eq:commutation-decomposition}
\end{equation}
where, e.g.,
\begin{equation}
V_1(t) = \frac{1}{4} \|E_t^{(j)} (T_{x \cdot u_k} g + h)\|^2 + \frac{1}{4} \|E_t^{(j)} (g - T_{x \cdot u_k} h)\|^2,
\label{eq:v1-definition}
\end{equation}
and $V_1^*(t)$, $V_2(t)$, and $V_2^*(t)$ have similar forms. The functions $V_r(t)$ and $V_r^*(t)$, $r = 1, 2$, are bounded monotone increasing functions.

We get
\begin{align}
\int_0^{\infty} t^{x \cdot u_j} dV_r(t) &= \int_0^{\infty} t^{x \cdot u_j} dV_r^*(t), \quad r = 1, 2.
\label{eq:integral-equality}
\end{align}

Since $V_r(t)$ and $V_r^*(t)$ are normed in the same way, by Lemma~\ref{lem:spectral-representation} they must be equal and, consequently,
\begin{equation}
(E_t^{(j)} T_{x \cdot u_k} g, h) = (E_t^{(j)} g, T_{x \cdot u_k} h).
\label{eq:commutation-result}
\end{equation}

From this it follows that
\begin{equation}
\int_0^{\infty} t^{x \cdot u_j} d(E_t^{(j)} E_{\mu}^{(k)} g, h) = \int_0^{\infty} t^{x \cdot u_j} d(E_{\mu}^{(k)} E_t^{(j)} g, h).
\label{eq:spectral-commutation}
\end{equation}

By the same reasoning as employed before we get
\begin{equation}
(E_t^{(j)} E_{\mu}^{(k)} g, h) = (E_{\mu}^{(k)} E_t^{(j)} g, h).
\label{eq:projections-commute}
\end{equation}

Since $\mathcal{J}'$ is dense in $\mathcal{J}$ we have that $\{E_t^{(j)}\}$ commutes with $\{E_{\mu}^{(k)}\}$.

Consider now the operators $U_{y \cdot u_k} \leftrightarrow f(x_1 + x_2, y_1 - y_2 + y \cdot u_k)$, for $k = 1, \ldots, m$, $-\infty < y < \infty$. These are unitary operators which for fixed $k$ form a group. It is clear that $(U_{y \cdot u_k} f, g)$ is a continuous function of $y \cdot u_k$ for every $f, g \in \mathcal{J}$. Consequently, there exists a resolution of the identity $\{F_t^{(k)}\}$ such that
\begin{equation}
U_{y \cdot u_k} = \int_{-\infty}^{\infty} e^{i y \cdot u_k \cdot t} dF_t^{(k)}.
\label{eq:unitary-representation}
\end{equation}

Since the operators $\{T_{u_j}\}$ commute with one another and all of the operators $\{U_{y \cdot u_k}\}$ commute with one another and with every $T_{u_j}$, the operator
\begin{equation}
E_{t_1, t_2} = \prod_{k=1}^{n} E_{t_1^{(k)}}^{(k)} \prod_{k=1}^{m} F_{t_2^{(k)}}^{(k)}
\label{eq:joint-spectral-family}
\end{equation}
is a projection and the set $\{E_{t_1, t_2}\}$ is a resolution of the identity. Therefore, if we write
\begin{equation}
T_{t_1} = \prod_{k=1}^{n} T_{t_1^{(k)} \cdot u_k} \quad \text{and} \quad U_{t_2} = \prod_{k=1}^{m} U_{t_2^{(k)} \cdot u_k},
\label{eq:product-operators}
\end{equation}
we have
\begin{equation}
T_{t_1} U_{t_2} = \int_{E_{n+m}} t_1^{t_1} \exp(i t_2 \cdot t_2) dE_{t_1, t_2} \quad \text{and} \quad V(t_1, t_2) = (E_{t_1, t_2} f, f)
\label{eq:spectral-formula}
\end{equation}
\begin{equation}
f(x, y) = (T_x U_y f, f) = \int_{E_{n+m}} t_1^x \exp(i t_2 \cdot y) dV(t_1, t_2).
\label{eq:final-representation}
\end{equation}

It remains to prove the uniqueness of $V(t_1, t_2)$. We write
\begin{equation}
\int_{E_{n+m}} \exp(i t_2 \cdot y) t_1^x dV(t_1, t_2) = \int_{E_m} \exp(i t_2 \cdot y) dt_2 \int_0^{\infty} t_1^x dV(t_1, t_2).
\label{eq:uniqueness-step1}
\end{equation}

If $V_1(t_1, t_2)$ is another monotone function as described in Lemma~\ref{lem:higher-dimensional}, we may assume without loss of generality that $V_1(t_1, t_2)$ is normed in the same manner as $V(t_1, t_2)$. We have then\footnote{The iterations which we are performing on these multiple integrals may be easily verified, at least for the simple functions used here, by measure-theoretic methods.}
\begin{equation}
\int_{E_{n+m}} \exp(i t_2 \cdot y) t_1^x dV(t_1, t_2) = \int_{E_{n+m}} \exp(i t_2 \cdot y) t_1^x dV_1(t_1, t_2).
\label{eq:uniqueness-step2}
\end{equation}

It follows quite easily\footnote{Cf., e.g., E. Hopf, Ergodentheorie, Ergibnisse der Mathematik und ihrer Grenzgebiete, vol. 5, no. 5, 1937, Berlin, Springer, p. 11.} that for every $t_2$,
\begin{equation}
\int_0^{\infty} t_1^x dV(t_1, t_2) = \int_0^{\infty} t_1^x dV_1(t_1, t_2).
\label{eq:uniqueness-step3}
\end{equation}

We may now write
\begin{align}
\int_0^{\infty} t_1^x dV(t_1, t_2) &= \int_0^{\infty} t_1^{x^{(1)}} dt_1^{(1)} \int_0^{\infty} t_1^{x^{(2)}} dt_1^{(2)} \cdots \int_0^{\infty} t_1^{x^{(n)}} dV(t_1, t_2), \\
&= \int_0^{\infty} t_1^{x^{(1)}} dt_1^{(1)} \int_0^{\infty} t_1^{x^{(2)}} dt_1^{(2)} \cdots \int_0^{\infty} t_1^{x^{(n)}} dV_1(t_1, t_2),
\label{eq:uniqueness-step4}
\end{align}
where the $dt_1^{(i)}$ indicates we are integrating with respect to $t_1^{(i)}$, the $dt_2$ indicates we are integrating with respect to the variables $t_2^{(j)}$, $j = 1, \ldots, m$, and $x^{(i)} = x^{(i)}$ By Lemma~\ref{lem:spectral-representation} we must have
\begin{equation}
\int_0^{\infty} t_1^{x^{(1)}} dV(t_1, t_2) = \int_0^{\infty} t_1^{x^{(1)}} dV_1(t_1, t_2).
\label{eq:uniqueness-step5}
\end{equation}

Proceeding in this way we get $V(t_1, t_2) = V_1(t_1, t_2)$. This completes the proof of the lemma.
\end{proof}

We are now in a position to prove the sufficiency of Theorem~\ref{thm:main}. Choose $c < c_1 < 0$ and consider the transformation $z' = z - c_1$ for $R(z) \geq c_1$. Consider then the function $f_{c_1}(z') = f(z)$; $f_{c_1}(z'_1 + z'_2) \geq_{\mathcal{J}} 0$ and the inequalities (2) and (3) of Theorem~\ref{thm:main} carry over for $f_{c_1}$.

By Lemma~\ref{lem:higher-dimensional} we may write
\begin{equation}
f_{c_1}(z') = \int_{E_{n+m}} t_1^{x'} \exp(i t_2 \cdot y') dV_{c_1}(t_1, t_2),
\label{eq:sufficiency-step1}
\end{equation}
where $V_{c_1}$ is a bounded monotone increasing function whose spectrum lies in the set $0 \leq t_1 < \infty$, $-\infty < t_2 < \infty$. If we make the transformation $t_1 = \log \tau_1$, $t_2 = \tau_2$, we get
\begin{equation}
f_{c_1}(z') = \int_{E_{n+m}} e^{z' \cdot t} dV'(t),
\label{eq:sufficiency-step2}
\end{equation}
where $t = (t_1, t_2) = (t_1^{(1)}, \ldots, t_1^{(n)}, t_2^{(1)}, \ldots, t_2^{(m)})$ and $V'(t) = V_{c_1}(e^{t_1}, t_2)$.

Furthermore, by virtue of the method of proof of Lemma~\ref{lem:higher-dimensional}, conditions (2) and (3) of Theorem~\ref{thm:main}, Lemma~\ref{lem:unitary-group}, and Theorem~\ref{thm:semi-bounded} we have
\begin{equation}
f_{c_1}(z') = \int_a^b e^{z' \cdot t} dV(t).
\label{eq:sufficiency-step3}
\end{equation}

Therefore, for $R(z) \geq c_1$,
\begin{equation}
f(z) = \int_a^b e^{z \cdot t} dV_{c_1}(t),
\label{eq:sufficiency-step4}
\end{equation}
where
\begin{equation}
V_{c_1}(t) = \int_a^t e^{c_1 \cdot s} dV(s).
\label{eq:sufficiency-step5}
\end{equation}

Since $c_1 < 0$, $V_{c_1}$ is a bounded monotone increasing function.

Choose now $c < c_2 < c_1$. By the same argument as used above we get
\begin{equation}
f(z) = \int_a^b e^{z \cdot t} dV_{c_2}(t),
\label{eq:sufficiency-step6}
\end{equation}
for $R(z) \geq c_2$. By Lemma~\ref{lem:higher-dimensional} it follows that $V_{c_1}$ and $V_{c_2}$ are substantially equal. Therefore, there exists a bounded monotone increasing function $V(t)$ such that for $R(z) > c$,
\begin{equation}
f(z) = \int_a^b e^{iz \cdot t} dV(t).
\label{eq:sufficiency-conclusion}
\end{equation}

This proves the sufficiency of our main theorem.

The necessity of conditions (1) and (2) of Theorem~\ref{thm:main} follow immediately by simple calculations. The necessity of condition (3) follows from the uniqueness of $V(t)$ in \eqref{eq:main-representation}, Lemma~\ref{lem:unitary-group}, and Theorem~\ref{thm:semi-bounded}. This concludes the proof of the theorem.

Let us notice now that for $n = 0$, $d = \infty$, this is the well known theorem of Bochner \cite{bochner}. For $m = 0$, $a = -\infty$, and $b = 0$ we have new conditions for the S. Bernstein-Hausdorff-Widder theorem on completely monotone functions. For $m = 0$, $n = 1$, $a = -\infty$, and $b = \infty$ this is a result of S. Bernstein on exponentially convex functions. Further, for $m = 1$, $n = 1$, $a = -\infty$, $b = \infty$, as far as the theorem goes, it gives a corrected version of an incorrect theorem stated by M. Livshitz \cite{livshitz}.

\section{Moment problems}
\label{sec:moment-problems}

Let us consider the vectors $r = (r^{(1)}, \ldots, r^{(n)})$, $s = (s^{(1)}, \ldots, s^{(m)})$, where $r^{(k)}$, $k = 1, \ldots, n$, ranges over the positive integers and zero and $s^{(k)}$, $k = 1, \ldots, m$, ranges over the positive and negative integers and zero. Further, let $a_1$, $b_1$, and $t_1$, with $a_1$, $b_1$ finite and $b_1 - a_1 \geq 0$, be vectors in $n$-dimensional Euclidean space and $a_2$, $b_2$, $t_2$, with $a_2$, $b_2$ finite and $0 \leq b_2 - a_2 \leq \pi$, be vectors in $m$-dimensional Euclidean space. With these notations we have the following theorem.

\begin{theorem}
\label{thm:moment-problems}
Let $\{\mu_{r,s}\}$ be a sequence of numbers with $r$ and $s$ as defined above. Necessary and sufficient conditions that there exists a bounded monotone increasing function $V(t_1, t_2)$ whose spectrum vanishes outside of the interval $I$ given by $a_j \leq t_j \leq b_j$, $j = 1, 2$, and such that
\begin{equation}
\mu_{r,s} = \int_I t_1^r \exp(i t_2 \cdot s) dV(t_1, t_2),
\label{eq:moment-integral}
\end{equation}
are:
\begin{enumerate}
\item $\mu_{r_1+r_2, s_1-s_2} \geq_{\mathcal{J}} 0$.
\item $a_1 \cdot u_k \mu_{r_1+r_2, s_1-s_2} \leq_{\mathcal{J}} \mu_{r_1+r_2+u_k, s_1-s_2} \leq_{\mathcal{J}} b_1 \cdot u_k \mu_{r_1+r_2, s_1-s_2}$ for $k = 1, \ldots, n$.
\item $\exp(-2^{-1} i (a_2 + b_2)) \mu_{r_1+r_2, s_1-s_2+u_k} + \exp(2^{-1} i (a_2 + b_2)) \mu_{r_1+r_2, s_1-s_2-u_k} \geq_{\mathcal{J}} 2 \cos(2^{-1} (b_2 - a_2)) \mu_{r_1+r_2, s_1-s_2}$ for $k = 1, \ldots, m$.
\end{enumerate}

The function $V(t_1, t_2)$ is substantially unique.
\end{theorem}

The proof of this theorem follows the same pattern as the proof of Theorem~\ref{thm:main}, but is much easier. For $m = 0$ we have the Hausdorff moment problem. For $n = 0$, $m = 1$, we have a result of Achieser and Krein \cite{achieser-krein}. For $m = 0$ and $n = 1$, the usual solutions of the moment problems involving infinite domains of integration have been obtained in Lemma~\ref{lem:one-dimensional}. For the higher-dimensional cases of these problems there is difficulty in obtaining the solutions by these methods because of the difficulty in proving the permutability of the unbounded operators which arise.

\begin{thebibliography}{99}

\bibitem{achieser-krein} N. Achieser and M. Krein, \emph{On certain problems in the theory of moments} (in Russian), Kharkoff, 1938, 254 pp.

\bibitem{aronszajn1} N. Aronszajn, La théorie générale des noyaux reproduisants et ses applications, Première Partie, \emph{Proc. Cambridge Philos. Soc.} vol. 39 (1943) p. 133.

\bibitem{aronszajn2} N. Aronszajn, The theory of reproducing kernels, \emph{Trans. Amer. Math. Soc.} vol. 68 (1950) pp. 337--404.

\bibitem{bernstein} S. Bernstein, Sur les fonctions absolument monotones, \emph{Acta Math.} vol. 52 (1929) pp. 1--66.

\bibitem{bochner} S. Bochner, \emph{Fouriersche Integrale}, Leipzig, 1932, 227 pp.

\bibitem{carleman} T. Carleman, Sur les équations intégrales singulières à noyau réel et symétrique, \emph{Uppsala Universitets Årsskrift}, 1923, 228 pp.

\bibitem{devinatz} A. Devinatz, Transformations in reproducing kernel spaces, Thesis, Harvard University, 1950.

\bibitem{hausdorff} F. Hausdorff, Summationsmethoden und Momentfolgen, \emph{Math. Zeit.} vol. 9 (1921) I pp. 74--109, II pp. 280--299.

\bibitem{krein1} M. Krein, On a remarkable class of Hermitian operators, \emph{C.R. (Doklady) Acad. Sci. URSS. N.S.} vol. 44 (1944) pp. 175--179.

\bibitem{krein2} M. Krein, On a generalized problem of moments, \emph{C.R. (Doklady) Acad. Sci. URSS N.S.} vol. 44 (1944) pp. 219--222.

\bibitem{krein3} M. Krein, Infinite J-matrices and matrices of the moment problem (in Russian), \emph{Doklady Acad. Nauk SSSR N.S.} vol. 69 (1949) pp. 125--128.

\bibitem{krein-krasnoselskii} M. Krein and M. A. Krasnoselskiï, Fundamental theorems on the extension of Hermitian operators and certain of their applications to the theory of orthogonal polynomials and the problem of moments (in Russian) \emph{Uspehi Matematicheskih Nauk N.S.} vol. 2 (1947) pp. 60--106.

\bibitem{livshitz} M. Livshitz, On an application of the theory of Hermitian operators to the generalized problem of moments, \emph{C.R. (Doklady) Acad. Sci. URSS N.S.} vol. 44 (1944) pp. 3--7.

\bibitem{neumann} J. V. Neumann, \emph{Functional operators}, vol. 1, Annals of Mathematics Studies, no. 21, Princeton University Press, 1950, 261 pp.

\bibitem{neumark} M. A. Neumark, On extremal spectral functions of a symmetric operator, \emph{C.R. (Doklady) Acad. Sci. URSS. N.S.} vol. 54 (1946) pp. 7--9.

\bibitem{shohat-tamarkin} J. A. Shohat and J. D. Tamarkin, \emph{The problem of moments}, Mathematical Surveys, vol. 2, New York, American Mathematical Society, 1943, 144 pp.

\bibitem{stone} M. H. Stone, \emph{Linear transformations in Hilbert space}, Amer. Math. Soc. Colloquium Publications, vol. 15, New York, 1932, 622 pp.

\bibitem{nagy} B. v. Sz. Nagy, \emph{Spektraldarstellung linearer Transformationen des Hilbertschen Raumes}, Ergebnisse der Mathematik und ihrer Grenzgebiete, no. 5, 1942, Berlin, 80 pp.

\bibitem{widder1} D. V. Widder, Necessary and sufficient conditions for the representation of a function as a Laplace integral, \emph{Trans. Amer. Math. Soc.} vol. 33 (1931) pp. 851--892.

\bibitem{widder2} D. V. Widder, Necessary and sufficient conditions for the representation of a function by a doubly infinite Laplace integral, \emph{Bull. Amer. Math. Soc.} vol. 40 (1934) pp. 321--326.

\bibitem{widder3} D. V. Widder, \emph{The Laplace transform}, Princeton, 1941, 406 pp.

\end{thebibliography}

\end{document}


