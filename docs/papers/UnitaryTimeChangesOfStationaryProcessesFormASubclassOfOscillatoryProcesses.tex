\documentclass[11pt]{article}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{hyperref}
\usepackage[margin=0.5in]{geometry}

% Define custom macros
\newcommand{\assign}{:=}
\newcommand{\tmop}[1]{\operatorname{#1}}
\newcommand{\tmtextbf}[1]{\textbf{#1}}
\newcommand{\tmtextit}[1]{\textit{#1}}
\newcommand{\cdummy}{\cdot}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}

\title{Unitary Time Changes of Stationary Processes Yield Oscillatory Processes}
\author{Stephen Crowley}
\date{February 2, 2026}

\begin{document}

\maketitle

\begin{abstract}
  A unitary time-change operator $U_{\theta}$ is constructed for absolutely
  continuous, strictly increasing time reparametrizations $\theta$, acting on
  functions that are locally square-integrable (meaning over compact sets).
  Applying $U_{\theta}$ to the Cram{\'e}r spectral representation of a
  stationary process $X (t)$ produces the transformed process $Z (t) =
  U_{\theta} X (t) = \sqrt{\dot{\theta} (t)} X (\theta (t)) =
  \sqrt{\dot{\theta} (t)} \int_{\mathbb{R}} e^{i \lambda \theta (t)} 
  d \Phi (\lambda)$, which is an oscillatory process in the
  sense of Priestley with oscillatory function $\varphi_t (\lambda) =
  \sqrt{\dot{\theta} (t)} e^{i \lambda \theta (t)}$,
  evolutionary power spectral density $S_t (\lambda) = \dot{\theta} (t) 
  S (\lambda)$, and covariance kernel $R_Z (t, s) =
  \sqrt{\dot{\theta} (t) \dot{\theta} (s)} R_X (\theta (t) -
  \theta (s))$ where $R_X$ is the stationary covariance of $X (t) =
  \int_{\mathbb{R}} e^{i \lambda t} d \Phi (\lambda)$, and
  the expected zero-counting function $\mathbb{E} [N_{[a, b]}]$ of the
  oscillatory process paths equals $\sqrt{- R''_X (0) / R_X (0)} 
  (\theta (b) - \theta (a)) / \pi$. The sample paths of any non-degenerate
  second-order stationary process are locally square integrable, making the
  unitary time-change operator $U_{\theta}$ applicable to typical
  realizations. By Bulinskaya's theorem, when the covariance is twice
  continuously differentiable with $R'' (0) < 0$, almost all zeros are simple.
  A zero-localization measure $d \mu (t) = \delta (Z (t)) 
  | \dot{Z} (t) | dt$ induces a Hilbert space $L^2 (\mu)$ on
  the zero set of each oscillatory process realization $Z (t)$, and the
  multiplication operator $(Lf) (t) = tf (t)$ has simple pure point spectrum
  equal to the zero crossing set of $Z$.
\end{abstract}

\tableofcontents

\section{Gaussian Processes}

\subsection{Definition}

\begin{definition}
  \label{def:gaussian_process}\tmtextbf{(Gaussian process)} Let $(\Omega,
  \mathcal{F}, \mathbb{P})$ be a probability space and $T$ a nonempty index
  set. A family $\{X_t : t \in T\}$ of real-valued random variables on
  $(\Omega, \mathcal{F}, \mathbb{P})$ is called a Gaussian process if for
  every finite subset $\{t_1, \ldots, t_n \} \subset T$ the random vector
  $(X_{t_1}, \ldots, X_{t_n})$ is multivariate normal (possibly degenerate).
  Equivalently, every finite linear combination $\sum_{i = 1}^n a_i X_{t_i}$
  is either almost surely constant or Gaussian. The mean function is $m (t)
  \assign \mathbb{E} [X_t]$ and the covariance kernel is
  \begin{equation}
    \label{eq:covariance_kernel} K (s, t) = \mathrm{Cov} (X_s, X_t)
  \end{equation}
  For any finite $(t_i)_{i = 1}^n \subset T$, the matrix $K_{ij} = K (t_i,
  t_j)$ is symmetric positive semidefinite, and a Gaussian process is
  completely determined in law by $m$ and $K$.
\end{definition}

\subsection{Stationary processes}

\begin{definition}
  \label{def:cramer}\tmtextbf{[Cram{\'e}r spectral representation]} A
  zero-mean stationary process $X$ with spectral measure $F$ admits the sample
  path representation
  \begin{equation}
    \label{eq:cramer_representation} X (t) = \int_{\mathbb{R}} e^{i \lambda t}
    d \Phi (\lambda)
  \end{equation}
  which has covariance
  \begin{equation}
    \label{eq:stationary_covariance} R_X (t - s) = \int_{\mathbb{R}} e^{i
    \lambda (t - s)} dF (\lambda)
  \end{equation}
\end{definition}

\subsubsection{Sample path realizations}

\begin{definition}
  \label{def:L2loc}\tmtextbf{[Locally square-integrable functions]} Define
  \begin{equation}
    \label{eq:L2loc_def} L^2_{\mathrm{loc}} (\mathbb{R}) \assign \left\{ f :
    \mathbb{R} \to \mathbb{C} : \int_K |f (t)
    |^2 dt < \infty \text{ for every compact } K \subseteq
    \mathbb{R} \right\}
  \end{equation}
\end{definition}

\begin{remark}
  \label{rem:L2loc_properties}Every bounded measurable set in $\mathbb{R}$ is
  compact or contained in a compact set; hence $L^2_{\mathrm{loc}}
  (\mathbb{R})$ contains functions that are square-integrable on every bounded
  interval, including functions with polynomial growth at infinity.
\end{remark}

\begin{theorem}
  \label{thm:paths_loc}\tmtextbf{[Sample paths in $L^2_{\mathrm{loc}}
  (\mathbb{R})$]} Let $\{X (t)\}_{t \in \mathbb{R}}$ be a second-order
  stationary process with
  \begin{equation}
    \label{eq:finite_variance} \sigma^2 \assign \mathbb{E} [X (t)^2] < \infty.
  \end{equation}
  Then almost every sample path lies in $L^2_{\mathrm{loc}} (\mathbb{R})$.
\end{theorem}

\begin{proof}
  Fix an arbitrary bounded interval $[a, b] \subset \mathbb{R}$ with $a < b$.
  Define
  \begin{equation}
    \label{eq:Yab_def} Y_{[a, b]} \assign \int_a^b X (t)^2 dt.
  \end{equation}
  By Tonelli's theorem, since $X (t)^2 \ge 0$,
  \begin{equation}
    \label{eq:tonelli_application} \mathbb{E} [Y_{[a, b]}] =\mathbb{E}
    \left[ \int_a^b X (t)^2 dt \right] =
    \int_a^b \mathbb{E} [X (t)^2] dt.
  \end{equation}
  By stationarity, $\mathbb{E} [X (t)^2] = \sigma^2$ for all $t$, hence
  \begin{equation}
    \label{eq:expectation_Yab} \mathbb{E} [Y_{[a, b]}] = \sigma^2 (b - a) <
    \infty.
  \end{equation}
  Markov's inequality yields, for $M > 0$,
  \begin{equation}
    \label{eq:markov_inequality} \mathbb{P} (Y_{[a, b]} > M) \le
    \frac{\mathbb{E} [Y_{[a, b]}]}{M} = \frac{\sigma^2 (b - a)}{M},
  \end{equation}
  and letting $M \to \infty$ gives $\mathbb{P} (Y_{[a, b]} < \infty) = 1$. Now
  let $K \subset \mathbb{R}$ be compact, so $K \subseteq [- N, N]$ for some $N
  > 0$. Then
  \begin{equation}
    \label{eq:compact_bound} \int_K X (t)^2 dt \le \int_{-
    N}^N X (t)^2 dt < \infty \quad \text{a.s.}
  \end{equation}
  hence almost every path satisfies $\int_K |X (t, \omega) |^2 
  dt < \infty$ for every compact $K$, i.e. $X (\cdot,
  \omega) \in L^2_{\mathrm{loc}} (\mathbb{R})$.
\end{proof}

\subsection{(Non-Stationary) Oscillatory Processes}\label{sec:oscillatory}

\begin{definition}
  \label{def:osc_proc}\tmtextbf{[Oscillatory process]} Let $F$ be a finite
  nonnegative Borel measure on $\mathbb{R}$. Let
  \begin{equation}
    \label{eq:gain_L2} A_t \in L^2 (F) \quad \forall t \in
    \mathbb{R}
  \end{equation}
  be the gain function and
  \begin{equation}
    \label{eq:oscillatory_function} \varphi_t (\lambda) = A_t (\lambda) 
    e^{i \lambda t}
  \end{equation}
  the corresponding oscillatory function. An oscillatory process is a
  stochastic process represented as
  \begin{equation}
    \label{eq:oscillatory_process} Z (t) =
    \int_{\mathbb{R}} \varphi_t (\lambda) d \Phi (\lambda)
    = \int_{\mathbb{R}} A_t (\lambda) 
    e^{i \lambda t} d \Phi (\lambda),
  \end{equation}
  where $\Phi$ is a complex orthogonal random measure with spectral measure
  $F$ satisfying
  \begin{equation}
    \label{eq:orthogonality_phi} d\mathbb{E} \left[ \Phi
    (\lambda) \overline{\Phi (\mu)} \right] =
    \delta (\lambda - \mu) dF (\lambda)
  \end{equation}
  and covariance
  \begin{equation}
    \label{eq:oscillatory_covariance}
    \begin{aligned}
      R_Z (t, s) = \mathbb{E}
      \left[ Z (t) \overline{Z (s)} \right] & =
      \int_{\mathbb{R}} A_t (\lambda) \overline{A_s (\lambda)}
      e^{i \lambda (t - s)} dF (\lambda)\\
      & = \int_{\mathbb{R}} \varphi_t (\lambda)
      \overline{\varphi_s (\lambda)} dF (\lambda).
    \end{aligned}
  \end{equation}
\end{definition}

\begin{definition}
  \label{def:epsd}\tmtextbf{[Evolutionary power spectral density (EPSD)]} For
  an oscillatory process with gain function $A_t (\lambda)$ and spectral
  measure $F$ having density $S (\lambda)$ (i.e., $dF (\lambda) = S (\lambda)
  d \lambda$), the evolutionary power spectral density is
  \begin{equation}
    \label{eq:epsd_definition} S_t (\lambda) = |A_t (\lambda) |^2 
    S (\lambda),
  \end{equation}
  so that the evolutionary spectral measure is $dF_t (\lambda) = S_t (\lambda)
  d \lambda = |A_t (\lambda) |^2 dF
  (\lambda)$.
\end{definition}

\begin{definition}
  \label{def:variance_evolutionary}\tmtextbf{[Variance of oscillatory
  process]} The variance of an oscillatory process $Z (t)$ is given by
  integrating the evolutionary power spectral density over all frequencies:
  \begin{equation}
    \label{eq:variance_epsd} \tmop{var} (Z (t)) = \int_{- \infty}^{\infty} S_t
    (\lambda) d \lambda = \int_{- \infty}^{\infty} dF_t
    (\lambda).
  \end{equation}
\end{definition}

\begin{theorem}
  \label{thm:realvaluedness}\tmtextbf{[Real-valuedness criterion for
  oscillatory processes]} Let $Z$ be an oscillatory process with oscillatory
  function $\varphi_t (\lambda) = A_t (\lambda) e^{i \lambda
  t}$ and spectral measure $F$. Then $Z$ is real-valued if and only if
  \begin{equation}
    \label{eq:gain_symmetry} A_t (- \lambda) = \overline{A_t (\lambda)} \quad
    \text{for } F \text{-a.e. } \lambda \in \mathbb{R},
  \end{equation}
  equivalently
  \begin{equation}
    \label{eq:osc_symmetry} \varphi_t (- \lambda) = \overline{\varphi_t
    (\lambda)} \quad \text{for } F \text{-a.e. } \lambda \in \mathbb{R}.
  \end{equation}
\end{theorem}

\begin{proof}
  If $Z$ is real-valued, then $Z (t) = \overline{Z (t)}$ for all $t$. Taking
  conjugates in the representation
  \begin{equation}
    \label{eq:real_proof_1} Z (t) = \int A_t (\lambda) e^{i
    \lambda t} d \Phi (\lambda)
  \end{equation}
  and using the symmetry relation for the orthogonal random measure
  appropriate for real-valued processes, a change of variable $\mu = -
  \lambda$ shows that the $L^2 (F)$-integrands must agree $F$-a.e., i.e.
  \begin{equation}
    \label{eq:real_proof_2} A_t (\lambda) = \overline{A_t (- \lambda)},
  \end{equation}
  which is equivalent to \eqref{eq:gain_symmetry}. Using $\varphi_t (\lambda)
  = A_t (\lambda) e^{i \lambda t}$ then gives \eqref{eq:osc_symmetry}. The
  converse follows by reversing the steps.
\end{proof}

\begin{theorem}
  \label{thm:existence_osc}\tmtextbf{[Existence of oscillatory processes with
  explicit $L^2$-limit construction]} Let $F$ be an absolutely continuous
  spectral measure with density $S (\lambda)$ and the gain function $A_t
  (\lambda) \in L^2 (F)$ for all $t \in \mathbb{R}$, measurable jointly in
  $(t, \lambda)$. Define the time-dependent variance
  \begin{equation}
    \label{eq:time_dependent_spectrum} \sigma_t^2 \assign \int_{\mathbb{R}}
    |A_t (\lambda) |^2 dF (\lambda) =
    \int_{\mathbb{R}} S_t (\lambda) d \lambda
    < \infty
  \end{equation}
  where $S_t (\lambda) = |A_t (\lambda) |^2 S (\lambda)$ is the evolutionary
  power spectral density. Then there exists a complex orthogonal random
  measure $\Phi$ with spectral measure $F$ such that for each fixed $t$ the
  stochastic integral
  \begin{equation}
    \label{eq:oscillatory_well_defined} Z (t) =
    \int_{\mathbb{R}} A_t (\lambda) e^{i
    \lambda t} d \Phi (\lambda)
  \end{equation}
  is well-defined as an $L^2 (\Omega)$-limit and has covariance $R_Z$ as in
  \eqref{eq:oscillatory_covariance}.
\end{theorem}

\begin{proof}
  \begin{enumerate}
    \item \tmtextit{Simple functions and isometry.} Let $\mathsf{S}$ denote
    the set of simple functions
    \begin{equation}
      \label{eq:simple_function} g (\lambda) =
      \sum_{j = 1}^n c_j \textbf{1}_{E_j} (\lambda)
    \end{equation}
    with disjoint Borel $E_j$ and $F (E_j) < \infty$, $c_j \in \mathbb{C}$.
    Define the stochastic integral on $\mathsf{S}$ by
    \begin{equation}
      \label{eq:integral_simple} \int_{\mathbb{R}} g (\lambda) 
      d \Phi (\lambda) \assign
      \sum_{j = 1}^n c_j \Phi (E_j)
    \end{equation}
    Using orthogonality of $\Phi$,
    \begin{equation}
      \label{eq:isometry_simple} \mathbb{E} \left[ \left|
      \int g d \Phi \right|^2 \right] = \sum_{j = 1}^n |c_j
      |^2 F (E_j) = \int_{\mathbb{R}} |g (\lambda) |^2 
      dF (\lambda)
    \end{equation}
    Thus the map $I : \mathsf{S} \to L^2 (\Omega)$, $I (g) = \int g
    d \Phi$, is an isometry with respect to the $L^2
    (F)$-norm.
    
    \item \tmtextit{Density and Cauchy property.} Simple functions are dense
    in $L^2 (F)$: for any $h \in L^2 (F)$ there exists $g_n \in \mathsf{S}$
    with $\|h - g_n \|_{L^2 (F)} \to 0$. By \eqref{eq:isometry_simple},
    \begin{equation}
      \label{eq:cauchy_sequence} \mathbb{E} \left[ \left|
      \int g_n d \Phi - \int g_m d \Phi
      \right|^2 \right] = \|g_n - g_m \|_{L^2 (F)}^2
      \xrightarrow[n, m \to \infty]{} 0
    \end{equation}
    so $\left\{ \int g_n d \Phi \right\}$ is Cauchy in $L^2
    (\Omega)$.
    
    \item \tmtextit{Definition by $L^2$-limit and independence of
    approximating sequence.} Since $L^2 (\Omega)$ is complete, the limit
    exists. Define, for $h \in L^2 (F)$,
    \begin{equation}
      \label{eq:L2_limit_def} \int_{\mathbb{R}} h (\lambda) d
      \Phi (\lambda) \assign \lim_{n \to
      \infty} \int_{\mathbb{R}} g_n (\lambda) d \Phi
      (\lambda)
    \end{equation}
    where $g_n \in \mathsf{S}$ and $\|h - g_n \|_{L^2 (F)} \to 0$. If $g_n$
    and $\tilde{g}_n$ are two such approximating sequences, then $\|g_n -
    \tilde{g}_n \|_{L^2 (F)} \to 0$ and again by \eqref{eq:isometry_simple}
    the corresponding integrals differ by an $L^2 (\Omega)$-null sequence, so
    the limit is independent of the sequence.
    
    \item \tmtextit{Isometry and linearity extend.} By continuity from
    \eqref{eq:isometry_simple} and \eqref{eq:L2_limit_def},
    \begin{equation}
      \label{eq:L2_isometry_extension} \mathbb{E} \left[
      \left| \int h d \Phi \right|^2 \right] =
      \int_{\mathbb{R}} |h (\lambda) |^2 dF (\lambda)
    \end{equation}
    for all $h \in L^2 (F)$, and the map $h \mapsto \int h d
    \Phi$ is linear and isometric.
    
    \item \tmtextit{Application to $\varphi_t$.} Since $|e^{i \lambda t} | =
    1$, $\varphi_t (\lambda) = A_t (\lambda) e^{i \lambda t}
    \in L^2 (F)$ and
    \begin{equation}
      \label{eq:varphi_L2} \int_{\mathbb{R}} | \varphi_t (\lambda) |^2 
      dF (\lambda) = \int_{\mathbb{R}} |A_t (\lambda) |^2 
      dF (\lambda) = \sigma_t^2 < \infty
    \end{equation}
    Hence $Z (t)$ in \eqref{eq:oscillatory_well_defined} is well-defined as
    the $L^2 (\Omega)$-limit \eqref{eq:L2_limit_def} with $h = \varphi_t$.
    Computing covariance via sesquilinearity together with
    \eqref{eq:orthogonality_phi} yields \eqref{eq:oscillatory_covariance}.
  \end{enumerate}
\end{proof}

\subsection{Filter Representations and Invertibility for Oscillatory
Processes}

\begin{definition}
  \label{def:filter_gain}\tmtextbf{[Time-dependent filter and gain]} The
  time-dependent filter $h (t, u)$ and gain function $A_t (\lambda)$ satisfy
  the Fourier transform pair
  \begin{equation}
    \label{eq:gain_from_filter} A_t (\lambda) = \int_{- \infty}^{\infty} h (t,
    u) e^{- i \lambda (t - u)} du
  \end{equation}
  \begin{equation}
    \label{eq:filter_from_gain} h (t, u) = \frac{1}{2 \pi} \int_{-
    \infty}^{\infty} A_t (\lambda) e^{i \lambda (t - u)} 
    d \lambda
  \end{equation}
  with square-integrability
  \begin{equation}
    \label{eq:filter_square_int} \int_{- \infty}^{\infty} |h (t, u) |^2 
    du < \infty \quad \forall t \in \mathbb{R}
  \end{equation}
\end{definition}

\begin{theorem}
  \label{thm:general_filter}\tmtextbf{[Forward and inverse filter
  representations for general oscillatory processes]} Let $Z (t)$ be an
  oscillatory process as in Definition \ref{def:osc_proc} with oscillatory
  function $\varphi_t (\lambda) = A_t (\lambda) e^{i \lambda t}$. Then:
  \begin{enumerate}
    \item The forward time-varying filter representation is
    \begin{equation}
      \label{eq:general_forward_filter} Z (t) = \int_{\mathbb{R}} h (t,
      \lambda) d \Phi (\lambda)
    \end{equation}
    with kernel $h (t, \lambda) = A_t (\lambda) e^{i \lambda
    t}$
    
    \item For oscillatory processes with white noise representation $dW (u)$
    satisfying
    \begin{equation}
      \label{eq:whitenoise_orthog} \mathbb{E} [dW (u_1)
      \overline{dW (u_2)}] = \delta (u_1 - u_2) du_1
    \end{equation}
    the process admits
    \begin{equation}
      \label{eq:whitenoise_filter} Z (t) = \int_{- \infty}^{\infty} h (t, u) 
      dW (u)
    \end{equation}
  \end{enumerate}
\end{theorem}

\begin{proof}
  \begin{enumerate}
    \item Equation \eqref{eq:general_forward_filter} is immediate from
    \eqref{eq:oscillatory_process}
    
    \item The white noise representation follows from the spectral relation
    \begin{equation}
      \label{eq:spectral_whitenoise} d \Phi (\lambda) = \frac{1}{2 \pi} \int
      e^{- i \lambda u} dW (u) du
    \end{equation}
    and application of the filter Fourier pair
  \end{enumerate}
\end{proof}

\begin{definition}
  \label{def:amplitude_nondeg}\tmtextbf{[Amplitude nondegeneracy]} The
  amplitude $A_t (\lambda)$ satisfies
  \begin{equation}
    \label{eq:nonzero} A_t (\lambda) \neq 0 \quad \text{for all } (t, \lambda)
    \text{ in the support of } F
  \end{equation}
\end{definition}

\begin{definition}
  \label{def:orthonormality}\tmtextbf{[Kernel orthonormality]} The amplitude
  satisfies
  \begin{equation}
    \label{eq:delta_ortho} \int_{- \infty}^{\infty} A_t (\lambda_1) 
    \overline{A_t (\lambda_2)} e^{i (\lambda_2 -
    \lambda_1) t} dt = \delta (\lambda_1 - \lambda_2)
  \end{equation}
\end{definition}

\begin{theorem}
  \label{thm:fund_inv}\tmtextbf{[Fundamental invertibility for oscillatory
  processes]} For $Z$ as in Definition \ref{def:osc_proc}, the inversion
  formula
  \begin{equation}
    \label{eq:inv_identity} \Phi (\{\lambda\}) = \lim_{\varepsilon \to 0} \int_{- \infty}^{\infty} A_t
    (\lambda) e^{- i \lambda t} Z (t) 
    \chi_{[\lambda - \varepsilon, \lambda + \varepsilon]}(\lambda) dt
  \end{equation}
  holds (in the sense of $L^2(\Omega)$ convergence) if and only if $A_t$ satisfies the nondegeneracy condition
  \eqref{eq:nonzero} and the orthonormality condition \eqref{eq:delta_ortho}.
\end{theorem}

\begin{proof}
  \begin{enumerate}
    \item \tmtextit{Forward direction.} From \eqref{eq:oscillatory_process},
    \begin{equation}
      \label{eq:inv_proof_1} Z (t) = \int_{\mathbb{R}} A_t (\lambda) 
      e^{i \lambda t} d \Phi (\lambda)
    \end{equation}
    Multiply by $\overline{A_t (\lambda_0)} e^{- i \lambda_0 t}$ and integrate over $t$:
    \begin{equation}
      \label{eq:inv_proof_2} \int_{- \infty}^{\infty} \overline{A_t (\lambda_0)} e^{- i
      \lambda_0 t} Z (t) dt = \int_{- \infty}^{\infty} \overline{A_t
      (\lambda_0)} e^{- i \lambda_0 t} \left[ \int_{\mathbb{R}} A_t (\lambda)
      e^{i \lambda t} d \Phi (\lambda) \right] dt
    \end{equation}
    \item \tmtextit{Swap order of integration.}
    \begin{equation}
      \label{eq:inv_proof_3} = \int_{\mathbb{R}} \left[ \int_{-
      \infty}^{\infty} \overline{A_t (\lambda_0)} A_t (\lambda) e^{i (\lambda -
      \lambda_0) t} dt \right] d \Phi (\lambda)
    \end{equation}
    \item \tmtextit{Apply orthonormality.} By \eqref{eq:delta_ortho},
    \begin{equation}
      \label{eq:inv_proof_4} = \int_{\mathbb{R}} \delta (\lambda - \lambda_0) 
      d \Phi (\lambda) = \Phi(\{\lambda_0\})
    \end{equation}
    \item \tmtextit{Backward direction.} Insert
    \begin{equation}
      \label{eq:inv_proof_5} Z_{\lambda_0} (t) = A_t (\lambda_0) e^{i
      \lambda_0 t}
    \end{equation}
    into \eqref{eq:inv_identity}:
    \begin{equation}
      \label{eq:inv_proof_6} \Phi_{\lambda_0} (\lambda) = \int_{-
      \infty}^{\infty} \overline{A_t (\lambda)} e^{- i \lambda t} A_t (\lambda_0) e^{i
      \lambda_0 t} dt
    \end{equation}
    The left side equals $\delta (\lambda - \lambda_0)$, hence
    \eqref{eq:delta_ortho} holds. Nondegeneracy follows from linear
    independence by evaluating at $(t, \lambda)$ where $Z (t) \neq 0$.
  \end{enumerate}
\end{proof}

\begin{lemma}
  \label{lem:unique}\tmtextbf{[Uniqueness of inversion]} If $\mathcal{I}_1 Z =
  d \Phi (\lambda) =\mathcal{I}_2 Z$ for all $Z$, then $\mathcal{I}_1
  =\mathcal{I}_2$.
\end{lemma}

\begin{proof}
  Let $\mathcal{L}=\mathcal{I}_1 -\mathcal{I}_2$. Choose
  \begin{equation}
    \label{eq:unique_proof_1} Z_{\lambda_0} (t) = A_t (\lambda_0) e^{i
    \lambda_0 t}
  \end{equation}
  Then $(\mathcal{L}Z_{\lambda_0}) (\lambda)$ equals
  \begin{equation}
    \label{eq:unique_proof_2} \int_{- \infty}^{\infty} A_t (\lambda) e^{- i
    \lambda t} A_t (\lambda_0) e^{i \lambda_0 t} dt - \int_{- \infty}^{\infty}
    A_t (\lambda) e^{- i \lambda t} A_t (\lambda_0) e^{i \lambda_0 t} dt = 0
  \end{equation}
  Density of the span $\{Z_{\lambda_0} \}$ implies $\mathcal{L}= 0$.
\end{proof}

\section{Unitarily Time-Changed Stationary
Processes}\label{sec:stationary_timechange}

\subsection{Unitary time-change operator $U_{\theta} f$}

\begin{theorem}
  \label{thm:local_unitarity}\tmtextbf{[Unitary time-change and local
  isometry]} Let the time-scaling function $\theta : \mathbb{R} \to
  \mathbb{R}$ be absolutely continuous, strictly increasing, and bijective,
  with
  \begin{equation}
    \label{eq:theta_dot_positive} \dot{\theta} (t) > 0
  \end{equation}
  almost everywhere and $\dot{\theta} (t) = 0$ only on sets of Lebesgue
  measure zero. For $f$ measurable, define
  \begin{equation}
    \label{eq:U_theta_def} (U_{\theta} f) (t) = \sqrt{\dot{\theta} (t)} 
    f (\theta (t))
  \end{equation}
  Its inverse is given by
  \begin{equation}
    \label{eq:U_theta_inverse} (U_{\theta}^{- 1} g) (s) = \frac{g (\theta^{-
    1} (s))}{\sqrt{\dot{\theta} (\theta^{- 1} (s))}}
  \end{equation}
  For every compact set $K \subseteq \mathbb{R}$ and $f \in L^2_{\mathrm{loc}}
  (\mathbb{R})$,
  \begin{equation}
    \label{eq:local_isometry} \int_K | (U_{\theta} f) (t) |^2
    dt = \int_{\theta (K)} |f (s) |^2 ds
  \end{equation}
  Moreover, $U_{\theta}^{- 1}$ is the inverse of $U_{\theta}$ on
  $L^2_{\mathrm{loc}} (\mathbb{R})$.
\end{theorem}

\begin{proof}
  By \eqref{eq:U_theta_def},
  \begin{equation}
    \label{eq:unitarity_proof_1} \int_K | (U_{\theta} f) (t) |^2 dt = \int_K
    \dot{\theta} (t) |f (\theta (t)) |^2 dt
  \end{equation}
  With the change of variables $s = \theta (t)$ and $ds = \dot{\theta} (t)
  dt$, the domain maps to $\theta (K)$, giving \eqref{eq:local_isometry}. The
  two-sided inverse identities follow from direct substitution into
  \eqref{eq:U_theta_def} and \eqref{eq:U_theta_inverse}.
\end{proof}

\subsection{Filter Representations for Unitarily Time-Changed Stationary
Processes}

\begin{theorem}
  \label{thm:inverse_filter}\tmtextbf{[Forward and inverse filter
  representations for unitarily time-changed stationary processes]} Let
  $\theta : \mathbb{R} \to \mathbb{R}$ be absolutely continuous, strictly
  increasing, and bijective with $\theta' (t) > 0$ a.e. Let $X (u) =
  \int_{\mathbb{R}} e^{i \lambda u} d \Phi (\lambda)$ be a
  realization of a stationary process, and set
  \begin{equation}
    \label{eq:Z_transformation} Z (t) = \sqrt{\dot{\theta} (t)} 
    X (\theta (t))
  \end{equation}
  Then:
  \begin{enumerate}
    \item The forward filter kernel is
    \begin{equation}
      \label{eq:forward_kernel} h (t, u) = \sqrt{\dot{\theta} (t)} 
      \delta (u - \theta (t))
    \end{equation}
    \item The inverse filter kernel is
    \begin{equation}
      \label{eq:inverse_kernel} g (t, s) = \frac{\delta (s - \theta^{- 1}
      (t))}{\sqrt{\dot{\theta} (\theta^{- 1} (t))}}
    \end{equation}
    \item The composition $(g \circ h)$ recovers the identity:
    \begin{equation}
      \label{eq:filter_identity} X (t) = \int_{\mathbb{R}} g (t, s) 
      Z (s) ds = \frac{Z (\theta^{- 1}
      (t))}{\sqrt{\dot{\theta} (\theta^{- 1} (t))}}
    \end{equation}
  \end{enumerate}
\end{theorem}

\begin{proof}
  \begin{enumerate}
    \item Using the sifting property of the Dirac delta in
    \eqref{eq:forward_kernel} gives \eqref{eq:Z_transformation}
    
    \item Applying \eqref{eq:inverse_kernel}, then substituting
    \eqref{eq:Z_transformation} at $s = \theta^{- 1} (t)$ and using
    \begin{equation}
      \label{eq:theta_inverse_id} \theta \circ \theta^{- 1} = \mathrm{id}
    \end{equation}
    yields \eqref{eq:filter_identity}
    
    \item The identity follows from items (1) and (2)
  \end{enumerate}
\end{proof}

\subsection{Transformation of stationary to oscillatory processes via
$U_{\theta}$}

\begin{theorem}
  \label{thm:Utheta_to_osc}\tmtextbf{[Unitary time change produces oscillatory
  process]} Let $X$ be zero-mean stationary as in Definition \ref{def:cramer}.
  For a scaling function $\theta$ as in Theorem \ref{thm:local_unitarity},
  define
  \begin{equation}
    \label{eq:Z_def} Z (t) = (U_{\theta} X) (t) = \sqrt{\dot{\theta} (t)} 
    X (\theta (t))
  \end{equation}
  Then $Z$ is a realization of an oscillatory process with oscillatory
  function
  \begin{equation}
    \label{eq:oscillatory_function_Z} \varphi_t (\lambda) = \sqrt{\dot{\theta}
    (t)} e^{i \lambda \theta (t)}
  \end{equation}
  gain function
  \begin{equation}
    \label{eq:gain_function_Z} A_t (\lambda) = \sqrt{\dot{\theta} (t)} 
    e^{i \lambda (\theta (t) - t)}
  \end{equation}
  and covariance
  \begin{equation}
    \label{UTCovar}
    \begin{aligned}
      R_Z (t, s) & =\mathbb{E} \left[ Z (t)
      \overline{Z (s)} \right] = \sqrt{\dot{\theta} (t) \dot{\theta} (s)} 
      \mathbb{E} \left[ X (\theta (t))
      \overline{X (\theta (s))} \right]\\
      & = \sqrt{\dot{\theta} (t) \dot{\theta} (s)} R_X 
      (\theta (t) - \theta (s)) = \sqrt{\dot{\theta} (t) 
      \dot{\theta} (s)} \int_{\mathbb{R}} e^{i \lambda (\theta (t) - \theta
      (s))} dF (\lambda)
    \end{aligned}
  \end{equation}
\end{theorem}

\begin{proof}
  From the Cram{\'e}r representation \eqref{eq:cramer_representation},
  \begin{equation}
    \label{eq:osc_proof_1} X (\theta (t)) = \int e^{i \lambda \theta (t)} 
    d \Phi (\lambda)
  \end{equation}
  Therefore
  \begin{equation}
    \label{eq:osc_proof_2} Z (t) = \sqrt{\dot{\theta} (t)} \int_{\mathbb{R}}
    e^{i \lambda \theta (t)} d \Phi (\lambda) =
    \int_{\mathbb{R}} \left( \sqrt{\dot{\theta} (t)} e^{i
    \lambda \theta (t)} \right) d \Phi (\lambda) = \int \varphi_t (\lambda) 
    d \Phi (\lambda)
  \end{equation}
  which is of the oscillatory form with $\varphi_t$ as in
  \eqref{eq:oscillatory_function_Z} and $A_t$ as in
  \eqref{eq:gain_function_Z}. The covariance follows from stationarity via
  \eqref{eq:stationary_covariance}.
\end{proof}

\begin{corollary}
  \label{cor:epsd_timechange}\tmtextbf{[Evolutionary power spectral density of
  unitarily time-changed stationary process]} If the stationary spectral
  measure has density $S (\lambda)$, i.e. $dF (\lambda) = S (\lambda) d
  \lambda$, then the evolutionary power spectral density of $Z (t) =
  U_{\theta} X (t)$ is
  \begin{equation}
    \label{eq:epsd_timechange} S_t (\lambda) = |A_t (\lambda) |^2 
    S (\lambda) = \dot{\theta} (t) S
    (\lambda)
  \end{equation}
  and therefore
  \begin{equation}
    \label{eq:epsd_measure} dF_t (\lambda) = S_t (\lambda) d
    \lambda = \dot{\theta} (t) dF (\lambda)
  \end{equation}
\end{corollary}

\begin{proof}
  Since
  \begin{equation}
    \label{eq:epsd_proof_1} |e^{i \alpha} | = 1
  \end{equation}
  we have
  \begin{equation}
    \label{eq:epsd_proof_2} |A_t (\lambda) |^2 = \dot{\theta} (t)
  \end{equation}
  giving \eqref{eq:epsd_timechange}.
\end{proof}

\subsection{Covariance operator conjugation}

\begin{proposition}
  \label{prop:conjugation}\tmtextbf{[Operator conjugation]} Let
  \begin{equation}
    \label{eq:T_K_def} (T_K f) (t) \assign \int_{\mathbb{R}} K (|t - s|) 
    f (s) ds
  \end{equation}
  with stationary kernel
  \begin{equation}
    \label{eq:K_def} K (h) = \int_{\mathbb{R}} e^{i \lambda h} 
    dF (\lambda)
  \end{equation}
  Define the transformed kernel
  \begin{equation}
    \label{eq:K_theta_def} K_{\theta} (s, t) \assign \sqrt{\dot{\theta} (t) 
    \dot{\theta} (s)} K (| \theta (t) -
    \theta (s) |)
  \end{equation}
  Then for all $f \in L^2_{\mathrm{loc}} (\mathbb{R})$,
  \begin{equation}
    \label{eq:conjugation} (T_{K_{\theta}} f) (t) = \left( U_{\theta} 
    T_K U_{\theta}^{- 1} f \right) (t)
  \end{equation}
\end{proposition}

\begin{proof}
  Compute
  \begin{equation}
    \label{eq:conj_proof_1} (U_{\theta} T_K U_{\theta}^{- 1} f) (t) =
    \sqrt{\dot{\theta} (t)} (T_K U_{\theta}^{- 1} f) (\theta
    (t)) = \sqrt{\dot{\theta} (t)} \int_{\mathbb{R}} K (| \theta (t) - s|)
    \frac{f (\theta^{- 1} (s))}{\sqrt{\dot{\theta} (\theta^{- 1} (s))}} 
    ds
  \end{equation}
  With $s = \theta (u)$, $ds = \dot{\theta} (u) du$, obtain
  \begin{equation}
    \label{eq:conj_proof_2} \sqrt{\dot{\theta} (t)} \int_{\mathbb{R}} K (|
    \theta (t) - \theta (u) |) \sqrt{\dot{\theta} (u)} 
    f (u) du = \int_{\mathbb{R}} K_{\theta}
    (u, t) f (u) du = (T_{K_{\theta}} f) (t)
  \end{equation}
\end{proof}

\section{Zero Localization}\label{sec:HP}

\begin{theorem}
  \label{thm:bulinskaya}\tmtextbf{[Bulinskaya's theorem: simplicity of zeros]}
  Let $X (t)$ be a real-valued, zero-mean stationary Gaussian process with
  covariance function $R (h) =\mathbb{E} [X (t) X (t + h)]$. Suppose $R (h)$
  is twice continuously differentiable in a neighborhood of $h = 0$ with $R''
  (0) < 0$. Then almost surely all zeros of $X (t)$ are simple, meaning
  \begin{equation}
    \label{eq:simple_zeros_guaranteed} X (t_0) = 0 \Rightarrow
    \dot{X} (t_0) \neq 0 \quad \text{almost surely}
  \end{equation}
\end{theorem}

\begin{proof}
  \begin{enumerate}
    \item \tmtextit{Differentiability of sample paths.} The twice continuous
    differentiability of $R (h)$ at $h = 0$ ensures that $X (t)$ has
    mean-square continuous first derivative $\dot{X} (t)$, and the joint
    process $(X (t), \dot{X} (t))$ is a Gaussian vector for each $t$.
    
    \item \tmtextit{Covariance structure at zeros.} At any $t_0$, the random
    vector $(X (t_0), \dot{X} (t_0))$ has covariance matrix
    \begin{equation}
      \label{eq:bul_cov_matrix} \Sigma = \left(\begin{array}{cc}
        R (0) & 0\\
        0 & - R'' (0)
      \end{array}\right)
    \end{equation}
    The off-diagonal entries vanish because
    \begin{equation}
      \label{eq:bul_cov_offdiag} \mathbb{E} [X (t_0) \dot{X} (t_0)] = \lim_{h
      \to 0} \frac{\mathbb{E} [X (t_0) (X (t_0 + h) - X (t_0))]}{h} = \lim_{h
      \to 0} \frac{R (h) - R (0)}{h} = R' (0) = 0
    \end{equation}
    by stationarity (which forces $R' (0) = 0$).
    
    \item \tmtextit{Independence at zeros.} Since $(X (t_0), \dot{X} (t_0))$
    is jointly Gaussian with zero correlation, $X (t_0)$ and $\dot{X} (t_0)$
    are independent random variables.
    
    \item \tmtextit{Probability of double zero.} For any fixed $t_0$, the
    event $\{X (t_0) = 0\}$ has probability zero (since $X (t_0)$ is a
    continuous Gaussian random variable). Moreover, the event $\{X (t_0) = 0
    \text{ and } \dot{X} (t_0) = 0\}$ is the intersection of two independent
    zero-probability events, hence also has probability zero.
    
    \item \tmtextit{Countable union argument.} Consider any interval $[a, b]$.
    By continuity of $X (t)$, the zero set $\mathcal{Z}= \{t \in [a, b] : X
    (t) = 0\}$ is closed. The Gaussian process theory (specifically the
    Bulinskaya-Belyaev results) shows that under the condition $R'' (0) < 0$,
    the expected number of zeros in $[a, b]$ is finite:
    \begin{equation}
      \label{eq:expected_zeros} \mathbb{E} [N_{[a, b]}] = \frac{(b - a)}{\pi} 
      \sqrt{- \frac{R'' (0)}{R (0)}} < \infty
    \end{equation}
    This implies that almost surely $\mathcal{Z}$ is discrete (has no
    accumulation points in $[a, b]$), hence is at most countable.
    
    \item \tmtextit{Conclusion.} For each zero $t_n \in \mathcal{Z}$, the
    probability that $\dot{X} (t_n) = 0$ given $X (t_n) = 0$ is zero by
    independence from item (3). Taking a countable union over all zeros in
    $\mathcal{Z}$,
    \begin{equation}
      \label{eq:bul_conclusion} \mathbb{P} \left( \exists t_n
      \in \mathcal{Z}: \dot{X} (t_n) = 0 \right) = 0
    \end{equation}
    Thus almost surely every zero is simple.
  \end{enumerate}
\end{proof}

\begin{corollary}
  \label{cor:oscillatory_simple_zeros}Let $Z (t) = \sqrt{\dot{\theta} (t)} 
  X (\theta (t))$ be the unitarily time-changed stationary
  Gaussian process constructed in Theorem \ref{thm:Utheta_to_osc}, where $X$
  has twice continuously differentiable covariance with $R''_X (0) < 0$. Then
  almost surely all zeros of $Z (t)$ are simple.
\end{corollary}

\begin{proof}
  The covariance of $Z$ is
  \begin{equation}
    \label{eq:cor_Z_cov} R_Z (t, s) = \sqrt{\dot{\theta} (t) \dot{\theta}
    (s)} R_X (\theta (t) - \theta (s))
  \end{equation}
  Since $\theta$ is strictly increasing with $\dot{\theta}(t) > 0$, and $X$ has twice continuously differentiable covariance with $R''_X(0) < 0$, the transformed process $Z$ inherits the regularity properties needed to apply Bulinskaya's theorem. Specifically, $Z(t)$ and $\dot{Z}(t)$ are jointly Gaussian with the appropriate covariance structure at zeros, ensuring that almost all zeros are simple.
\end{proof}

\end{document}

