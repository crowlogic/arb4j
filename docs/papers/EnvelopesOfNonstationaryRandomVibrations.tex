\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{cite}

\geometry{margin=1in}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

\title{NONSTATIONARY ENVELOPE IN RANDOM VIBRATION THEORY}
\author{Giuseppe Muscolino\footnote{Researcher, Dipartimento di Ingegneria Strutturale e Geotecnica, Universit\`{a} degli Studi di Palermo, Viale delle Scienze, I-90128 Palermo, Italy.}}
\date{}

\begin{document}

\maketitle

\begin{abstract}
In this paper, it is shown that the input process in the nonstationary case must be defined as a complex process, i.e., as the product of an analytic random stationary process by a deterministic shaping function. Defining the input in this manner, the complex nonstationary cross-correlation matrix is evaluated, and the nonstationary spectral moments take on a self-evident physical meaning as variances of the complex response and of its time derivatives. Using the complex process, the nonstationary envelope, too, becomes a natural consequence of the previous definition, i.e., the modulus of the complex response of linear systems subjected to such input. In the framework of complex processes, the mean rate threshold crossing for circular barriers and the first-passage probability are evaluated using the one-step memory Markov process.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

The problem of predicting the safety of structural systems subjected to random loading arises in many engineering applications. It is well-known that such loadings as aircraft impact during landing are nonstationary random processes. It follows that the response of quiescent systems is also nonstationary and that the prediction of their structural safety is an important topic in structural engineering.

In the framework of the prediction of structural safety, the envelope process \cite{langley1986} plays an important role. For example, in the problem of first excursion failure and that of fatigue failure, evaluating the statistical properties of the envelope process becomes an important task in both stationary \cite{yang1971} and nonstationary \cite{yang1972} response processes. In the stationary case, the envelope process is usually defined following \cite{dugundji1958} and \cite{cramer1967}, and it can be seen as the modulus of the response of a linear system subjected to a complex process called pre-envelope \cite{arens1957,dugundji1958}, which is a complex process in which the imaginary part is the Hilbert transform of the companion real part.

In previous papers \cite{borino1988,dipaola1985}, it has been demonstrated that the complex processes must be introduced not only for the definition of the envelope process, but also to give a clearer definition of stationary and nonstationary spectral moments, which are simply variances of the complex response and its time derivatives in structural systems subjected to such input \cite{dipaola1985}.

In this paper, which defines the nonstationary pre-envelope process as the product of a deterministic shaping function by the pre-envelope of a stationary random process, a critical review and extensions of the well-known stationary concept are made in the nonstationary case. The complex cross-correlation matrix of the response of a single-degree-of-freedom (SDOF) linear system subjected to such input are obtained, as well as the time derivatives of the response.

In the last sections, the nonstationary cross-correlation function and the nonstationary spectral moments are used in the evaluation of the mean rate threshold crossing for circular barriers and in the first-passage probability problem for the Poisson and Markov assumption of level crossing.

\section{Preliminary Concepts and Definitions}
\label{sec:preliminaries}

\subsection{Stationary Case}
\label{sec:stationary}

The equation of motion of an SDOF system may be written in the canonical form as follows:
\begin{equation}
\ddot{x} + 2\zeta\omega_0\dot{x} + \omega_0^2 x = f(t)
\label{eq:motion}
\end{equation}
where $\zeta$ and $\omega_0$ are the damping ratio and the natural radian frequency, respectively; the displacement $x(t)$ is the solution of equation~\eqref{eq:motion}; the upper dot indicates time differentiation; and $f(t)$ is a stochastic zero-mean process.

It is well-known that for the stationary analysis of linear systems, the function that characterizes both the input and output processes is the power spectral density function (PSD). Though from a mathematical viewpoint the PSD is defined in the frequency range $-\infty$ to $\infty$, from the physical viewpoint the power is defined only in the positive frequency range. In the last few years, it has been shown that the one-sided PSD (defined as $0$-$\infty$) is required in order to obtain some significant quantities in the evaluation of the statistics of the stochastic response \cite{vanmarcke1972,vanmarcke1975}. It is defined as the product of the Heaviside function $U(\omega)$ by twice the PSD (defined as $-\infty$-$\infty$), i.e.
\begin{equation}
G_f(\omega) = 2U(\omega)\bar{G}_f(\omega)
\label{eq:psd_onesided}
\end{equation}
where the overbar indicates the usual PSD (defined as $-\infty$-$\infty$). On the other hand, in order to obtain a process that defines the one-sided PSD in equation~\eqref{eq:psd_onesided}, the corresponding process $f(t)$ in the time domain must be a complex one, in which the imaginary part is the Hilbert transform of the corresponding real part, i.e., an analytic process \cite{dipaola1985}. This process is the so-called pre-envelope \cite{arens1957,dugundji1958} (see Appendix~\ref{app:psd}) and is given as
\begin{equation}
f(t) = n(t) + i\hat{n}(t)
\label{eq:preenvelope}
\end{equation}
where $n(t)$ is the stationary process having the usual PSD, $G_n(\omega)$; $i = \sqrt{-1}$; and the accent $(\hat{})$ means Hilbert transform:
\begin{equation}
H[n(t)] = \hat{n}(t) = \frac{1}{\pi} \int_{-\infty}^{\infty} \frac{n(\tau)}{t-\tau} d\tau
\label{eq:hilbert}
\end{equation}

Due to the fact that input is analytic, the corresponding output is analytic as well \cite{krenk1981}, i.e.
\begin{equation}
x(t) = y(t) + i\hat{y}(t)
\label{eq:output_analytic}
\end{equation}
where $y(t)$ is the response of the oscillator subjected to the real process $n(t)$. The process $x(t)$ can be considered as a point in the rectangular coordinates of the plane $y(t)/i\hat{y}(t)$, while in polar coordinates the process $x(t)$ can be written in the form:
\begin{equation}
x(t) = a(t) \exp[i\vartheta(t)]
\label{eq:polar}
\end{equation}
where $a(t)$ and $\vartheta(t)$ are a pair of random processes called the amplitude and the phase, respectively. It is to be noted that $y(t)$ and $\hat{y}(t)$ are given in polar coordinates in the form
\begin{align}
y(t) &= a(t) \cos[\vartheta(t)] \label{eq:polar_y}\\
\hat{y}(t) &= a(t) \sin[\vartheta(t)] \label{eq:polar_yhat}
\end{align}

In equations~\eqref{eq:polar} and~\eqref{eq:polar_y}-\eqref{eq:polar_yhat}, following the primary definition of \cite{dugundji1958} and \cite{cramer1967}, $a(t)$ is the so-called envelope function of the process $x(t)$ and is the modulus of the complex process $x(t)$ defined in equation~\eqref{eq:output_analytic}, i.e.
\begin{equation}
a(t) = \sqrt{y^2(t) + \hat{y}^2(t)}
\label{eq:envelope}
\end{equation}

Notice that the process $a(t)$ is defined in the range $0$-$\infty$, while $\vartheta(t)$ is defined in the range $0$-$2\pi$ and is given as
\begin{equation}
\vartheta(t) = \tan^{-1}\left(\frac{\hat{y}(t)}{y(t)}\right)
\label{eq:phase}
\end{equation}

\subsection{Nonstationary Case}
\label{sec:nonstationary}

In the nonstationary case, a quite different situation is observed. If we construct a complex input process in which the imaginary part is the Hilbert transform of the corresponding real part, it follows that the imaginary part of the output is different from zero for $-\infty < t < 0$, and the corresponding envelope exists in the negative time region, in contrast with its own physical meaning. Thus in the nonstationary case, the complex input process of equation~\eqref{eq:motion} must be defined as the product of a deterministic real shaping function $F(t)$ by the pre-envelope of a stationary process, i.e.
\begin{equation}
f(t) = F(t)[n(t) + i\hat{n}(t)]
\label{eq:nonstationary_input}
\end{equation}

Assuming the latter as input, the corresponding output will be given in the form:
\begin{equation}
x(t) = y(t) + i\tilde{y}(t)
\label{eq:nonstationary_output}
\end{equation}
where $y(t)$ is the response of equation~\eqref{eq:motion} when the input is $F(t)n(t)$. Equations~\eqref{eq:nonstationary_input} and~\eqref{eq:nonstationary_output} are the extensions of the pre-envelope of the input and output processes, respectively, in the nonstationary case. It is also evident that $\tilde{y}(t)$ coincides with $\hat{y}(t)$ only when $F(t) = 1$ $\forall t$ (stationary case).

Due to the fact that the envelope $a(t)$ is defined as the amplitude of the complex output process, as in the stationary case, we can write
\begin{equation}
a(t) = \sqrt{y^2(t) + \tilde{y}^2(t)}
\label{eq:nonstationary_envelope}
\end{equation}
and the corresponding nonstationary phase is given as
\begin{equation}
\vartheta(t) = \tan^{-1}\left(\frac{\tilde{y}(t)}{y(t)}\right)
\label{eq:nonstationary_phase}
\end{equation}

Notice that equation~\eqref{eq:nonstationary_input} is the only correct definition of complex input for separable processes. Moreover, it can easily be shown that the previously defined nonstationary envelope coincides with the definition of envelope given by \cite{yang1972}, using the \cite{priestley1967} spectral representation of stochastic processes.

\section{Cross-Correlation Matrix of Complex Processes}
\label{sec:correlation_matrix}

To obtain the statistics of the envelope process, the cross-correlation matrix of the process $x(t)$ and its time differentiations must be evaluated. To this purpose, a vector $\mathbf{X}_m(t)$ is introduced in the form
\begin{equation}
\mathbf{X}_m(t) = \left[x(t), \frac{dx(t)}{dt}, \ldots, \frac{d^{m-1}x(t)}{dt^{m-1}}\right]^T
\label{eq:vector_x}
\end{equation}
where the superscript $T$ denotes transpose; and $x(t)$ is the complex process defined in equation~\eqref{eq:output_analytic} for the stationary case and in equation~\eqref{eq:nonstationary_output} for the nonstationary case. It follows that the cross-correlation matrix of the vector $\mathbf{X}_m(t)$ can be obtained as
\begin{equation}
\mathbf{R}_{m,x}(t_1, t_2) = E[\mathbf{X}_m(t_1)\mathbf{X}_m^*(t_2)]
\label{eq:correlation_matrix}
\end{equation}
where $(*)$ denotes complex conjugate; and $E[\cdot]$ denotes stochastic average. In order to evaluate the various entries of the matrix $\mathbf{R}_{m,x}(t_1, t_2)$, all stochastic averages of the product of the various time derivatives of $x(t_1)$ and $x(t_2)$ must be computed \cite{borino1988,dipaola1985,dipaola1985b}, i.e.
\begin{equation}
p_{s,v,x}(t_1, t_2) = E\left[\frac{d^s x(t_1)}{dt_1^s} \frac{d^v x^*(t_2)}{dt_2^v}\right]
\label{eq:cross_correlation_entry}
\end{equation}

Though in the last two sections only the first two entries of the correlation matrix are used, hereafter, for the sake of completeness, the general case involving time derivatives up to the $(m-1)$th order is treated. To obtain the cross-correlation function given in equation~\eqref{eq:cross_correlation_entry}, the various time differentiations of the process $x(t)$ must be evaluated. For this purpose, using the Duhamel integral representation of the quiescent system subjected to the process defined in equation~\eqref{eq:nonstationary_input} and also using the Leibnitz rule applied to this case, we write
\begin{equation}
\frac{d^r x(t_1)}{dt_1^r} = \sum_{k=0}^{r} \binom{r}{k} \frac{d^{r-k} h(t_1)}{dt_1^{r-k}} \int_0^{t_1} \frac{d^k}{dt_1^k} f(t_1 - \tau_1) d\tau_1, \quad r = s,v
\label{eq:leibnitz}
\end{equation}
where $h(t)$ is the impulse response function:
\begin{equation}
h(t) = \frac{1}{\omega_D} \exp(-\zeta\omega_0 t) \sin(\omega_D t), \quad t \geq 0; \quad h(t) = 0, \quad t < 0
\label{eq:impulse_response}
\end{equation}
and $\omega_D = \omega_0\sqrt{1-\zeta^2}$. It is worth noting that the impulse response function defined in equation~\eqref{eq:impulse_response} exhibits a slope discontinuity in $t = 0$. It follows that the second derivatives of $h(t)$ exhibit a Dirac delta in $t = 0$, while the higher derivatives exhibit discontinuity of a higher order. However, due to the fact that the Leibnitz rule has been used, the various derivatives that appear in equation~\eqref{eq:leibnitz} must be evaluated in $t = 0^+$. On the other hand, equation~\eqref{eq:leibnitz} can be rewritten in a more suitable form for the following analysis by dropping the last summation and considering the various derivatives of the impulse response function in $t = 0$, i.e.
\begin{equation}
\frac{d^r x(t_1)}{dt_1^r} = \sum_{k=0}^{r-2} \binom{r}{k} \beta_{r-k-1} \frac{d^k}{dt_1^k} f(t_1) + \int_0^{t_1} \frac{d^r h(t_1 - \tau_1)}{dt_1^r} f(t_1 - \tau_1) d\tau_1
\label{eq:derivative_form}
\end{equation}
in which $\delta(t)$ is the Dirac's delta; and $g(t)$ is given as
\begin{equation}
g(t) = \frac{1}{\omega_D} \exp(-\zeta\omega_0 t) \cos(\omega_D t), \quad t \geq 0; \quad g(t) = 0, \quad t < 0
\label{eq:g_function}
\end{equation}
and
\begin{align}
\alpha_r &= -\zeta\omega_0 \alpha_{r-1} - \omega_D^2 \beta_{r-1} \label{eq:alpha_recursion}\\
\alpha_0 &= 1 \label{eq:alpha_initial}
\end{align}
\begin{align}
\beta_r &= -\zeta\omega_0 \beta_{r-1} + \omega_D \alpha_{r-1} \label{eq:beta_recursion}\\
\beta_0 &= 0 \label{eq:beta_initial}
\end{align}

It follows that, using equation~\eqref{eq:derivative_form} to represent the high derivatives of $h(t)$ instead of the Leibnitz rule, we can write in a more concise manner
\begin{equation}
\frac{d^r x(t_1)}{dt_1^r} = \sum_{k=0}^{r-2} \binom{r}{k} \beta_{r-k-1} \frac{d^k}{dt_1^k} f(t_1) + \int_0^{t_1} \frac{d^r h(t_1 - \tau_1)}{dt_1^r} f(t_1 - \tau_1) d\tau_1
\label{eq:concise_derivative}
\end{equation}

Observing that the following relationship holds (see Appendix~\ref{app:psd}):
\begin{equation}
E[f(t_1 - \tau_1)f^*(t_2 - \tau_2)] = F(t_1 - \tau_1)F(t_2 - \tau_2)[p_n(\gamma) + ip_{\hat{n}}(\gamma)]
\label{eq:cross_correlation_f}
\end{equation}
and substituting equation~\eqref{eq:concise_derivative} into equation~\eqref{eq:cross_correlation_entry}, the cross-correlation function can be written in the form:
\begin{equation}
p_{s,v,x}(t_1, t_2) = \int_0^{t_1} \int_0^{t_2} \frac{d^s h(\tau_1)}{dt_1^s} \frac{d^v h(\tau_2)}{dt_2^v} F(t_1 - \tau_1)F(t_2 - \tau_2)[p_n(\gamma) + ip_{\hat{n}}(\gamma)] d\tau_1 d\tau_2
\label{eq:cross_correlation_general}
\end{equation}
where
\begin{equation}
\gamma = t_1 - t_2 + \tau_1 - \tau_2
\label{eq:gamma}
\end{equation}

In equations~\eqref{eq:cross_correlation_f} and~\eqref{eq:cross_correlation_general}, $p_n(\gamma)$ and $p_{\hat{n}}(\gamma)$ are the autocorrelation functions of the stationary process $n(t)$ and its Hilbert transform, respectively.

It is worth noting that using equation~\eqref{eq:leibnitz}, an equivalent expression of the $p_{s,v,x}(t_1, t_2)$ function can also be obtained, but its mathematical form is more complicated than that given in equation~\eqref{eq:cross_correlation_general}.

For our purposes, a more suitable expression of the cross-correlation function given in equation~\eqref{eq:cross_correlation_general} can be obtained by using the representation of $p_n(\gamma)$ and $p_{\hat{n}}(\gamma)$ as the inverse of the Fourier transform of the PSD \cite{papoulis1984}, i.e.
\begin{align}
p_n(\gamma) &= E[n(t)n(t + \gamma)] = \int_{-\infty}^{\infty} G_n(\omega) e^{i\omega\gamma} d\omega \label{eq:pn_fourier}\\
p_{\hat{n}}(\gamma) &= E[\hat{n}(t)n(t + \gamma)] = -i \int_{-\infty}^{\infty} \text{sgn}(\omega) G_n(\omega) e^{i\omega\gamma} d\omega \label{eq:pnhat_fourier}
\end{align}

Substituting the latter into equation~\eqref{eq:cross_correlation_general} and changing the order of integration we obtain
\begin{equation}
p_{s,v,x}(t_1, t_2) = 4 \int_{-\infty}^{\infty} U(\omega) G_n(\omega) e^{i\omega(t_1-t_2)} K_s(\omega, t_1) K_v^*(\omega, t_2) d\omega
\label{eq:cross_correlation_frequency}
\end{equation}
where
\begin{equation}
K_r(\omega, t) = \int_0^t \frac{d^r h(\tau)}{dt^r} F(t - \tau) e^{i\omega\tau} d\tau, \quad r = s,v; \quad t = t_1, t_2
\label{eq:k_function}
\end{equation}

For $s = v = 0$ and $t_1 = t_2 = t$, the integrand in equation~\eqref{eq:cross_correlation_frequency} is the so-called evolutionary PSD \cite{corotis1977,corotis1972,grossmayer1977}, namely:
\begin{equation}
G_x(\omega, t) = 4U(\omega) G_n(\omega) K_0(\omega, t) K_0^*(\omega, t)
\label{eq:evolutionary_psd}
\end{equation}
which is a one-sided function and shows how the frequency content changes with time. Due to the fact that the following inequality:
\begin{equation}
K_r(\omega, t) \neq (i\omega)^r K_0(\omega, t)
\label{eq:inequality}
\end{equation}
holds true for $r > 0$, the correlation function defined in equation~\eqref{eq:cross_correlation_frequency} cannot be evaluated by means of the evolutionary PSD. It follows that the latter is not able to give the counterpart in the frequency domain of the various derivatives of the correlation function. By contrast, in the stationary case, equation~\eqref{eq:inequality} becomes an identity for any order of $r$.

\subsection{Stationary Particularization}
\label{sec:stationary_particularization}

Hereafter, the cross-correlation function is obtained in the stationary case. Putting $t \to \infty$ and $F(t) = 1$ $\forall t$ in equation~\eqref{eq:cross_correlation_frequency}, it follows that the function $K_r(\omega, \infty)$ can be written in the form
\begin{equation}
K_r(\omega, \infty) = \int_0^{\infty} \frac{d^r h(\tau)}{dt^r} e^{i\omega\tau} d\tau = (i\omega)^r K_0(\omega, \infty), \quad r = s,v
\label{eq:stationary_k}
\end{equation}
where $K_0(\omega, \infty)$ is the complex conjugate of the transfer function in terms of displacement, given as
\begin{equation}
K_0(\omega, \infty) = H^*(\omega) = \frac{1}{\omega_0^2 - \omega^2 - 2i\zeta\omega_0\omega}
\label{eq:transfer_function}
\end{equation}

It follows that by setting $\tau = t_2 - t_1$ in equation~\eqref{eq:cross_correlation_frequency}, the cross-correlation function can be written in the well-known simpler form:
\begin{equation}
p_{s,v,x}(\tau) = 4 \int_{-\infty}^{\infty} U(\omega) G_n(\omega) [(-i\omega)^s H(\omega)][(i\omega)^v H^*(\omega)] e^{i\omega\tau} d\omega
\label{eq:stationary_correlation}
\end{equation}

It is worth noting that while in the nonstationary case the correlation function defined in equation~\eqref{eq:cross_correlation_frequency} takes on different values when the order of differentiation changes, i.e., it depends on $s$ and $v$ being taken separately, in the stationary case the correlation function depends on the sum of $s$ and $v$, i.e.
\begin{align}
p_{2r,x}(\tau) &= (-1)^r E\left[\frac{d^r x(t)}{dt^r} \frac{d^r x^*(t + \tau)}{dt^r}\right] \quad (2r = s + v) \label{eq:stationary_2r}\\
p_{2r+1,x}(\tau) &= (-1)^r E\left[\frac{d^r x(t)}{dt^r} \frac{d^{r+1} x^*(t + \tau)}{dt^{r+1}}\right] \quad (2r+1 = s + v) \label{eq:stationary_2r1}
\end{align}

If the time derivatives of all orders of $p_{0,x}(\tau)$ exist, an equivalent definition of $p_{j,x}(\tau)$ ($j = 2r, 2r+1$) can be written in the form
\begin{align}
p_{2r,x}(\tau) &= (-1)^r \frac{d^{2r} p_{0,x}(\tau)}{d\tau^{2r}} \label{eq:derivative_2r}\\
p_{2r+1,x}(\tau) &= (-1)^{r+1} \frac{d^{2r+1} p_{0,x}(\tau)}{d\tau^{2r+1}} \label{eq:derivative_2r1}
\end{align}

Notice that in equations~\eqref{eq:stationary_2r}-\eqref{eq:derivative_2r1} the imaginary part of $p_{2r,x}(\tau)$ and the real part of $p_{2r+1,x}(\tau)$ are the Hilbert transforms of the corresponding real and imaginary parts, respectively.

\section{Cross-Covariance Spectral Matrix}
\label{sec:spectral_matrix}

In this section, the special cases defined by $\tau = 0$ in equation~\eqref{eq:stationary_correlation} and $t_1 = t_2 = t$ in equation~\eqref{eq:cross_correlation_frequency} will be discussed, obtaining the so-called spectral moments in the stationary and nonstationary cases, respectively. The manner in which these quantities play a fundamental role in the study of the statistics of the envelope will be discussed in the following sections.

\subsection{Stationary Case}
\label{sec:spectral_stationary}

In the stationary case, setting $\tau = 0$ in equation~\eqref{eq:stationary_correlation}, we obtain
\begin{equation}
p_{s,v,x}(0) = 4(-i)^s \int_{-\infty}^{\infty} U(\omega) G_n(\omega) H(\omega) H^*(\omega) \omega^{s+v} d\omega
\label{eq:spectral_moment_stationary}
\end{equation}

The integral in equation~\eqref{eq:spectral_moment_stationary} represents the moments of the one-sided PSD with respect to the frequency origin, i.e., the so-called spectral moments \cite{vanmarcke1972}
\begin{equation}
\lambda_{s+v,x} = 4 \int_{-\infty}^{\infty} \omega^{s+v} U(\omega) G_n(\omega) H(\omega) H^*(\omega) d\omega
\label{eq:spectral_moment_def}
\end{equation}

Substituting equation~\eqref{eq:spectral_moment_def} into equation~\eqref{eq:spectral_moment_stationary}, we obtain
\begin{equation}
p_{s,v,x}(0) = (-i)^s \lambda_{s+v,x}
\label{eq:spectral_moment_relation}
\end{equation}

It follows that the correlation matrix evaluated for $t_1 = t_2$ in the stationary case becomes a Hermitian time-independent matrix, namely the so-called cross-covariance spectral (CCS) matrix \cite{borino1988}
\begin{equation}
\mathbf{R}_{m,x}(0) = \boldsymbol{\Lambda}_{m,x} = \begin{bmatrix}
\lambda_{0,x} & -i\lambda_{1,x} & -\lambda_{2,x} & i\lambda_{3,x} & \cdots \\
i\lambda_{1,x} & \lambda_{2,x} & -i\lambda_{3,x} & -\lambda_{4,x} & \cdots \\
-\lambda_{2,x} & i\lambda_{3,x} & \lambda_{4,x} & -i\lambda_{5,x} & \cdots \\
-i\lambda_{3,x} & -\lambda_{4,x} & i\lambda_{5,x} & \lambda_{6,x} & \cdots \\
\vdots & \vdots & \vdots & \vdots & \ddots
\end{bmatrix}
\label{eq:ccs_matrix}
\end{equation}

Equation~\eqref{eq:ccs_matrix} shows that the various entries in the correlation matrix evaluated in $\tau = 0$ are related to the spectral moments defined in equation~\eqref{eq:spectral_moment_def}.

\subsection{Nonstationary Case}
\label{sec:spectral_nonstationary}

As has been previously shown, in the stationary case there is a perfect duality between the time domain and the frequency one, i.e., in the former (see, e.g., equations~\eqref{eq:stationary_2r}-\eqref{eq:spectral_moment_relation}), the spectral moments are variances of analytical processes, while in the latter they are moments of the one-sided PSD (see, e.g., equation~\eqref{eq:spectral_moment_def}). In the nonstationary case, the spectral moments of the evolutionary PSD are given as
\begin{equation}
\lambda_j^*(t) = \int_{-\infty}^{\infty} \omega^j G_x(\omega, t) d\omega
\label{eq:evolutionary_moments}
\end{equation}

They have the physical meaning of variances of analytical processes only for $j = 0$, as demonstrated in the previous section, as, in fact, equation~\eqref{eq:inequality} demonstrates (for $j > 0$).

Strictly speaking, the spectral moments as defined by \cite{vanmarcke1972,vanmarcke1975} should be evaluated by means of equation~\eqref{eq:evolutionary_moments}. However, since the spectral moments so evaluated do not provide the physical meaning of the variances, it seems more appropriate, in the nonstationary case, to calculate them using equation~\eqref{eq:cross_correlation_frequency}, particularized for $t_1 = t_2 = t$. The latter definition is useful for the evaluation of the statistics of the response, as will be shown in the next section.

Notice that, using equation~\eqref{eq:cross_correlation_frequency} for $t_1 = t_2 = t$, no divergences occur in the transient case for white process input with $j = 1$, while, using equation~\eqref{eq:evolutionary_moments}, some divergences without physical meaning occur in the transient zone, as demonstrated by \cite{corotis1972}. Therefore the CCS matrix in the nonstationary case will be a Hermitian one, defined in the following form:
\begin{equation}
\mathbf{R}_{m,x}(t,t) = \boldsymbol{\Lambda}_{m,x}(t) = \begin{bmatrix}
\lambda_{00,x}(t) & \lambda_{01,x}(t) & \lambda_{02,x}(t) & \lambda_{03,x}(t) & \cdots \\
\lambda_{10,x}(t) & \lambda_{11,x}(t) & \lambda_{12,x}(t) & \lambda_{13,x}(t) & \cdots \\
\lambda_{20,x}(t) & \lambda_{21,x}(t) & \lambda_{22,x}(t) & \lambda_{23,x}(t) & \cdots \\
\lambda_{30,x}(t) & \lambda_{31,x}(t) & \lambda_{32,x}(t) & \lambda_{33,x}(t) & \cdots \\
\vdots & \vdots & \vdots & \vdots & \ddots
\end{bmatrix}
\label{eq:nonstationary_ccs}
\end{equation}
where
\begin{equation}
\lambda_{s,v,x}(t) = (-i)^s p_{s,v,x}(t,t)
\label{eq:nonstationary_moment_def}
\end{equation}

It should be emphasized that in the nonstationary case, two indices are necessary in order to define the spectral moments, since in general
\begin{equation}
\lambda_{s,v,x}(t) \neq \lambda_{j,k,x}(t), \quad (s + v = j + k; s \neq j, v \neq k)
\label{eq:nonstationary_inequality}
\end{equation}

However, if $m = 2$, i.e., $\boldsymbol{\Lambda}_{2,x}(t)$ is a $2 \times 2$ matrix, a single index given as the sum of the two indices is sufficient to define the CCS matrix in a perfectly clear manner. Thus, in this particular case, the $\boldsymbol{\Lambda}_{2,x}(t)$ matrix will be written as
\begin{equation}
\boldsymbol{\Lambda}_{2,x}(t) = \begin{bmatrix}
\lambda_{0,x}(t) & \lambda_{1,x}(t) \\
\lambda_{1,x}^*(t) & \lambda_{2,x}(t)
\end{bmatrix}
\label{eq:ccs_2x2}
\end{equation}

Notice that the following inequality:
\begin{equation}
\lambda_{1,x}(t) \neq \lambda_{1,x}^*(t)
\label{eq:lambda_inequality}
\end{equation}
becomes an identity only for discrete sequences of points in the time axis $t = r\pi/\omega_D$ ($r = 0, 1, 2, \ldots$).

\section{Mean-Rate Threshold Crossing for Circular Barriers}
\label{sec:threshold_crossing}

To obtain the statistics of the envelope process, a new vector $\mathbf{Z}_m(t)$ is introduced, whose various entries are equal to the effective values of the vector $\mathbf{X}_m(t)$, i.e.
\begin{equation}
\mathbf{Z}_m(t) = \frac{\mathbf{X}_m(t)}{\sqrt{2}}
\label{eq:effective_vector}
\end{equation}

It follows that the correlation matrix of the vector $\mathbf{Z}_m(t)$ is related to the correlation matrix of the vectors $\mathbf{X}_m(t)$ through
\begin{equation}
\mathbf{R}_{m,z}(t_1, t_2) = E[\mathbf{Z}_m(t_1)\mathbf{Z}_m^*(t_2)] = \frac{1}{2}\mathbf{R}_{m,x}(t_1, t_2)
\label{eq:correlation_z}
\end{equation}

If $f(t)$ is a zero-mean Gaussian process, the joint probability density function (JPDF) of the vector $\mathbf{Z}_m(t)$ is also Gaussian and can be expressed as follows:
\begin{equation}
p_{\mathbf{Z}_m}(\mathbf{z}_m; t) = (2\pi)^{-m} |\boldsymbol{\Lambda}_{m,z}(t)|^{-1} \exp\left[-\frac{1}{2}\mathbf{z}_m^T(t) \boldsymbol{\Lambda}_{m,z}^{-1}(t) \mathbf{z}_m(t)\right]
\label{eq:jpdf_z}
\end{equation}
where the symbol $|\cdot|$ denotes "determinant of." The mean numbers of upcrossings per unit time $\nu_a^+(\eta, t)$ of the circular barrier $\eta$ of the envelope process $a(t)$ defined in equation~\eqref{eq:nonstationary_envelope}, following the main definitions of \cite{rice1955} and \cite{middleton1960}, can be written in the form
\begin{equation}
\nu_a^+(\eta, t) = \int_0^{\infty} p_{a\dot{a}}(\eta, \dot{a}; t) \dot{a} d\dot{a}
\label{eq:upcrossing_rate}
\end{equation}
where $p_{a\dot{a}}(a, \dot{a}; t)$ is the JPDF of the envelope and its time differentiation. The latter can be computed as follows:
\begin{equation}
p_{a\dot{a}}(a, \dot{a}; t) = \int_0^{2\pi} \int_{-\infty}^{\infty} p_{a\dot{a}\vartheta\dot{\vartheta}}(a, \dot{a}, \vartheta, \dot{\vartheta}; t) d\vartheta d\dot{\vartheta}
\label{eq:jpdf_marginal}
\end{equation}
where the integrand JPDF in equation~\eqref{eq:jpdf_marginal} can be computed by using the coordinate transformation given in equation~\eqref{eq:polar}, namely
\begin{equation}
p_{a\dot{a}\vartheta\dot{\vartheta}}(a, \dot{a}, \vartheta, \dot{\vartheta}; t) = |J| p_{\mathbf{Z}_2}(\mathbf{z}_2; t)
\label{eq:jacobian_transform}
\end{equation}
where
\begin{equation}
|J| = a^2(t)
\label{eq:jacobian}
\end{equation}
is the Jacobian of the transformation; and $p_{\mathbf{Z}_2}(\mathbf{z}_2; t)$ can be obtained by putting $m = 2$ in equation~\eqref{eq:jpdf_z}, in which the matrix $\boldsymbol{\Lambda}_{2,z}(t)$ and its inverse are given as
\begin{equation}
\boldsymbol{\Lambda}_{2,z}(t) = \frac{1}{2}\begin{bmatrix}
\lambda_{0,x}(t) & \lambda_{1,x}(t) \\
\lambda_{1,x}^*(t) & \lambda_{2,x}(t)
\end{bmatrix}
\label{eq:lambda_2z}
\end{equation}
and
\begin{equation}
\boldsymbol{\Lambda}_{2,z}^{-1}(t) = \frac{2}{|\boldsymbol{\Lambda}_{2,z}(t)|} \begin{bmatrix}
\lambda_{2,x}(t) & -\lambda_{1,x}(t) \\
-\lambda_{1,x}^*(t) & \lambda_{0,x}(t)
\end{bmatrix}
\label{eq:lambda_2z_inverse}
\end{equation}

The determinant $|\boldsymbol{\Lambda}_{2,z}(t)|$ is given as
\begin{equation}
|\boldsymbol{\Lambda}_{2,z}(t)| = \frac{1}{4}[\lambda_{0,x}(t)\lambda_{2,x}(t) - |\lambda_{1,x}(t)|^2] = \frac{1}{4}\lambda_{0,x}(t)\lambda_{2,x}(t)q_z^2(t)
\label{eq:determinant_lambda}
\end{equation}
where
\begin{equation}
q_z^2(t) = 1 - \frac{|\lambda_{1,x}(t)|^2}{\lambda_{0,x}(t)\lambda_{2,x}(t)}
\label{eq:qz_definition}
\end{equation}

In the stationary case, $q_z$ is the well-known band-width parameter \cite{vanmarcke1972}. Notice that only when $\mathrm{Im}[\lambda_{1,x}(t)]$ is negligible does $q_z(t)$ coincide with the time-dependent spectral density-function shape parameter defined by \cite{corotis1972}.

After some algebra, the JPDF function defined in equation~\eqref{eq:jacobian_transform} can be written, in an explicit form, as follows:
\begin{equation}
p_{a\dot{a}\vartheta\dot{\vartheta}}(a, \dot{a}, \vartheta, \dot{\vartheta}; t) = \frac{4\pi^2 a^2(t)}{|\boldsymbol{\Lambda}_{2,z}(t)|} \exp\left[-\frac{1}{2|\boldsymbol{\Lambda}_{2,z}(t)|}\left(\lambda_{2,x}(t)a^2(t) + \lambda_{0,x}(t)\dot{a}^2(t) - 2\mathrm{Re}[\lambda_{1,x}(t)]a(t)\dot{a}(t)\right)\right]
\label{eq:jpdf_explicit}
\end{equation}

where the variables $\dot{\vartheta}(t)$ and $\vartheta(t)$ are defined in the range $-\infty \leq \dot{\vartheta} \leq \infty$, equation~\eqref{eq:jpdf_explicit} shows that $\vartheta(t)$ is uniformly distributed in the range $0$-$2\pi$, and that $a(t)$ and $\dot{a}(t)$ are not independent. Instead, they are independent in the corresponding stationary case, in which $\mathrm{Im}[\lambda_{1,x}(t)] = 0$.

Once the JPDF function is evaluated, it is a very simple matter to derive the marginal probability density functions $p_{a\dot{a}}(a, \dot{a}; t)$ and $p_a(a; t)$ (see also equation~\eqref{eq:jpdf_marginal}), which take on the following forms, respectively:
\begin{equation}
p_{a\dot{a}}(a, \dot{a}; t) = \frac{a(t)}{[2\pi\lambda_{0,x}(t)|\boldsymbol{\Lambda}_{2,z}(t)|]^{1/2}} \exp\left[-\frac{1}{2|\boldsymbol{\Lambda}_{2,z}(t)|}\left(\lambda_{0,x}(t)\lambda_{2,x}(t)a^2(t) - 2\mathrm{Re}[\lambda_{1,x}(t)]a(t)\dot{a}(t) + \lambda_{0,x}(t)\dot{a}^2(t)\right)\right]
\label{eq:marginal_aa_dot}
\end{equation}

\begin{equation}
p_a(a; t) = \frac{a(t)}{\lambda_{0,x}(t)} \exp\left(-\frac{a^2(t)}{2\lambda_{0,x}(t)}\right)
\label{eq:marginal_a}
\end{equation}

The mean number of upcrossings per unit time $\nu_a^+(\eta, t)$ is obtained by substituting equation~\eqref{eq:marginal_aa_dot} into equation~\eqref{eq:upcrossing_rate} as follows:
\begin{equation}
\nu_a^+(\eta, t) = \frac{1}{\sqrt{2\pi}} \sqrt{\frac{\lambda_{2,x}(t)}{|\boldsymbol{\Lambda}_{2,z}(t)|}} \exp\left(-\frac{\eta^2}{2\lambda_{0,x}(t)}\right) \left[1 + \Phi\left(\frac{\mathrm{Im}[\lambda_{1,x}(t)]\eta}{\sqrt{2\lambda_{0,x}(t)|\boldsymbol{\Lambda}_{2,z}(t)|}}\right)\right]
\label{eq:upcrossing_final}
\end{equation}
where $\Phi(\xi)$ is the widely known error function
\begin{equation}
\Phi(\xi) = \frac{2}{\sqrt{\pi}} \int_0^{\xi} e^{-\rho^2} d\rho
\label{eq:error_function}
\end{equation}

Notice that equation~\eqref{eq:upcrossing_final} gives an exact solution in the nonstationary case of the mean-rate threshold upcrossing for circular barriers and that the greatest computational effort in evaluating $\nu_a^+(\eta; t)$ is in the computation of nonstationary spectral moments.

In the stationary case, since $\mathrm{Im}[\lambda_{1,x}(t)] = 0$, equation~\eqref{eq:upcrossing_final} becomes
\begin{equation}
\nu_a^+(\eta) = \frac{1}{\sqrt{2\pi}} \sqrt{\frac{\lambda_{2,x}}{\lambda_{0,x}}} \exp\left(-\frac{\eta^2}{2\lambda_{0,x}}\right)
\label{eq:stationary_upcrossing}
\end{equation}
and coincides with the well-known mean-rate upcrossings given by \cite{cramer1967} for circular barriers.

It is worth noting that, by introducing the complex processes instead of the real ones, the exact JPDF given in equations~\eqref{eq:jpdf_explicit} and~\eqref{eq:marginal_aa_dot} and the exact mean-rate upcrossings given in equation~\eqref{eq:upcrossing_final} have been obtained, while only approximate expressions are available in the literature.

\section{First-Passage Probability}
\label{sec:first_passage}

In this section, as an application of complex processes, the first-passage probability following the Poisson and the Markov assumptions is evaluated.

To this purpose, let us consider the nonstationary zero-mean narrow-band Gaussian response process $z(t) = x(t)/\sqrt{2}$. $x(t)$ is defined in equation~\eqref{eq:nonstationary_output} as an output process of a lightly damped oscillator excited by the process $f(t)/\sqrt{2}$, which is defined in equation~\eqref{eq:nonstationary_input}. The PSD of $n(t)$ is fairly broad. Let its mean circular frequency $\omega_a(t)$ be in the form
\begin{equation}
\omega_a(t) = \sqrt{\frac{\lambda_{2,x}(t)}{\lambda_{0,x}(t)}}
\label{eq:mean_frequency}
\end{equation}

It follows from the narrow-band character of the process that the peak and trough of the real part of the process $z(t)$ are almost uniformly spaced at intervals $\Delta t(t) = \pi/\omega_a(t)$. To simplify matters, hereafter we will suppose that $\Delta t(t)$ is almost constant, i.e.
\begin{equation}
\Delta t(t) = \Delta t, \quad \forall t
\label{eq:constant_interval}
\end{equation}

Equation~\eqref{eq:constant_interval} holds true in the stationary case, and, excluding some transient zones, can be considered sufficiently accurate even in the nonstationary case.

Let $\eta$ be the threshold level of the real part of $z(t)$ and $Y(t_n)$ be the discrete point process ($t_n = n\Delta t$) of the peaks and troughs of the real part of $z(t)$. Then the failure rate $b(t_n)$---namely, the probability that the absolute value of $Y(t_n)$ will exit from the safe domain in the $n$th half cycle, conditioned by the fact that no threshold crossing has occurred before \cite{yang1971}---is given as
\begin{equation}
b(t_n) = \text{Prob}\left\{|Y(t_n)| \geq \eta \left| \bigcap_{j=1}^{n-1} |Y(t_j)| < \eta \right.\right\}
\label{eq:failure_rate}
\end{equation}

Based on the observation that the envelope process, in the narrow-band response process, has a peak distribution that can be approximated by the distribution of the envelope process at times separated by $\Delta t$, equation~\eqref{eq:failure_rate} can be rewritten in the form
\begin{equation}
b(t_n) = \text{Prob}\left\{a(t_n) \geq \eta \left| \bigcap_{j=1}^{n-1} a(t_j) < \eta \right.\right\}
\label{eq:failure_rate_envelope}
\end{equation}

Once $b(t_n)$ is evaluated, the probability that the first excursion of $a(t_n)$, $L(t_n, \eta)$ will occur in the first $n$ half cycles is given in the well-known form \cite{krenk1979,naess1983,naess1984,preumont1985,yang1971}
\begin{equation}
L(t_n, \eta) = 1 - \prod_{j=1}^{n} [1 - b(t_j)]
\label{eq:first_excursion}
\end{equation}
in which it is assumed that the probability of no excursion at $t = 0$ is one. For $b(t_j) \ll 1$ and for large values of $n$, equation~\eqref{eq:first_excursion} can be approximated in the form \cite{yang1971}
\begin{equation}
L(t_n, \eta) = 1 - \exp\left(-\sum_{j=1}^{n} b(t_j)\right) \quad (t_j = j\Delta t)
\label{eq:first_excursion_approx}
\end{equation}

To obtain the unknown failure rate $b(t_j)$, which appears in equation~\eqref{eq:first_excursion_approx}, the Poisson and Markov assumptions are usually made in the literature.

In the Poisson assumption, the successive extrema $Y(t_j)$ are considered independent, and it is easily shown that the failure rate $b(t_j)$ can be written as
\begin{equation}
b(t_j) = \text{Prob}\{a(t_j) \geq \eta\} = q_0(t_j)
\label{eq:poisson_failure}
\end{equation}
where
\begin{equation}
q_0(t_j) = \int_{\eta}^{\infty} p_a(a; t_j) da = \exp\left(-\frac{\eta^2}{2\lambda_{0,x}(t_j)}\right)
\label{eq:q0}
\end{equation}

In the one-step memory Markov assumption, the conditional probability distribution of an extremum depends only on the previous extremum at a time separated by $\Delta t$; it follows that $b(t_j)$ is given as
\begin{equation}
b(t_j) = \text{Prob}\{a_2 \geq \eta | a_1 < \eta\} = \frac{\text{Prob}\{a_2 \geq \eta, a_1 < \eta\}}{\text{Prob}\{a_1 < \eta\}} = \frac{q(t_j, \Delta t)}{1 - q_0(t_j - \Delta t)}
\label{eq:markov_failure}
\end{equation}
where $a_1 = a(t_j - \Delta t)$ and $a_2 = a(t_j)$ are the values of the envelope function evaluated at times $t_j - \Delta t$ and $t_j$, respectively. Further, since
\begin{equation}
\text{Prob}\{a_1 < \eta\} = 1 - \int_{\eta}^{\infty} p_a(a; t_j - \Delta t) da = 1 - q_0(t_j - \Delta t)
\label{eq:prob_a1}
\end{equation}
and
\begin{equation}
\text{Prob}\{a_2 \geq \eta, a_1 < \eta\} = q(t_j, \Delta t) = \int_0^{\eta} da_1 \int_{\eta}^{\infty} p_{a_1a_2}(a_1, a_2; t_j, \Delta t) da_2
\label{eq:prob_a1a2}
\end{equation}
it follows that
\begin{equation}
b(t_j) = \frac{q(t_j, \Delta t)}{1 - q_0(t_j - \Delta t)}
\label{eq:markov_b}
\end{equation}

Thus to obtain $b(t_j)$, the JPDF that appears in equation~\eqref{eq:prob_a1a2} must be evaluated. This function can be easily obtained starting from the JPDF of the complex variables $z(t_j)$ and $z(t_j - \Delta t)$.

In general, if a vector $\mathbf{Z}_m(t_j, \Delta t)$ is defined in the form
\begin{equation}
\mathbf{Z}_m(t_j, \Delta t) = [\mathbf{Z}_m(t_j - \Delta t), \mathbf{Z}_m(t_j)]^T
\label{eq:vector_combined}
\end{equation}
where the vector $\mathbf{Z}_m(t_j)$ has been defined in equation~\eqref{eq:effective_vector}, the JPDF of the vector $\mathbf{Z}_m(t_j, \Delta t)$ can be expressed as
\begin{equation}
p_{\mathbf{Z}_m}[\mathbf{z}_m(t_j, \Delta t)] = (2\pi)^{-2m} |\mathbf{R}_{m,z}(t_j, \Delta t)|^{-1} \exp\left[-\frac{1}{2}\mathbf{z}_m^T(t_j, \Delta t) \mathbf{R}_{m,z}^{-1}(t_j, \Delta t) \mathbf{z}_m(t_j, \Delta t)\right]
\label{eq:jpdf_combined}
\end{equation}
$\mathbf{R}_{m,z}(t_j, \Delta t)$ being a $2m \times 2m$ Hermitian correlation matrix given by
\begin{equation}
\mathbf{R}_{m,z}(t_j, \Delta t) = \begin{bmatrix}
\mathbf{R}_{m,z}(t_j - \Delta t, t_j - \Delta t) & \mathbf{R}_{m,z}(t_j - \Delta t, t_j) \\
\mathbf{R}_{m,z}(t_j, t_j - \Delta t) & \mathbf{R}_{m,z}(t_j, t_j)
\end{bmatrix}
\label{eq:correlation_block}
\end{equation}

The diagonal block matrices of this equation are the CCS matrices, already defined in equation~\eqref{eq:nonstationary_ccs}, and the nondiagonal block matrices are the cross-correlation matrices, already defined in equations~\eqref{eq:correlation_matrix} and~\eqref{eq:cross_correlation_frequency}. Using the following coordinate transformation:
\begin{equation}
z_r(i) = \frac{1}{\sqrt{2}} \frac{d^{r-1} x(t)}{dt^{r-1}} = \frac{1}{\sqrt{2}} a_r(t) \exp[i\vartheta_r(t)], \quad r = 1, 2, \ldots, m; \quad i = t_j - \Delta t; \quad t_j
\label{eq:coordinate_transform}
\end{equation}
where $z_r(i)$ is the $r$th element of vector $\mathbf{Z}_m(t)$, the JPDF of the envelope, the phase, and its time derivatives can be computed, by substituting equation~\eqref{eq:coordinate_transform} into equation~\eqref{eq:jpdf_combined}, multiplied by the Jacobian of the transformation.

Performing the latter operations specialized for $m = 1$ we obtain
\begin{equation}
p_{a_1a_2\vartheta_1\vartheta_2}(a_1, a_2, \vartheta_1, \vartheta_2; t_j, \Delta t) = \frac{4\pi^2 a_1 a_2}{|\mathbf{R}_{1,z}(t_j, \Delta t)|} \exp\left[-\frac{1}{2|\mathbf{R}_{1,z}(t_j, \Delta t)|}\left(\lambda_{0,z}(t_j - \Delta t) a_1^2 + \lambda_{0,z}(t_j) a_2^2 - 2a_1 a_2 r_0 \cos(\vartheta_2 - \vartheta_1 + \gamma)\right)\right]
\label{eq:jpdf_a1a2_explicit}
\end{equation}
where $\vartheta_1 = \vartheta(t_j - \Delta t)$ and $\vartheta_2 = \vartheta(t_j)$ are phase processes uniformly distributed in the range $0$-$2\pi$. $r_0$ and $|\mathbf{R}_{1,z}(t_j, \Delta t)|$ are given, respectively, as
\begin{align}
r_0 &= |p_{0,z}(t_j - \Delta t, t_j)| \label{eq:r0}\\
|\mathbf{R}_{1,z}(t_j, \Delta t)| &= \lambda_{0,z}(t_j - \Delta t) \lambda_{0,z}(t_j) - r_0^2 \label{eq:determinant_r}
\end{align}
and $\gamma$ as
\begin{equation}
\gamma = \tan^{-1}\left(\frac{\mathrm{Im}[p_{0,z}(t_j - \Delta t, t_j)]}{\mathrm{Re}[p_{0,z}(t_j - \Delta t, t_j)]}\right)
\label{eq:gamma_phase}
\end{equation}

It is to be emphasized that $r_0$ is the modulus of the complex cross-correlation function $p_{0,z}(t_j - \Delta t, t_j)$ and that this meaning is evident only when the complex representation of stochastic processes is used.

Integrating equation~\eqref{eq:jpdf_a1a2_explicit} twice with respect to $\vartheta_1$ and $\vartheta_2$, the marginal JPDF are computed in the form
\begin{equation}
p_{a_1a_2}(a_1, a_2; t_j, \Delta t) = \frac{4\pi^2 a_1 a_2}{|\mathbf{R}_{1,z}(t_j, \Delta t)|} \exp\left[-\frac{\lambda_{0,z}(t_j - \Delta t) a_1^2 + \lambda_{0,z}(t_j) a_2^2}{2|\mathbf{R}_{1,z}(t_j, \Delta t)|}\right] I_0\left(\frac{a_1 a_2 r_0}{|\mathbf{R}_{1,z}(t_j, \Delta t)|}\right)
\label{eq:marginal_jpdf}
\end{equation}
where $I_0(\cdot)$ is the modified Bessel's function of order zero.

Finally, the $q(t_j, \Delta t)$ can be evaluated by the series expansion of the Bessel's function $I_0(\cdot)$ in a form that is more suitable for numerical evaluation \cite{krenk1979}
\begin{equation}
q(t_j, \Delta t) = \frac{r_0}{|\mathbf{R}_{1,z}(t_j, \Delta t)|} \exp\left[-\frac{\eta^2[\lambda_{0,z}(t_j - \Delta t) + \lambda_{0,z}(t_j)]}{2|\mathbf{R}_{1,z}(t_j, \Delta t)|}\right] + \exp\left(-\frac{\eta^2}{2\lambda_{0,z}(t_j)}\right) \Phi_2(\eta) + \exp\left(-\frac{\eta^2}{2\lambda_{0,z}(t_j - \Delta t)}\right) \Phi_1(\eta) - \exp\left(-\frac{\eta^2}{2\lambda_{0,z}(t_j)}\right) \Phi_2(\eta) - \exp\left(-\frac{\eta^2}{2\lambda_{0,z}(t_j - \Delta t)}\right) \Phi_1(\eta)
\label{eq:q_series}
\end{equation}
where
\begin{equation}
\Phi_i(\eta) = \int_0^{\eta} \frac{a_i}{\lambda_{0,z}(t_i)} \exp\left(-\frac{a_i^2}{2\lambda_{0,z}(t_i)}\right) da_i \quad (i = 1,2)
\label{eq:phi_integral}
\end{equation}
and
\begin{align}
w_1 &= \frac{r_0}{|\mathbf{R}_{1,z}(t_j, \Delta t)|} \lambda_{0,z}(t_j) \label{eq:w1}\\
w_2 &= \frac{r_0}{|\mathbf{R}_{1,z}(t_j, \Delta t)|} \lambda_{0,z}(t_j - \Delta t) \label{eq:w2}
\end{align}

Substituting equations~\eqref{eq:prob_a1} and~\eqref{eq:q_series} into equation~\eqref{eq:markov_b}, the failure rate $b(t_j)$ in the Markov assumption can be computed.

It is worth noting that equation~\eqref{eq:q_series} requires that only one peak or trough always follow one zero crossing by $x(t)$, while no hypotheses are made on the coincidence between $x$ and $x/\omega_0$, which holds true only for very narrow band processes and, in some cases, gives unacceptable results \cite{langley1986}.

From a computational point of view, since the integral of equation~\eqref{eq:phi_integral} can be evaluated in a very simple manner \cite{krenk1979}, the greatest computational effort in the computation of $b(t_j)$ consists in the evaluation of both the spectral moments and the cross-correlation function, which appear in the JPDF of the envelope for nonstationary input. In order to reduce the computational effort, an approximate form of the JPDF of the envelope is available in the literature \cite{spanos1983}.

\section{Conclusions}
\label{sec:conclusions}

In this paper, it is shown that by introducing the input process, i.e., the so-called pre-envelope, as the product of an analytical random stationary process by a deterministic shaping function, the nonstationary envelope can be defined as the modulus of the complex response process of structural systems subjected to such a pre-envelope. It is also shown that the introduction of the complex input process, instead of the more familiar real one, is essential, not only for the definition of the envelope process, but also for the correct definition of the spectral moments in both stationary and nonstationary cases.

Starting from the previous assumption, the cross-correlation function matrix of nonstationary processes is obtained as the average of the complex output and its time derivatives in linear systems subjected to nonstationary pre-envelope. By similar considerations, the spectral moments of the output are defined as the cross-covariances of complex processes. The latter definition is essential for evaluating the nonstationary spectral moments, as, in fact, the moments of the so-called evolutionary PSD are not able to evaluate these quantities.

In the two last sections, the previous definition of the envelope function for nonstationary processes is applied in the evaluation of the mean-rate threshold crossing for circular barriers and in the first-passage probability problem within the framework of complex processes. A more satisfactory representation and a clearer vision of the two problems are obtained. Moreover, using this procedure, a closed-form solution in the nonstationary case is given for the evaluation of the mean-rate threshold crossing of circular barriers.

\section*{Acknowledgments}

The writer is indebted to Mario Di Paola for his helpful comments and valuable suggestions in the theoretical formulation of this paper.

\appendix

\section{PSD of Analytic Process}
\label{app:psd}

In this appendix, it is shown that the analytic process defined in equation~\eqref{eq:preenvelope} has a one-sided PSD. It can easily be shown that the correlation function $p_f(\tau)$ of this analytic process is given as
\begin{equation}
p_f(\tau) = E[f(t)f^*(t + \tau)] = 2[p_n(\tau) + ip_{\hat{n}}(\tau)]
\label{eq:pf_correlation}
\end{equation}

$p_n(\tau)$ and $p_{\hat{n}}(\tau)$ are defined in the text after equation~\eqref{eq:gamma}. Making the Fourier transform of equation~\eqref{eq:pf_correlation}, we obtain the PSD of $f(t)$, according to the Wiener-Kinchine theorem:
\begin{equation}
G_f(\omega) = \int_{-\infty}^{\infty} p_f(\tau) e^{-i\omega\tau} d\tau = 2 \int_{-\infty}^{\infty} p_n(\tau) e^{-i\omega\tau} d\tau + 2i \int_{-\infty}^{\infty} p_{\hat{n}}(\tau) e^{-i\omega\tau} d\tau
\label{eq:gf_fourier}
\end{equation}

Using the property of the Fourier transform of the Hilbert transform of $p_n(\tau)$, i.e. \cite{papoulis1984}
\begin{equation}
\int_{-\infty}^{\infty} p_{\hat{n}}(\tau) e^{-i\omega\tau} d\tau = -i \text{sgn}(\omega) G_n(\omega)
\label{eq:hilbert_fourier}
\end{equation}
where $\text{sgn}(\omega)$ is the signum function. Substituting this equation into equation~\eqref{eq:gf_fourier} we obtain
\begin{equation}
G_f(\omega) = \int_{-\infty}^{\infty} p_f(\tau) e^{-i\omega\tau} d\tau = 4U(\omega) G_n(\omega) = 2U(\omega) \bar{G}_f(\omega)
\label{eq:gf_final}
\end{equation}

Thus the analytic process defined in equation~\eqref{eq:preenvelope} exhibits power only in the positive frequency range.

\section{Notation}
\label{app:notation}

The following symbols are used in this paper:
\begin{description}
\item[$a(t)$] stationary and nonstationary envelope process;
\item[$\dot{a}(t)$] time differentiation of envelope process;
\item[$b(t_n)$] failure rate;
\item[$E[\cdot]$] stochastic average of;
\item[$F(t)$] deterministic shaping function;
\item[$f(t)$] stochastic complex zero mean input process;
\item[$G_f(\omega)$] one-sided PSD of complex input process $f(t)$;
\item[$G_n(\omega)$] two-sided PSD of real input process $n(t)$;
\item[$G_x(\omega)$] one-sided PSD of complex output process $x(t)$;
\item[$G_x(\omega, t)$] so-called one-sided evolutionary PSD;
\item[$g(\tau)$] deterministic function defined in equation~\eqref{eq:g_function};
\item[$H(\omega)$] transfer function in terms of displacements;
\item[$H[\cdot]$] Hilbert transform of;
\item[$h(\tau)$] impulse response function;
\item[$I_0(\cdot)$] modified Bessel function of order zero;
\item[$\mathrm{Im}[\cdot]$] imaginary part of;
\item[$|J|$] Jacobian of transformation;
\item[$K_r(\omega, t)$] truncated Fourier transform of product defined in equation~\eqref{eq:k_function};
\item[$K_r(\omega, \infty)$] transfer function in terms of the $r$th derivative of displacements;
\item[$L(t_n, \eta)$] first excursion probability of the envelope process;
\item[$n(t)$] stationary real zero mean input process;
\item[$\hat{n}(t)$] Hilbert transform of $n(t)$;
\item[$p_a(a; t)$] probability density function of envelope;
\item[$p_{a\dot{a}}(a, \dot{a}; t)$] joint probability density function of envelope and its time derivative;
\item[$p_{a\dot{a}\vartheta\dot{\vartheta}}(a, \dot{a}, \vartheta, \dot{\vartheta}; t)$] joint probability density function of envelope, its time derivative, phase, and phase derivative;
\item[$p_{a_1a_2}(a_1, a_2; t_j, \Delta t)$] joint probability density function of envelope at two time points;
\item[$p_{a_1a_2\vartheta_1\vartheta_2}(a_1, a_2, \vartheta_1, \vartheta_2; t_j, \Delta t)$] joint probability density function of envelope and phase at two time points;
\item[$p_f(\tau)$] correlation function of analytical process $f(t)$;
\item[$p_n(\gamma)$] autocorrelation function of stationary process $n(t)$;
\item[$p_{\hat{n}}(\gamma)$] autocorrelation function of the Hilbert transform of $n(t)$;
\item[$p_{s,v,x}(t_1, t_2)$] $(s,v)$th entry of the cross-correlation matrix $\mathbf{R}_{m,x}(t_1, t_2)$;
\item[$p_{\mathbf{Z}_m}(\mathbf{z}_m; t)$] joint probability density function of vector $\mathbf{Z}_m(t)$;
\item[$\mathbf{R}_{m,x}(t_1, t_2)$] cross-correlation matrix of vector $\mathbf{X}_m(t_1)$ and $\mathbf{X}_m(t_2)$;
\item[$\mathbf{R}_{m,z}(t_1, t_2)$] cross-correlation matrix of vector $\mathbf{Z}_m(t_1)$ and $\mathbf{Z}_m(t_2)$;
\item[$\mathbf{R}_{m,z}(t_j, \Delta t)$] $2m \times 2m$ Hermitian correlation matrix for vector $\mathbf{Z}_m(t_j, \Delta t)$;
\item[$\mathrm{Re}[\cdot]$] real part of;
\item[$U(\omega)$] Heaviside's function;
\item[$\mathbf{X}_m(t)$] complex vector of order $m$, whose elements are $x(t)$ and its time derivatives;
\item[$x(t)$] complex zero mean output process;
\item[$Y(t_n)$] process of peaks and troughs of real part of $z(t)$;
\item[$y(t); \hat{y}(t); \tilde{y}(t)$] different real zero mean output processes;
\item[$\mathbf{Z}_m(t)$] effective value of complex output vector $\mathbf{X}_m(t)$;
\item[$\mathbf{Z}_m(t_j, \Delta t)$] concatenated vector $[\mathbf{Z}_m(t_j-\Delta t), \mathbf{Z}_m(t_j)]^T$;
\item[$z(t)$] effective value of complex zero mean output process $x(t)$;
\item[$\alpha_r, \beta_r$] recursive coefficients as defined in equations~\eqref{eq:alpha_recursion}-\eqref{eq:beta_initial};
\item[$\delta(\tau)$] Dirac's delta function;
\item[$\zeta$] damping ratio;
\item[$\eta$] cylindrical (circular) barrier threshold;
\item[$\vartheta(t)$] phase process;
\item[$\lambda_{j,x}(t)$] stationary and nonstationary $j$th spectral moment;
\item[$\lambda_j^*(t)$] $j$th moment of evolutionary PSD;
\item[$\lambda_{s,v,x}(t)$] nonstationary spectral moment with two indices;
\item[$\boldsymbol{\Lambda}_{m,x}(t)$] cross-covariance spectral matrix of order $m$ for process $x(t)$;
\item[$\boldsymbol{\Lambda}_{m,z}(t)$] cross-covariance spectral matrix of order $m$ for process $z(t)$;
\item[$\nu_a^+(\eta, t)$] mean number of upcrossings per unit time of circular barrier $\eta$;
\item[$\omega_0$] natural radian frequency;
\item[$\omega_D$] damped natural frequency, $\omega_D = \omega_0\sqrt{1-\zeta^2}$;
\item[$\omega_a(t)$] mean circular frequency of the process;
\item[$\text{sgn}(\omega)$] sign function;
\item[$|\cdot|$] determinant (for matrices) or modulus (for complex numbers);
\item[$I_0(\cdot)$] modified Bessel function of order zero;
\item[$\Phi(\cdot)$] error function;
\item[$\Phi_i(\eta)$] integral functions as defined in equation~\eqref{eq:phi_integral};
\item[$q_z(t)$] time-dependent spectral density-function shape parameter;
\item[$q_0(t_j)$] probability function as defined in equation~\eqref{eq:q0};
\item[$q(t_j, \Delta t)$] probability function as defined in equation~\eqref{eq:q_series};
\item[$r_0$] modulus of the complex cross-correlation function;
\item[$\gamma$] argument for autocorrelation functions and phase difference;
\item[$w_1, w_2$] auxiliary variables for integral evaluation as defined in equations~\eqref{eq:w1}-\eqref{eq:w2};
\end{description}

\begin{thebibliography}{99}

\bibitem{arens1957} Arens, R. (1957). Complex processes for envelopes of normal noise. \textit{IRE Trans. on Information Theory}, 3, 204-207.

\bibitem{borino1988} Borino, G., Di Paola, M., and Muscolino, G. (1988). Non-stationary spectral moments of base excited MDOF systems. (in press).

\bibitem{corotis1977} Corotis, R. B., and Marshall, A. (1977). Oscillator response to modulated random excitation. \textit{J. Engrg. Mech. Div.}, ASCE, 103(4), 501-513.

\bibitem{corotis1972} Corotis, R. B., Vanmarcke, E. H., and Cornell, C. A. (1972). First passage of non-stationary random processes. \textit{J. Engrg. Mech. Div.}, ASCE, 98(2), 401-414.

\bibitem{cramer1967} Cramer, H., and Leadbetter, M. R. (1967). \textit{Stationary and related stochastic processes}. John Wiley and Sons, Inc., New York, N.Y.

\bibitem{dipaola1985} Di Paola, M. (1985). Transient spectral moments of linear systems. \textit{SM Archives}, 10, 225-243.

\bibitem{dipaola1985b} Di Paola, M., and Muscolino, G. (1985). Response maxima of a SDOF system under seismic action. \textit{J. Struct. Engrg.}, ASCE, 111(9), 2033-2045.

\bibitem{dipaola1986} Di Paola, M., and Muscolino, G. (1986). On the convergent part of high spectral moments for stationary structural response. \textit{J. Sound Vib.}, 110(2), 233-245.

\bibitem{dugundji1958} Dugundji, J. (1958). Envelope and pre-envelopes of real waveforms. \textit{IRE Trans. on Information Theory}, 4, 53-57.

\bibitem{grossmayer1977} Grossmayer, R. (1977). A seismic reliability and first passage failure. \textit{Random excitation of structures by earthquake and atmospheric turbulence}, CISM Courses and Lectures 225, H. Parkus, ed., Springer-Verlag, Wien-New York, 110-200.

\bibitem{krenk1979} Krenk, S. (1979). Non-stationary narrow-band response and first passage probability. \textit{J. Appl. Mech.}, ASME, 46, 919-924.

\bibitem{krenk1981} Krenk, S., Madsen, H. O., and Madsen, P. H. (1981). Stationary and transient response envelopes. \textit{J. Engrg. Mech. Div.}, ASCE, 109(1), 263-277.

\bibitem{langley1986} Langley, R. S. (1986). On various definitions of the envelope of a random process. \textit{J. Sound Vib.}, 105(3), 503-512.

\bibitem{lutes1978} Lutes, L. D., Chen, Y.-T. T., and Tzuang, S.-H. (1978). First-passage approximations for simple oscillators. \textit{J. Engrg. Mech. Div.}, ASCE, 106(6), 1111-1124.

\bibitem{middleton1960} Middleton, D. (1960). \textit{An introduction to statistical communication theory}. McGraw-Hill, Inc., New York, N.Y.

\bibitem{naess1983} Naess, A. (1983). Extreme values of a stochastic process whose peak values are subjected to the Markov chain condition. \textit{Norwegian Maritime Res.}, 11, 29-37.

\bibitem{naess1984} Naess, A. (1984). The effect of the Markov chain condition on the prediction of extreme values. \textit{J. Sound Vib.}, 94(1), 87-103.

\bibitem{nigam1982} Nigam, N. C. (1982). Phase properties of a class of random processes. \textit{Earthquake Engrg. Struct. Dyn.}, 10, 711-717.

\bibitem{papoulis1984} Papoulis, A. (1984). \textit{Signal Analysis}. McGraw-Hill, Inc., New York, N.Y.

\bibitem{preumont1985} Preumont, A. (1985). On the peak factor of stationary Gaussian process. \textit{J. Sound Vib.}, 100(1), 15-34.

\bibitem{priestley1967} Priestley, M. B. (1967). Power spectral analysis of non-stationary random processes. \textit{J. Sound Vib.}, 6, 86-87.

\bibitem{rice1955} Rice, S. O. (1955). Mathematical analysis of random noise. \textit{Selected papers on noise and stochastic processes}, N. Wax, ed., Dover Publications, Inc., New York, N.Y.

\bibitem{spanos1983} Spanos, P. T. D., and Solomos, G. P. (1983). Markov approximation to transient vibration. \textit{J. Engrg. Mech. Div.}, ASCE, 109(4), 1134-1150.

\bibitem{vanmarcke1972} Vanmarcke, E. H. (1972). Properties of spectral moments with applications to random vibration. \textit{J. Engrg. Mech. Div.}, ASCE, 98(2), 425-446.

\bibitem{vanmarcke1975} Vanmarcke, E. H. (1975). On the distribution of the first-passage time for normal stationary random processes. \textit{J. Appl. Mech.}, ASME, 42, 215-220.

\bibitem{yang1972} Yang, J.-N. (1972). Non-Stationary envelope process and first excursion probability. \textit{J. Struct. Mech.}, 1, 231-248.

\bibitem{yang1971} Yang, J.-N., and Shinozuka, M. (1971). On the first excursion probability in stationary narrow-band random vibration. \textit{J. Appl. Mech.}, ASME, 38, 1017-1022.

\end{thebibliography}

\end{document}

