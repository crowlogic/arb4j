\documentclass{article}
\usepackage[english]{babel}
\usepackage{amsmath,amssymb,latexsym,theorem}

%%%%%%%%%% Start TeXmacs macros
\newcommand{\assign}{:=}
\newcommand{\cdummy}{\cdot}
\newcommand{\tmtextbf}[1]{\text{{\bfseries{#1}}}}
\newcommand{\tmtextit}[1]{\text{{\itshape{#1}}}}
\newenvironment{proof}{\noindent\textbf{Proof\ }}{\hspace*{\fill}$\Box$\medskip}
\newtheorem{conjecture}{Conjecture}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
{\theorembodyfont{\rmfamily}\newtheorem{remark}{Remark}}
\newtheorem{theorem}{Theorem}
%%%%%%%%%% End TeXmacs macros

\providecommand{\cdummy}{{\cdot}}
\providecommand{\tmtextbf}[1]{\tmtextbf{#1}}
\providecommand{\tmtextit}[1]{\tmtextit{#1}}

\begin{document}

\title{Unitarily Time-Changed Stationary Processes: A Subclass of Oscillatory
Processes}

\author{Stephen Crowley}

\date{December 13, 2025}

\maketitle

\begin{abstract}
  A unitary time-change operator $U_{\theta}$ is constructed for absolutely
  continuous, strictly increasing time reparametrizations $\theta$, acting on
  functions that are locally square-integrable. Applying $U_{\theta}$ to the
  Cram{\'e}r spectral representation of a stationary process $X (t)$ produces
  the transformed process
  \[ Z (t) = U_{\theta} X (t) = \sqrt{\dot{\theta} (t)}  \hspace{0.17em} X
     (\theta (t)) = \sqrt{\dot{\theta} (t)}  \int_{\mathbb{R}} e^{i \lambda
     \theta (t)}  \hspace{0.17em} d \Phi (\lambda), \]
  which is an oscillatory process in the sense of Priestley with oscillatory
  function $\varphi_t (\lambda) = \sqrt{\dot{\theta} (t)}  \hspace{0.17em}
  e^{i \lambda \theta (t)}$, evolutionary power spectral density $S_t
  (\lambda) = \dot{\theta} (t) S (\lambda)$, and covariance kernel $K_Z (t, s)
  = \sqrt{\dot{\theta} (t)  \dot{\theta} (s)}  \hspace{0.17em} K_X (\theta
  (t), \theta (s))$ where $K_X$ is the stationary covariance of $X (t) =
  \int_{\mathbb{R}} e^{i \lambda t}  \hspace{0.17em} d \Phi (\lambda)$.
  Unitarily time-changed stationary processes form a subclass of oscillatory
  processes. The Kac--Rice formula gives the expected zero-counting function
  for stationary processes. By Bulinskaya's theorem, when the covariance is
  twice continuously differentiable with $R'' (0) < 0$, almost all zeros are
  simple (for stationary processes). A zero-localization measure $d \mu (t) =
  \delta (Z (t)) | \dot{Z} (t) |  \hspace{0.17em} dt$ induces a Hilbert space
  $L^2 (\mu)$ on the zero set of each oscillatory process realization $Z (t)$.
\end{abstract}

{\tableofcontents}

\section{Gaussian Processes}

\subsection{Definition}

\begin{definition}
  \label{def:gaussian_process}\tmtextbf{(Gaussian process)} Let $(\Omega,
  \mathcal{F}, \mathbb{P})$ be a probability space and $T$ a nonempty index
  set. A family $\{X_t : t \in T\}$ of real-valued random variables on
  $(\Omega, \mathcal{F}, \mathbb{P})$ is called a Gaussian process if for
  every finite subset $\{t_1, \ldots, t_n \} \subset T$ the random vector
  $(X_{t_1}, \ldots, X_{t_n})$ is multivariate normal (possibly degenerate).
  Equivalently, every finite linear combination $\sum_{i = 1}^n a_i X_{t_i}$
  is either almost surely constant or Gaussian. The mean function is $m (t)
  \assign \mathbb{E} [X_t]$ and the covariance kernel is
  \begin{equation}
    \label{eq:covariance_kernel} K (s, t) = \mathrm{Cov} (X_s, X_t) .
  \end{equation}
  For any finite $(t_i)_{i = 1}^n \subset T$, the matrix $K_{ij} = K (t_i,
  t_j)$ is symmetric positive semidefinite, and a Gaussian process is
  completely determined in law by $m$ and $K$.
\end{definition}

\subsection{Stationary processes}

\begin{definition}
  \label{def:cramer}\tmtextbf{[Cram{\'e}r spectral representation]} A
  zero-mean stationary process $X$ with spectral measure $F$ admits the sample
  path representation
  \begin{equation}
    \label{eq:cramer_representation} X (t) = \int_{\mathbb{R}} e^{i \lambda t}
    \hspace{0.17em} d \Phi (\lambda)
  \end{equation}
  which has covariance
  \begin{equation}
    \label{eq:stationary_covariance} R_X  (t - s) = \int_{\mathbb{R}} e^{i
    \lambda (t - s)}  \hspace{0.17em} dF (\lambda) .
  \end{equation}
\end{definition}

\subsubsection{Sample path realizations}

\begin{definition}
  \label{def:L2loc}\tmtextbf{[Locally square-integrable functions]} Define
  \begin{equation}
    \label{eq:L2loc_def} L^2_{\mathrm{loc}} (\mathbb{R}) \assign \left\{ f :
    \mathbb{R} \to \mathbb{C}: \int_K |f (t) |^2  \hspace{0.17em} dt < \infty
    \text{for every compact } K \subseteq \mathbb{R} \right\} .
  \end{equation}
\end{definition}

\begin{remark}
  \label{rem:L2loc_properties}Every bounded measurable set in $\mathbb{R}$ is
  compact or contained in a compact set; hence $L^2_{\mathrm{loc}}
  (\mathbb{R})$ contains functions that are square-integrable on every bounded
  interval, including functions with polynomial growth at infinity.
\end{remark}

\begin{theorem}
  \label{thm:paths_loc}\tmtextbf{[Sample paths in $L^2_{\mathrm{loc}}
  (\mathbb{R})$]} Let $\{X (t)\}_{t \in \mathbb{R}}$ be a second-order
  stationary process with
  \begin{equation}
    \label{eq:finite_variance} \sigma^2 \assign \mathbb{E} [X (t)^2] < \infty
    .
  \end{equation}
  Then almost every sample path lies in $L^2_{\mathrm{loc}} (\mathbb{R})$.
\end{theorem}

\begin{proof}
  Fix a bounded interval $[a, b] \subset \mathbb{R}$ with $a < b$ and define
  \begin{equation}
    \label{eq:Yab_def} Y_{[a, b]} \assign \int_a^b X (t)^2  \hspace{0.17em}
    dt.
  \end{equation}
  By Tonelli's theorem,
  \begin{equation}
    \label{eq:tonelli_application} \mathbb{E} [Y_{[a, b]}] = \int_a^b
    \mathbb{E} [X (t)^2]  \hspace{0.17em} dt.
  \end{equation}
  By stationarity, $\mathbb{E} [X (t)^2] = \sigma^2$, hence
  \begin{equation}
    \label{eq:expectation_Yab} \mathbb{E} [Y_{[a, b]}] = \sigma^2  (b - a) <
    \infty .
  \end{equation}
  Markov's inequality yields
  \begin{equation}
    \label{eq:markov_inequality} \mathbb{P} (Y_{[a, b]} > M) \le
    \frac{\sigma^2  (b - a)}{M},
  \end{equation}
  so $\mathbb{P} (Y_{[a, b]} < \infty) = 1$. If $K \subset \mathbb{R}$ is
  compact then $K \subseteq [- N, N]$ for some $N > 0$, so
  \begin{equation}
    \label{eq:compact_bound} \int_K X (t)^2  \hspace{0.17em} dt \le \int_{-
    N}^N X (t)^2  \hspace{0.17em} dt < \infty \quad \text{a.s.}
  \end{equation}
  Thus $X (\cdummy, \omega) \in L^2_{\mathrm{loc}} (\mathbb{R})$ for almost
  every $\omega$.
\end{proof}

\section{(Non-Stationary) Oscillatory Processes}

\begin{definition}
  \label{def:osc_proc}\tmtextbf{[Oscillatory process]} Let $F$ be a finite
  nonnegative Borel measure on $\mathbb{R}$. Let
  \begin{equation}
    \label{eq:gain_L2} A_t \in L^2 (F) \quad \forall t \in \mathbb{R}
  \end{equation}
  be the gain function and
  \begin{equation}
    \label{eq:oscillatory_function} \varphi_t (\lambda) = A_t (\lambda) e^{i
    \lambda t}
  \end{equation}
  the corresponding oscillatory function. An oscillatory process is a
  stochastic process represented as
  \begin{equation}
    \label{eq:oscillatory_process} Z (t) = \int_{\mathbb{R}} \varphi_t
    (\lambda)  \hspace{0.17em} d \Phi (\lambda) = \int_{\mathbb{R}} A_t
    (\lambda) e^{i \lambda t}  \hspace{0.17em} d \Phi (\lambda)
  \end{equation}
  where $\Phi$ is a complex orthogonal random measure with spectral measure
  $F$ satisfying
  \begin{equation}
    \label{eq:orthogonality_phi} \mathbb{E} [\Phi (\lambda) \overline{\Phi
    (\mu)}] = \delta (\lambda - \mu)  \hspace{0.17em} dF (\lambda)
  \end{equation}
  and covariance
  \begin{equation}
    \label{eq:oscillatory_covariance} \begin{array}{ll}
      R_Z (t, s) & =\mathbb{E} [Z (t) \overline{Z (s)}] = \int_{\mathbb{R}}
      A_t (\lambda) \overline{A_s (\lambda)} e^{i \lambda (t - s)} 
      \hspace{0.17em} dF (\lambda)\\
      & = \int_{\mathbb{R}} \varphi_t (\lambda) \overline{\varphi_s
      (\lambda)} \hspace{0.17em} dF (\lambda) .
    \end{array}
  \end{equation}
\end{definition}

\begin{definition}
  \label{def:epsd}\tmtextbf{[Evolutionary power spectral density (EPSD)]} If
  $dF (\lambda) = S (\lambda)  \hspace{0.17em} d \lambda$, define
  \begin{equation}
    \label{eq:epsd_definition} S_t (\lambda) \assign |A_t (\lambda) |^2 S
    (\lambda)
  \end{equation}
  so
  \begin{equation}
    dF_t (\lambda) = S_t (\lambda)  \hspace{0.17em} d \lambda = |A_t (\lambda)
    |^2  \hspace{0.17em} dF (\lambda)
  \end{equation}
\end{definition}

\begin{theorem}
  \label{thm:realvaluedness}\tmtextbf{[Real-valuedness criterion for
  oscillatory processes]} Let $Z$ be an oscillatory process with $\varphi_t
  (\lambda) = A_t (\lambda) e^{i \lambda t}$ and spectral measure $F$. Then
  $Z$ is real-valued if and only if
  \begin{equation}
    \label{eq:gain_symmetry} A_t  (- \lambda) = \overline{A_t (\lambda)} \quad
    \text{for } F \text{-a.e. } \lambda \in \mathbb{R},
  \end{equation}
  equivalently
  \begin{equation}
    \label{eq:osc_symmetry} \varphi_t  (- \lambda) = \overline{\varphi_t
    (\lambda)} \quad \text{for } F \text{-a.e. } \lambda \in \mathbb{R}.
  \end{equation}
\end{theorem}

\begin{proof}
  Taking complex conjugates in
  \[ Z (t) = \int A_t (\lambda) e^{i \lambda t}  \hspace{0.17em} d \Phi
     (\lambda) \]
  and applying the real-valued symmetry for the orthogonal random measure,
  with the change of variables $\mu = - \lambda$, yields $A_t (\lambda) =
  \overline{A_t  (- \lambda)}$ $F$-a.e., which is \eqref{eq:gain_symmetry}.
  The equivalence with \eqref{eq:osc_symmetry} follows from $\varphi_t
  (\lambda) = A_t (\lambda) e^{i \lambda t}$. Reversing the steps gives the
  converse.
\end{proof}

\begin{theorem}
  \label{thm:existence_osc}\tmtextbf{[Existence of oscillatory processes with
  explicit $L^2$-limit construction]} Let $F$ be absolutely continuous with
  density $S (\lambda)$ and let $A_t (\lambda) \in L^2 (F)$ for all $t \in
  \mathbb{R}$, measurable jointly in $(t, \lambda)$. Define
  \begin{equation}
    \label{eq:time_dependent_spectrum} \sigma_t^2 \assign \int_{\mathbb{R}}
    |A_t (\lambda) |^2  \hspace{0.17em} dF (\lambda) < \infty .
  \end{equation}
  Then there exists a complex orthogonal random measure $\Phi$ with spectral
  measure $F$ such that for each fixed $t$ the stochastic integral
  \begin{equation}
    \label{eq:oscillatory_well_defined} Z (t) = \int_{\mathbb{R}} A_t
    (\lambda) e^{i \lambda t}  \hspace{0.17em} d \Phi (\lambda)
  \end{equation}
  is well-defined as an $L^2 (\Omega)$-limit and has covariance
  \eqref{eq:oscillatory_covariance}.
\end{theorem}

\begin{proof}
  \begin{enumerate}
    \item Let $\mathsf{S}$ be the set of simple functions $g (\lambda) =
    \sum_{j = 1}^n c_j  \textbf{1}_{E_j} (\lambda)$ with disjoint Borel $E_j$
    and $F (E_j) < \infty$. Define $\int g \hspace{0.17em} d \Phi \assign
    \sum_{j = 1}^n c_j \Phi (E_j)$. Orthogonality gives the isometry
    \[ \mathbb{E} \left[ \left| \int g \hspace{0.17em} d \Phi \right|^2
       \right] = \int_{\mathbb{R}} |g (\lambda) |^2  \hspace{0.17em} dF
       (\lambda) . \]
    \item For $h \in L^2 (F)$, choose $g_n \in \mathsf{S}$ with $\|h - g_n
    \|_{L^2 (F)} \to 0$. Then
    \begin{equation}
      \label{eq:cauchy_sequence_lims} \mathbb{E} \left[ \left| \int g_n 
      \hspace{0.17em} d \Phi - \int g_m  \hspace{0.17em} d \Phi \right|^2
      \right] = \|g_n - g_m \|_{L^2 (F)}^2, \qquad \lim_{n, m \to \infty}
      \|g_n - g_m \|_{L^2 (F)}^2 = 0.
    \end{equation}
    \item Completeness of $L^2 (\Omega)$ yields existence of the limit, and
    the isometry shows independence of the approximating sequence.
  \end{enumerate}
\end{proof}

\section{Filter Representations and Invertibility for Oscillatory Processes}

\begin{definition}
  \label{def:filter_gain}\tmtextbf{[Time-dependent filter and gain]} The
  time-dependent filter $h (t, u)$ and gain function $A_t (\lambda)$ satisfy
  \begin{equation}
    \label{eq:gain_from_filter} A_t (\lambda) = \int_{- \infty}^{\infty} h (t,
    u) e^{- i \lambda (t - u)}  \hspace{0.17em} du,
  \end{equation}
  \begin{equation}
    \label{eq:filter_from_gain} h (t, u) = \frac{1}{2 \pi}  \int_{-
    \infty}^{\infty} A_t (\lambda) e^{i \lambda (t - u)}  \hspace{0.17em} d
    \lambda,
  \end{equation}
  with
  \begin{equation}
    \label{eq:filter_square_int} \int_{- \infty}^{\infty} |h (t, u) |^2 
    \hspace{0.17em} du < \infty \quad \forall t \in \mathbb{R}.
  \end{equation}
\end{definition}

\begin{theorem}
  \label{thm:general_filter}\tmtextbf{[Forward and inverse filter
  representations for general oscillatory processes]} Let $Z (t)$ be an
  oscillatory process with $\varphi_t (\lambda) = A_t (\lambda) e^{i \lambda
  t}$. Then:
  \begin{enumerate}
    \item
    \begin{equation}
      \label{eq:general_forward_filter} Z (t) = \int_{\mathbb{R}} h (t,
      \lambda)  \hspace{0.17em} d \Phi (\lambda), \qquad h (t, \lambda) = A_t
      (\lambda) e^{i \lambda t} .
    \end{equation}
    \item If there is a white noise representation $dW (u)$ with
    \begin{equation}
      \label{eq:whitenoise_orthog} \mathbb{E} [dW (u_1) \overline{dW (u_2)}] =
      \delta (u_1 - u_2)  \hspace{0.17em} du_1,
    \end{equation}
    then
    \begin{equation}
      \label{eq:whitenoise_filter} Z (t) = \int_{- \infty}^{\infty} h (t, u) 
      \hspace{0.17em} dW (u) .
    \end{equation}
  \end{enumerate}
\end{theorem}

\begin{proof}
  Item (1) is \eqref{eq:oscillatory_process}. Item (2) follows from the
  spectral relation
  \[ d \Phi (\lambda) = \frac{1}{2 \pi}  \int e^{- i \lambda u} 
     \hspace{0.17em} dW (u)  \hspace{0.17em} du \]
  and the Fourier pair in Definition \ref{def:filter_gain}.
\end{proof}

\begin{definition}
  \label{def:amplitude_nondeg}\tmtextbf{[Amplitude nondegeneracy]}
  \begin{equation}
    \label{eq:nonzero} A_t (\lambda) \neq 0 \quad \text{for all } (t, \lambda)
    \text{in the support of } F.
  \end{equation}
\end{definition}

\begin{definition}
  \label{def:orthonormality}\tmtextbf{[Kernel orthonormality]}
  \begin{equation}
    \label{eq:delta_ortho} \int_{- \infty}^{\infty} A_t (\lambda_1) A_t
    (\lambda_2) e^{i (\lambda_2 - \lambda_1) t}  \hspace{0.17em} dt = \delta
    (\lambda_1 - \lambda_2) .
  \end{equation}
\end{definition}

\begin{theorem}
  \label{thm:fund_inv}\tmtextbf{[Fundamental invertibility for oscillatory
  processes]} The inversion formula
  \begin{equation}
    \label{eq:inv_identity} d \Phi (\lambda) = \int_{- \infty}^{\infty} A_t
    (\lambda) e^{- i \lambda t} Z (t)  \hspace{0.17em} dt
  \end{equation}
  holds if and only if \eqref{eq:nonzero} and \eqref{eq:delta_ortho} hold, and
  the gain function satisfies the additional consistency condition
  \begin{equation}
    \label{eq:consistency_condition} \int_{- \infty}^{\infty} A_t (\lambda)
    A_s (\mu) e^{i (\mu s - \lambda t)}  \hspace{0.17em} dt = \delta (\lambda
    - \mu) \delta (s - t)
  \end{equation}
  for all $s, \mu$ in the support of the respective measures.
\end{theorem}

\begin{proof}
  The forward direction requires the strengthened orthonormality condition
  \eqref{eq:consistency_condition} to handle the mixed time variables arising
  from the substitution of $Z (t) = \int A_s (\mu) e^{i \mu s} 
  \hspace{0.17em} d \Phi (\mu)$. Under this condition, the double integral
  reduces to $\delta (\lambda - \mu)  \hspace{0.17em} d \Phi (\mu) = d \Phi
  (\lambda)$. The reverse direction follows by testing on $Z_{\lambda_0} (t)
  \assign A_t (\lambda_0) e^{i \lambda_0 t}$.
\end{proof}

\begin{lemma}
  \label{lem:unique}\tmtextbf{[Uniqueness of inversion]} If $\mathcal{I}_1 Z =
  d \Phi (\lambda) =\mathcal{I}_2 Z$ for all $Z$, then $\mathcal{I}_1
  =\mathcal{I}_2$.
\end{lemma}

\begin{proof}
  Let $\mathcal{L}=\mathcal{I}_1 -\mathcal{I}_2$. Then $\mathcal{L}Z = 0$ for
  all $Z$, hence $\mathcal{L}= 0$.
\end{proof}

\section{Unitarily Time-Changed Stationary Processes}

\subsection{Unitary time-change operator}

\begin{theorem}
  \label{thm:local_unitarity}\tmtextbf{[Unitary time-change and local
  isometry]} Let $\theta : \mathbb{R} \to \mathbb{R}$ be absolutely
  continuous, strictly increasing, and bijective with $\dot{\theta} (t) > 0$
  a.e. For measurable $f$, define
  \begin{equation}
    \label{eq:U_theta_def} (U_{\theta} f) (t) = \sqrt{\dot{\theta} (t)} 
    \hspace{0.17em} f (\theta (t)) .
  \end{equation}
  Define the inverse map
  \begin{equation}
    \label{eq:U_theta_inverse} (U_{\theta}^{- 1} g) (s) = \frac{g (\theta^{-
    1} (s))}{\sqrt{\dot{\theta} (\theta^{- 1} (s))}} .
  \end{equation}
  For every compact $K \subseteq \mathbb{R}$ and $f \in L^2_{\mathrm{loc}}
  (\mathbb{R})$,
  \begin{equation}
    \label{eq:local_isometry} \int_K | (U_{\theta} f) (t) |^2 \hspace{0.17em}
    dt = \int_{\theta (K)} |f (s) |^2  \hspace{0.17em} ds.
  \end{equation}
  Moreover, for $f, g \in L^2_{\mathrm{loc}} (\mathbb{R})$,
  \begin{equation}
    \label{eq:two_sided_inverse} U_{\theta}^{- 1}  (U_{\theta} f) = f, \qquad
    U_{\theta}  (U_{\theta}^{- 1} g) = g.
  \end{equation}
\end{theorem}

\begin{proof}
  By \eqref{eq:U_theta_def},
  \[ \int_K | (U_{\theta} f) (t) |^2  \hspace{0.17em} dt = \int_K \dot{\theta}
     (t) |f (\theta (t)) |^2  \hspace{0.17em} dt. \]
  With $s = \theta (t)$ and $ds = \dot{\theta} (t)  \hspace{0.17em} dt$, this
  equals $\int_{\theta (K)} |f (s) |^2  \hspace{0.17em} ds$. Direct
  substitution proves the two identities in \eqref{eq:two_sided_inverse}.
\end{proof}

\subsection{The subclass and exact inversion}

\begin{definition}
  \label{def:utc_subclass}\tmtextbf{[Unitarily time-changed stationary
  process]} Let $X = \{X (t)\}_{t \in \mathbb{R}}$ be a second-order
  stationary process with sample paths in $L^2_{\mathrm{loc}} (\mathbb{R})$.
  Let $\theta$ satisfy the hypotheses of Theorem \ref{thm:local_unitarity}.
  Define
  \begin{equation}
    \label{eq:utc_def_Z} Z (t) \assign (U_{\theta} X) (t) = \sqrt{\dot{\theta}
    (t)}  \hspace{0.17em} X (\theta (t)) .
  \end{equation}
  Then $Z$ is called a unitarily time-changed stationary process.
\end{definition}

\begin{lemma}
  \label{lem:utc_inverse}\tmtextbf{[Exact recovery of $X$]} If $Z$ is defined
  by \eqref{eq:utc_def_Z}, then
  \begin{equation}
    \label{eq:utc_inverse_identity} X = U_{\theta}^{- 1} Z.
  \end{equation}
\end{lemma}

\begin{proof}
  This is the identity $U_{\theta}^{- 1}  (U_{\theta} X) = X$ from
  \eqref{eq:two_sided_inverse}.
\end{proof}

\subsection{Filter representations}

\begin{theorem}
  \label{thm:inverse_filter}\tmtextbf{[Forward and inverse filter
  representations for unitarily time-changed stationary processes]} Let
  $\theta$ satisfy Theorem \ref{thm:local_unitarity}. Let $X (u) =
  \int_{\mathbb{R}} e^{i \lambda u}  \hspace{0.17em} d \Phi (\lambda)$ and let
  $Z (t) = \sqrt{\dot{\theta} (t)}  \hspace{0.17em} X (\theta (t))$. Then:
  \begin{enumerate}
    \item
    \begin{equation}
      \label{eq:forward_kernel} h (t, u) = \sqrt{\dot{\theta} (t)} 
      \hspace{0.17em} \delta (u - \theta (t)) .
    \end{equation}
    \item
    \begin{equation}
      \label{eq:inverse_kernel} g (t, s) = \frac{\delta (s - \theta^{- 1}
      (t))}{\sqrt{\dot{\theta} (\theta^{- 1} (t))}} .
    \end{equation}
    \item
    \begin{equation}
      \label{eq:filter_identity} X (t) = \int_{\mathbb{R}} g (t, s) 
      \hspace{0.17em} Z (s)  \hspace{0.17em} ds = \frac{Z (\theta^{- 1}
      (t))}{\sqrt{\dot{\theta} (\theta^{- 1} (t))}} .
    \end{equation}
  \end{enumerate}
\end{theorem}

\begin{proof}
  Item (1) is the sifting identity for $\delta$ applied to $X (\theta (t))$.
  Item (2) is the explicit inverse map $U_{\theta}^{- 1}$ written as an
  integral kernel. Item (3) is substitution.
\end{proof}

\subsection{Stationary to oscillatory}

\begin{theorem}
  \label{thm:Utheta_to_osc}\tmtextbf{[Unitary time change produces oscillatory
  process]} Let $X$ be zero-mean stationary with
  \[ X (t) = \int_{\mathbb{R}} e^{i \lambda t}  \hspace{0.17em} d \Phi
     (\lambda) . \]
  Let $\theta$ satisfy Theorem \ref{thm:local_unitarity}. Define
  \begin{equation}
    \label{eq:Z_def} Z (t) \assign (U_{\theta} X) (t) = \sqrt{\dot{\theta}
    (t)}  \hspace{0.17em} X (\theta (t)) .
  \end{equation}
  Then $Z$ is an oscillatory process with oscillatory function
  \begin{equation}
    \label{eq:oscillatory_function_Z} \varphi_t (\lambda) = \sqrt{\dot{\theta}
    (t)}  \hspace{0.17em} e^{i \lambda \theta (t)}
  \end{equation}
  and gain function
  \begin{equation}
    \label{eq:gain_function_Z} A_t (\lambda) = \sqrt{\dot{\theta} (t)} 
    \hspace{0.17em} e^{i \lambda (\theta (t) - t)} .
  \end{equation}
\end{theorem}

\begin{proof}
  Substitute $t \mapsto \theta (t)$ into the stationary representation and
  multiply by $\sqrt{\dot{\theta} (t)}$:
  \[ Z (t) = \sqrt{\dot{\theta} (t)}  \int_{\mathbb{R}} e^{i \lambda \theta
     (t)}  \hspace{0.17em} d \Phi (\lambda) = \int_{\mathbb{R}} \left(
     \sqrt{\dot{\theta} (t)}  \hspace{0.17em} e^{i \lambda \theta (t)} \right)
     d \Phi (\lambda) . \]
  This is \eqref{eq:oscillatory_process} with $\varphi_t$ given by
  \eqref{eq:oscillatory_function_Z}.
\end{proof}

\begin{corollary}
  \label{cor:epsd_timechange}\tmtextbf{[EPSD for the unitary time change]} If
  $dF (\lambda) = S (\lambda)  \hspace{0.17em} d \lambda$, then
  \begin{equation}
    \label{eq:epsd_timechange} S_t (\lambda) = |A_t (\lambda) |^2 S (\lambda)
    = \dot{\theta} (t)  \hspace{0.17em} S (\lambda) .
  \end{equation}
\end{corollary}

\begin{proof}
  From \eqref{eq:gain_function_Z}, $|A_t (\lambda) |^2 = \dot{\theta} (t)$.
\end{proof}

\section{Zero Localization}

\subsection{Kac--Rice}

\begin{theorem}
  \label{thm:kac_rice}\tmtextbf{[Kac--Rice formula for stationary processes]}
  Let $Z (t)$ be a real-valued, zero-mean Gaussian process with covariance $K
  (t, s) =\mathbb{E} [Z (t) Z (s)]$. Assume $Z$ is stationary with $K (t, s) =
  K (t - s)$, $K (0) > 0$, and that $K (h)$ is twice continuously
  differentiable in a neighborhood of $h = 0$ with $K'' (0) < 0$. Define
  \begin{equation}
    \label{eq:kac_rice_variance_deriv} K (0) \assign \mathbb{E} [Z (t)^2],
    \qquad K'' (0) \assign \left. \frac{d^2 K (h)}{dh^2} \right|_{h = 0} .
  \end{equation}
  Then for $t \in [a, b]$,
  \begin{equation}
    \label{eq:kac_rice_formula} \mathbb{E} [N_{[a, b]}] = \int_a^b
    \frac{1}{\pi}  \sqrt{\frac{- K'' (0)}{K (0)}}  \hspace{0.17em} dt.
  \end{equation}
\end{theorem}

\begin{proof}
  For stationary processes, $\mathbb{E} [Z (t) \dot{Z} (t)] = 0$ and
  $\mathbb{E} [\dot{Z} (t)^2] = - K'' (0)$. The joint density of $(Z (t),
  \dot{Z} (t))$ factors, and the standard Kac-Rice computation gives the
  result.
\end{proof}

\subsection{Bulinskaya}

\begin{theorem}
  \label{thm:bulinskaya}\tmtextbf{[Bulinskaya]} Let $X (t)$ be a real-valued,
  zero-mean stationary Gaussian process with covariance $R (h) =\mathbb{E} [X
  (t) X (t + h)]$. If $R$ is twice continuously differentiable in a
  neighborhood of $0$ and $R'' (0) < 0$, then with probability $1$ all zeros
  of $X$ are simple.
\end{theorem}

\begin{proof}
  For fixed $t_0$, $(X (t_0), \dot{X} (t_0))$ is jointly Gaussian and
  stationarity gives $\mathbb{E} [X (t_0) \dot{X} (t_0)] = R' (0) = 0$. Thus
  $X (t_0)$ and $\dot{X} (t_0)$ are independent. Since $R'' (0) < 0$, $\dot{X}
  (t_0)$ is non-degenerate, hence $\mathbb{P} (\dot{X} (t_0) = 0) = 0$. This
  yields $\mathbb{P} (X (t_0) = 0 \text{and } \dot{X} (t_0) = 0) = 0$, and the
  conclusion follows.
\end{proof}

\begin{remark}
  \label{rem:bulinskaya_nonstationary}The Bulinskaya theorem applies only to
  stationary processes. For unitarily time-changed processes $Z (t) =
  \sqrt{\dot{\theta} (t)} X (\theta (t))$, the cross-covariance $\mathbb{E} [Z
  (t) \dot{Z} (t)] = \frac{\sigma^2}{2}  \ddot{\theta} (t)$ is generally
  non-zero, so the theorem does not apply.
\end{remark}

\section{Example: The Hardy $Z$-Function}

\subsection{Definitions}

\begin{definition}
  \label{def:hardyZ}\tmtextbf{[Hardy $Z$-function]} Let $\zeta (s)$ be the
  Riemann zeta function and let $\theta (t)$ denote the Riemann--Siegel theta
  function. Define
  \begin{equation}
    \label{eq:hardy_z_def} Z (t) \assign e^{i \theta (t)}  \hspace{0.17em}
    \zeta \hspace{-0.17em} \left( \tfrac{1}{2} + it \right) .
  \end{equation}
\end{definition}

\begin{definition}
  \label{def:Theta}\tmtextbf{[Monotonized theta time change]} Let $a > 0$ be
  the unique critical point of $\theta$ on $(0, \infty)$. Define $\Theta : [0,
  \infty) \to [\Theta (0), \infty)$ by
  \begin{equation}
    \label{eq:Theta_def} \Theta (t) \assign \left\{\begin{array}{ll}
      2 \theta (a) - \theta (t), & 0 \le t \le a,\\
      \theta (t), & t \ge a.
    \end{array}\right.
  \end{equation}
\end{definition}

\subsection{Stationary candidate and exact inversion}

\begin{definition}
  \label{def:X_from_Z}\tmtextbf{[Stationary candidate defined by
  $U_{\Theta}^{- 1}$]} Define
  \begin{equation}
    \label{eq:X_def_hardy} X (u) \assign (U_{\Theta}^{- 1} Z) (u) = \frac{Z
    (\Theta^{- 1} (u))}{\sqrt{\Theta' (\Theta^{- 1} (u))}}, \qquad u \in
    [\Theta (0), \infty) .
  \end{equation}
\end{definition}

\begin{lemma}
  \label{lem:Z_from_X}\tmtextbf{[Exact reconstruction $Z = U_{\Theta} X$]}
  With $X$ as in Definition \ref{def:X_from_Z},
  \begin{equation}
    \label{eq:Z_from_X_hardy} Z (t) = (U_{\Theta} X) (t) = \sqrt{\Theta' (t)} 
    \hspace{0.17em} X (\Theta (t)), \qquad t \in [0, \infty) .
  \end{equation}
\end{lemma}

\begin{proof}
  This is the identity $U_{\Theta}  (U_{\Theta}^{- 1} Z) = Z$ from Theorem
  \ref{thm:local_unitarity}, applied on the domain where $\Theta$ is defined.
\end{proof}

\subsection{$L^2_{\mathrm{loc}}$ identity on finite intervals}

\begin{lemma}
  \label{lem:finite_interval_identity_hardy}\tmtextbf{[Finite-interval $L^2$
  identity]} For every $T > 0$,
  \begin{equation}
    \label{eq:finite_interval_L2_identity_hardy} \int_{\Theta (0)}^{\Theta
    (T)} |X (u) |^2 \hspace{0.17em} du = \int_0^T |Z (t) |^2  \hspace{0.17em}
    dt.
  \end{equation}
\end{lemma}

\begin{proof}
  With $u = \Theta (t)$, $du = \Theta' (t)  \hspace{0.17em} dt$, and $X (u) =
  Z (t) / \sqrt{\Theta' (t)}$,
  \[ \int_{\Theta (0)}^{\Theta (T)} |X (u) |^2  \hspace{0.17em} du = \int_0^T
     \left| \frac{Z (t)}{\sqrt{\Theta' (t)}} \right|^2 \Theta' (t) 
     \hspace{0.17em} dt = \int_0^T |Z (t) |^2  \hspace{0.17em} dt. \]
\end{proof}

\begin{theorem}
  \label{thm:X_L2loc}\tmtextbf{[$X \in L^2_{\mathrm{loc}} ([\Theta (0),
  \infty))$]}
  \begin{equation}
    \label{eq:X_L2loc} X \in L^2_{\mathrm{loc}} ([\Theta (0), \infty)) .
  \end{equation}
\end{theorem}

\begin{proof}
  Let $[c, d] \subset [\Theta (0), \infty)$ be compact. Then $[\Theta^{- 1}
  (c), \Theta^{- 1} (d)] \subset [0, \infty)$ is compact, and $Z$ is bounded
  on that interval. Thus $\int_{\Theta^{- 1} (c)}^{\Theta^{- 1} (d)} |Z (t)
  |^2  \hspace{0.17em} dt < \infty$. By the same change of variables as in
  Lemma \ref{lem:finite_interval_identity_hardy},
  \[ \int_c^d |X (u) |^2 \hspace{0.17em} du = \int_{\Theta^{- 1}
     (c)}^{\Theta^{- 1} (d)} |Z (t) |^2  \hspace{0.17em} dt < \infty . \]
\end{proof}

\subsection{Limit-form mean-square statements}

\begin{theorem}
  \label{thm:hardy_littlewood_limit}\tmtextbf{[Hardy--Littlewood second moment
  (limit form)]}
  \begin{equation}
    \label{eq:hl_moment_limit} \lim_{T \to \infty}  \frac{\int_0^T \left|
    \zeta \hspace{-0.17em} \left( \tfrac{1}{2} + it \right) \right|^2 
    \hspace{0.17em} dt}{T \log T} = 1.
  \end{equation}
  Equivalently,
  \begin{equation}
    \label{eq:hl_moment_Z_limit} \lim_{T \to \infty}  \frac{\int_0^T |Z (t)
    |^2  \hspace{0.17em} dt}{T \log T} = 1.
  \end{equation}
\end{theorem}

\begin{theorem}
  \label{thm:Theta_ratio_limit}\tmtextbf{[Ratio limit for $\Theta$]}
  \begin{equation}
    \label{eq:Theta_ratio_limit} \lim_{T \to \infty}  \frac{\Theta
    (T)}{\frac{T}{2} \log T} = 1.
  \end{equation}
\end{theorem}

\begin{theorem}
  \label{thm:mean_square_X_limit}\tmtextbf{[Mean-square limit for $X$]}
  \begin{equation}
    \label{eq:mean_square_X_limit} \lim_{T \to \infty}  \frac{1}{\Theta (T) -
    \Theta (0)}  \int_{\Theta (0)}^{\Theta (T)} |X (u) |^2  \hspace{0.17em} du
    = 2.
  \end{equation}
\end{theorem}

\begin{proof}
  By Lemma \ref{lem:finite_interval_identity_hardy},
  \[ \frac{1}{\Theta (T) - \Theta (0)}  \int_{\Theta (0)}^{\Theta (T)} |X (u)
     |^2  \hspace{0.17em} du = \frac{\int_0^T |Z (t) |^2  \hspace{0.17em}
     dt}{\Theta (T) - \Theta (0)} . \]
  Write
  \[ \frac{\int_0^T |Z (t) |^2  \hspace{0.17em} dt}{\Theta (T) - \Theta (0)} =
     \left( \frac{\int_0^T |Z (t) |^2  \hspace{0.17em} dt}{T \log T} \right)
     \left( \frac{T \log T}{\Theta (T) - \Theta (0)} \right) . \]
  The first factor has limit $1$ by \eqref{eq:hl_moment_Z_limit}. From
  \eqref{eq:Theta_ratio_limit},
  \[ \lim_{T \to \infty}  \frac{T \log T}{\Theta (T)} = 2 \quad \Rightarrow
     \quad \lim_{T \to \infty}  \frac{T \log T}{\Theta (T) - \Theta (0)} = 2.
  \]
  Multiplying limits gives \eqref{eq:mean_square_X_limit}.
\end{proof}

\section{Time-average covariance conjectures}

\begin{definition}
  \label{def:empirical_covariance}\tmtextbf{[Empirical covariance kernel]} For
  $U > \Theta (0)$ and $\tau \in \mathbb{R}$ define
  \begin{equation}
    \label{eq:KU_def} K_U (\tau) \assign \frac{1}{U - \Theta (0)} 
    \int_{\Theta (0)}^U X (u)  \hspace{0.17em} X (u + \tau)  \hspace{0.17em}
    du.
  \end{equation}
\end{definition}

\begin{conjecture}
  \label{conj:stationary_kernel}\tmtextbf{[Existence of a stationary
  covariance kernel]} For each fixed $\tau \in \mathbb{R}$, the limit
  \begin{equation}
    \label{eq:K_limit} K (\tau) \assign \lim_{U \to \infty} K_U (\tau)
  \end{equation}
  exists in $\mathbb{R}$.
\end{conjecture}

\begin{conjecture}
  \label{conj:ergodic_realization}\tmtextbf{[Ergodic stationary realization]}
  There exists a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and a
  stationary ergodic process $\{X_{\mathrm{st}} (u, \omega)\}_{u \in
  \mathbb{R}}$ such that there exists $\omega_0 \in \Omega$ with
  \[ X_{\mathrm{st}} (u, \omega_0) = X (u) \quad \forall u \ge \Theta (0), \]
  and such that for every fixed $\tau \in \mathbb{R}$,
  \[ \mathbb{E} [X_{\mathrm{st}} (0, \omega) X_{\mathrm{st}} (\tau, \omega)] =
     \lim_{U \to \infty}  \frac{1}{U - \Theta (0)}  \int_{\Theta (0)}^U X (u) 
     \hspace{0.17em} X (u + \tau)  \hspace{0.17em} du. \]
\end{conjecture}

\begin{thebibliography}{9}
  {\bibitem{stationaryAndRelatedStochasticProcesses}}Harald Cram{\'e}r and M.
  R. Leadbetter. \tmtextit{Stationary and Related Processes: Sample Function
  Properties and Their Applications}. Wiley Series in Probability and
  Mathematical Statistics, 1967.
  
  {\bibitem{evolutionarySpectraAndNonStationaryProcesses}}Maurice B.
  Priestley. Evolutionary spectra and non-stationary processes.
  \tmtextit{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 27(2):204--229, 1965.
  
  {\bibitem{priestley1981}}Maurice B. Priestley. \tmtextit{Spectral Analysis
  and Time Series}. Academic Press, 1981.
  
  {\bibitem{bulinskaya}}Bulinskaya, E. V. On the mean number of crossings of a
  level by a stationary Gaussian process. \tmtextit{Theory of Probability and
  Its Applications}, 1961.
\end{thebibliography}

\end{document}
