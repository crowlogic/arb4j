\documentclass[12pt]{article}
\usepackage{amsmath,amsthm,amssymb,graphicx,enumitem}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}
\newtheorem{conjecture}{Conjecture}

\newcommand{\defeq}{\mathrel{\vcenter{\baselineskip0.5ex \lineskiplimit0pt
                     \hbox{\scriptsize.}\hbox{\scriptsize.}}}%
                     =}

\title{Unitarily Time-Changed Stationary Processes: A Subclass of Oscillatory Processes}
\author{Stephen Crowley}
\date{December 13, 2025}

\begin{document}

\maketitle

\begin{abstract}
A unitary time-change operator $U_{\theta}$ is constructed for absolutely continuous, strictly increasing time reparametrizations $\theta$, acting on functions that are locally square-integrable. Applying $U_{\theta}$ to the Cramér spectral representation of a stationary process $X(t)$ produces the transformed process
\[ Z(t) = (U_{\theta} X)(t) = \sqrt{\dot{\theta}(t)} X(\theta(t)) = \sqrt{\dot{\theta}(t)} \int_{\mathbb{R}} e^{i \lambda\theta(t)} d\Phi(\lambda) \]
which is an oscillatory process with oscillatory function $\phi_t(\lambda) = \sqrt{\dot{\theta}(t)} e^{i \lambda \theta(t)}$, evolutionary power spectral density $S_t(\lambda) = \dot{\theta}(t) S(\lambda)$, and covariance kernel
\[ K_Z(t, s) = \sqrt{\dot{\theta}(t) \dot{\theta}(s)} K_X(\theta(t), \theta(s)) \]
where $K_X$ is the stationary covariance of $X(t) = \int_{\mathbb{R}} e^{i \lambda t} d\Phi(\lambda)$. Following Mandrekar's characterization theorem \cite{mandrekar1972}, every oscillatory process admits a stationary representation via shift-commuting operators. The generalized Kac-Rice formula for non-stationary processes gives the expected zero-counting function. By Bulinskaya's theorem, when the covariance is twice continuously differentiable with $\ddot{R}(0) < 0$, almost all zeros are simple.
\end{abstract}

\tableofcontents

\section{Gaussian Processes}

\subsection{Definition}

\begin{definition}
\label{def:gaussian_process}
(Gaussian process) Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space and $T$ a nonempty index set. A family $\{X_t : t \in T\}$ of real-valued random variables on $(\Omega, \mathcal{F}, \mathbb{P})$ is called a Gaussian process if for every finite subset $\{t_1, \ldots, t_n\} \subset T$ the random vector $(X_{t_1}, \ldots, X_{t_n})$ is multivariate normal (possibly degenerate). Equivalently, every finite linear combination $\sum_{i = 1}^n a_i X_{t_i}$ is either almost surely constant or Gaussian. The mean function is $m(t) \defeq \mathbb{E}[X_t]$ and the covariance kernel is
\begin{equation}
\label{eq:covariance_kernel}
K(s, t) = \mathrm{Cov}(X_s, X_t)
\end{equation}
For any finite $(t_i)_{i = 1}^n \subset T$, the matrix $K_{ij} = K(t_i, t_j)$ is symmetric positive semidefinite, and a Gaussian process is completely determined in law by $m$ and $K$.
\end{definition}

\subsection{Stationary Processes}

\begin{definition}
\label{def:cramer_representation}
(Cramér spectral representation) A zero-mean stationary process $X$ with spectral measure $F$ admits the sample path representation
\begin{equation}
\label{eq:cramer_spectral}
X(t) = \int_{\mathbb{R}} e^{i \lambda t} d\Phi(\lambda)
\end{equation}
which has covariance
\begin{equation}
\label{eq:stationary_covariance}
R_X(t - s) = \int_{\mathbb{R}} e^{i \lambda(t - s)} dF(\lambda)
\end{equation}
\end{definition}

\subsection{Sample Path Realizations}

\begin{definition}
\label{def:L2loc}
(Locally square-integrable functions) Define
\begin{equation}
\label{eq:L2loc_def}
L^2_{\mathrm{loc}}(\mathbb{R}) \defeq \left\{ f : \mathbb{R} \to \mathbb{C}: \int_K |f(t)|^2 dt < \infty \text{ for every compact } K \subseteq \mathbb{R} \right\}
\end{equation}
\end{definition}

\begin{remark}
\label{rem:bounded_compact}
Every bounded measurable set in $\mathbb{R}$ is compact or contained in a compact set; hence $L^2_{\mathrm{loc}}(\mathbb{R})$ contains functions that are square-integrable on every bounded interval, including functions with polynomial growth at infinity.
\end{remark}

\begin{theorem}
\label{thm:sample_paths_L2loc}
(Sample paths in $L^2_{\mathrm{loc}}(\mathbb{R})$) Let $\{X(t)\}_{t \in \mathbb{R}}$ be a second-order stationary process with
\begin{equation}
\label{eq:finite_variance}
\sigma^2 \defeq \mathbb{E}[X(t)^2] < \infty
\end{equation}
Then almost every sample path lies in $L^2_{\mathrm{loc}}(\mathbb{R})$.
\end{theorem}

\begin{proof}
Fix a bounded interval $[a, b] \subset \mathbb{R}$ with $a < b$ and define
\begin{equation}
\label{eq:Y_ab}
Y_{[a, b]} \defeq \int_a^b X(t)^2 dt
\end{equation}
By Tonelli's theorem,
\begin{equation}
\label{eq:tonelli_expectation}
\mathbb{E}[Y_{[a, b]}] = \int_a^b \mathbb{E}[X(t)^2] dt
\end{equation}
By stationarity, $\mathbb{E}[X(t)^2] = \sigma^2$, hence
\begin{equation}
\label{eq:expected_Y}
\mathbb{E}[Y_{[a, b]}] = \sigma^2(b - a) < \infty
\end{equation}
Markov's inequality yields
\begin{equation}
\label{eq:markov_bound}
\mathbb{P}(Y_{[a, b]} > M) \leq \frac{\sigma^2(b - a)}{M}
\end{equation}
so $\mathbb{P}(Y_{[a, b]} < \infty) = 1$. If $K \subset \mathbb{R}$ is compact then $K \subseteq [-N, N]$ for some $N > 0$, so
\begin{equation}
\label{eq:compact_bound}
\int_K X(t)^2 dt \leq \int_{-N}^N X(t)^2 dt < \infty \text{ a.s.}
\end{equation}
Thus $X(\cdot, \omega) \in L^2_{\mathrm{loc}}(\mathbb{R})$ for almost every $\omega$.
\end{proof}

\section{Oscillatory Processes}

\subsection{Definition}

\begin{definition}
\label{def:oscillatory_process}
(Oscillatory process) Let $F$ be a finite nonnegative Borel measure on $\mathbb{R}$. Let
\begin{equation}
\label{eq:gain_condition}
A_t \in L^2(F) \quad \forall t \in \mathbb{R}
\end{equation}
be the gain function and
\begin{equation}
\label{eq:oscillatory_function}
\phi_t(\lambda) = A_t(\lambda) e^{i\lambda t}
\end{equation}
the corresponding oscillatory function. An oscillatory process is a stochastic process represented as
\begin{equation}
\label{eq:oscillatory_representation}
\begin{aligned}
Z(t) &= \int_{\mathbb{R}} \phi_t(\lambda) d\Phi(\lambda)\\
&= \int_{\mathbb{R}} A_t(\lambda) e^{i\lambda t} d\Phi(\lambda)
\end{aligned}
\end{equation}
where $\Phi$ is a complex orthogonal random measure with spectral measure $F$ satisfying
\begin{equation}
\label{eq:orthogonal_measure}
\mathbb{E}[\Phi(\lambda) \overline{\Phi(\mu)}] = \delta(\lambda - \mu) dF(\lambda)
\end{equation}
and covariance
\begin{equation}
\label{eq:oscillatory_covariance}
\begin{aligned}
R_Z(t, s) &= \mathbb{E}[Z(t) \overline{Z(s)}]\\
&= \int_{\mathbb{R}} A_t(\lambda) \overline{A_s(\lambda)} e^{i\lambda(t - s)} dF(\lambda)\\
&= \int_{\mathbb{R}} \phi_t(\lambda) \overline{\phi_s(\lambda)} dF(\lambda)
\end{aligned}
\end{equation}
\end{definition}

\begin{definition}
\label{def:EPSD}
(Evolutionary power spectral density) If $dF(\lambda) = S(\lambda) d\lambda$, define
\begin{equation}
\label{eq:EPSD}
S_t(\lambda) \defeq |A_t(\lambda)|^2 S(\lambda)
\end{equation}
so that
\begin{equation}
\label{eq:EPSD_measure}
\begin{aligned}
dF_t(\lambda) &= S_t(\lambda) d\lambda\\
&= |A_t(\lambda)|^2 dF(\lambda)\\
&= |A_t(\lambda)|^2 S(\lambda) d\lambda
\end{aligned}
\end{equation}
\end{definition}

\begin{theorem}
\label{thm:real_valued_criterion}
(Real-valuedness criterion for oscillatory processes) Let $Z$ be an oscillatory process with $\phi_t(\lambda) = A_t(\lambda) e^{i\lambda t}$ and spectral measure $F$. Then $Z$ is real-valued if and only if
\begin{equation}
\label{eq:real_gain_condition}
A_t(-\lambda) = \overline{A_t(\lambda)} \text{ for } F\text{-a.e. } \lambda \in \mathbb{R}
\end{equation}
equivalently
\begin{equation}
\label{eq:real_oscillatory_condition}
\phi_t(-\lambda) = \overline{\phi_t(\lambda)} \text{ for } F \text{-a.e. } \lambda \in \mathbb{R}
\end{equation}
\end{theorem}

\begin{proof}
Taking complex conjugates of (\ref{eq:oscillatory_representation}) and applying the symmetry $d\overline{\Phi(\lambda)} = d\Phi(-\lambda)$ for real processes, with change of variables $\mu = -\lambda$, yields $A_t(\lambda) = \overline{A_t(-\lambda)}$ $F$-a.e. Reversing the steps gives the converse.
\end{proof}

\begin{theorem}
\label{thm:oscillatory_existence}
(Existence of oscillatory processes with explicit $L^2$-limit construction) Let $F$ be absolutely continuous with density $S(\lambda)$ and let $A_t(\lambda) \in L^2(F)$ for all $t \in \mathbb{R}$, measurable jointly in $(t, \lambda)$. Define
\begin{equation}
\label{eq:variance_t}
\sigma_t^2 \defeq \int_{\mathbb{R}} |A_t(\lambda)|^2 dF(\lambda) < \infty
\end{equation}
Then there exists a complex orthogonal random measure $\Phi$ with spectral measure $F$ such that for each fixed $t$ the stochastic integral
\begin{equation}
\label{eq:stochastic_integral}
Z(t) = \int_{\mathbb{R}} A_t(\lambda) e^{i\lambda t} d\Phi(\lambda)
\end{equation}
is well-defined as an $L^2(\Omega)$-limit and has covariance (\ref{eq:oscillatory_covariance}).
\end{theorem}

\begin{proof}
Let $S$ be the set of simple functions $g(\lambda) = \sum_{j = 1}^n c_j \mathbf{1}_{E_j}(\lambda)$ with disjoint Borel $E_j$ and $F(E_j) < \infty$. Define $\int g \, d\Phi \defeq \sum_{j = 1}^n c_j \Phi(E_j)$. Orthogonality gives the isometry:
\begin{equation}
\label{eq:isometry}
\mathbb{E}\left|\int g \, d\Phi\right|^2 = \int_{\mathbb{R}} |g(\lambda)|^2 dF(\lambda)
\end{equation}
For $h \in L^2(F)$, choose $g_n \in S$ with $\|h - g_n\|_{L^2(F)} \to 0$. Then:
\begin{equation}
\label{eq:cauchy_sequence}
\mathbb{E}\left|\int g_n d\Phi - \int g_m d\Phi\right|^2 = \|g_n - g_m\|_{L^2(F)}^2
\end{equation}
and $\lim_{n, m \to \infty} \|g_n - g_m\|_{L^2(F)}^2 = 0$. Completeness of $L^2(\Omega)$ yields the limit, and the isometry shows independence of the approximating sequence.
\end{proof}

\section{Unitarily Time-Changed Stationary Processes}

\subsection{Unitary Time-Change Operator}

\begin{theorem}
\label{thm:unitary_time_change}
(Unitary time-change and local isometry) Let $\theta : \mathbb{R} \to \mathbb{R}$ be absolutely continuous, strictly increasing, and bijective with $\dot{\theta}(t) > 0$ a.e. For measurable $f$, define:
\begin{equation}
\label{eq:U_theta}
(U_{\theta} f)(t) = \sqrt{\dot{\theta}(t)} f(\theta(t))
\end{equation}
Define the inverse map:
\begin{equation}
\label{eq:U_theta_inverse}
(U_{\theta}^{-1} g)(s) = \frac{g(\theta^{-1}(s))}{\sqrt{\dot{\theta}(\theta^{-1}(s))}}
\end{equation}
For every compact $K \subseteq \mathbb{R}$ and $f \in L^2_{\mathrm{loc}}(\mathbb{R})$:
\begin{equation}
\label{eq:local_isometry}
\int_K |(U_{\theta} f)(t)|^2 dt = \int_{\theta(K)} |f(s)|^2 ds
\end{equation}
Moreover, for $f, g \in L^2_{\mathrm{loc}}(\mathbb{R})$:
\begin{equation}
\label{eq:inverse_identities}
U_{\theta}^{-1}(U_{\theta} f) = f, \quad U_{\theta}(U_{\theta}^{-1} g) = g
\end{equation}
\end{theorem}

\begin{proof}
Using change of variables $s = \theta(t)$, $ds = \dot{\theta}(t) dt$:
\begin{equation}
\label{eq:change_of_variables}
\int_K \dot{\theta}(t) |f(\theta(t))|^2 dt = \int_{\theta(K)} |f(s)|^2 ds
\end{equation}
Direct substitution verifies the inverse identities (\ref{eq:inverse_identities}).
\end{proof}

\begin{theorem}
\label{thm:mandrekar_characterization}
(Fundamental inversion via stationary representation \cite{mandrekar1972}) Let $Z(t)$ be an oscillatory process with spectral representation
\begin{equation}
\label{eq:Z_oscillatory}
Z(t) = \int_{\mathbb{R}} A_t(\lambda) e^{i\lambda t} d\Phi(\lambda)
\end{equation}
where $A_t \in L^2(F)$ for each $t$ and $\Phi$ is an orthogonal random measure with spectral measure $F$. Then there exists a stationary process
\begin{equation}
\label{eq:X_stationary}
X(t) = \int_{\mathbb{R}} e^{i\lambda t} d\Phi(\lambda)
\end{equation}
and a closed, densely-defined operator $A$ acting on the Hilbert space $H_X(\infty) = \overline{\mathrm{span}}\{X(s) : s \in \mathbb{R}\}$ such that
\begin{equation}
\label{eq:Z_as_AX}
Z(t) = (A X)(t)
\end{equation}
where the operator $A$ is defined by the spectral integral
\begin{equation}
\label{eq:A_operator}
A = \int_{\mathbb{R}} A_t(\lambda) E(d\lambda)
\end{equation}
with domain $D(A) \supseteq \{X(s) : s \in \mathbb{R}\}$, where $E$ is the spectral measure of the shift group $\{U_s\}_{s \in \mathbb{R}}$ defined by $U_s X(r) = X(r+s)$. The operator $A$ commutes with the shift group:
\begin{equation}
\label{eq:shift_commutation}
(A U_s)(h) = (U_s A)(h) \quad \text{for all } h \in D(A) \text{ and } s \in \mathbb{R}
\end{equation}
The random spectral measure $\Phi$ is uniquely determined by $X$ via $\Phi(B) = (E(B) X)(0)$ for all Borel $B$.
\end{theorem}

\begin{proof}
This is Mandrekar's characterization theorem \cite{mandrekar1972}. We outline the key steps:

Forward direction: Given oscillatory $Z(t)$ as in (\ref{eq:Z_oscillatory}), define the stationary curve
\begin{equation}
\label{eq:X_from_Z}
X(t) = \int_{\mathbb{R}} e^{i\lambda t} d\Phi(\lambda)
\end{equation}
By Stone's theorem, there exists a unitary shift group $\{U_s\}$ and spectral measure $E$ such that $X(t) = U_t X(0)$ and
\begin{equation}
\label{eq:X_spectral}
X(t) = \int_{\mathbb{R}} e^{i\lambda t} E(d\lambda) X(0)
\end{equation}
with $\Phi(B) = E(B) X(0)$. Define the operator as in (\ref{eq:A_operator}). By Dunford-Schwartz spectral theory, $A$ is a closed operator with domain containing $\{X(s) : s \in \mathbb{R}\}$. The commutation relation (\ref{eq:shift_commutation}) follows from $U_s E(B) = E(B) U_s$ for all Borel $B$. Computing:
\begin{equation}
\label{eq:AX_computation}
\begin{aligned}
(A X)(t) &= \int A_t(\lambda) E(d\lambda) \int e^{i\mu t} E(d\mu) X(0)\\
&= \int A_t(\lambda) e^{i\lambda t} E(d\lambda) X(0)\\
&= \int A_t(\lambda) e^{i\lambda t} d\Phi(\lambda) = Z(t)
\end{aligned}
\end{equation}

Reverse direction: If $Z(t) = (A X)(t)$ where $X$ is stationary and $(A U_s) = (U_s A)$, then by the Stone-von Neumann theorem on commutants of unitary groups, there exists a Borel measurable function $A_t(\cdot)$ such that (\ref{eq:A_operator}) holds. The domain condition $\{X(s) : s \in \mathbb{R}\} \subseteq D(A)$ implies
\begin{equation}
\label{eq:domain_condition}
\int_{\mathbb{R}} |A_t(\lambda)|^2 \|E(d\lambda) X(0)\|^2 < \infty
\end{equation}
for each $t$, giving $A_t \in L^2(F)$ where $dF(\lambda) = \|E(d\lambda) X(0)\|^2$. This yields the oscillatory representation.
\end{proof}

\begin{remark}
\label{rem:generality}
(Generality of the stationary representation) Theorem \ref{thm:mandrekar_characterization} establishes that every oscillatory process is a deformed stationary curve in the sense of Mandrekar \cite{mandrekar1972}. The key requirement is shift-commutation (\ref{eq:shift_commutation}). Unitarily time-changed processes arise as a particular explicit subclass where $A_t(\lambda) = \sqrt{\dot{\theta}(t)} e^{i\lambda(\theta(t)-t)}$. The theorem guarantees that for any choice of gain function $A_t(\lambda) \in L^2(F)$, there exists an underlying stationary process and operator recovering the oscillatory process. The notation $(A X)(t)$ indicates that $A$ is an operator acting on the process $X$, not pointwise function multiplication.
\end{remark}

\begin{definition}
\label{def:unitarily_time_changed}
(Unitarily time-changed stationary process) Let $X = \{X(t)\}_{t \in \mathbb{R}}$ be a second-order stationary process with sample paths in $L^2_{\mathrm{loc}}(\mathbb{R})$. Let $\theta$ satisfy Theorem \ref{thm:unitary_time_change}. Define:
\begin{equation}
\label{eq:Z_time_changed}
Z(t) \defeq (U_{\theta} X)(t) = \sqrt{\dot{\theta}(t)} X(\theta(t))
\end{equation}
Then $Z$ is called a unitarily time-changed stationary process.
\end{definition}

\begin{lemma}
\label{lem:exact_recovery}
(Exact recovery of $X$) If $Z$ is defined as in (\ref{eq:Z_time_changed}), then:
\begin{equation}
\label{eq:X_recovery}
X = U_{\theta}^{-1} Z
\end{equation}
\end{lemma}

\begin{proof}
This is precisely (\ref{eq:inverse_identities}) from Theorem \ref{thm:unitary_time_change}.
\end{proof}

\subsection{Stationary to Oscillatory}

\begin{theorem}
\label{thm:time_change_oscillatory}
(Unitary time change produces oscillatory process) Let $X$ be zero-mean stationary with spectral representation (\ref{eq:cramer_spectral}). Let $\theta$ satisfy Theorem \ref{thm:unitary_time_change}. Define $Z(t)$ as in (\ref{eq:Z_time_changed}). Then $Z$ is an oscillatory process with oscillatory function:
\begin{equation}
\label{eq:phi_t_time_change}
\begin{aligned}
\phi_t(\lambda) &= A_t(\lambda) e^{i\lambda t}\\
&= \sqrt{\dot{\theta}(t)} e^{i\lambda(\theta(t) - t)} e^{i\lambda t}\\
&= \sqrt{\dot{\theta}(t)} e^{i\lambda\theta(t)}
\end{aligned}
\end{equation}
where the gain function is:
\begin{equation}
\label{eq:gain_time_change}
A_t(\lambda) = \sqrt{\dot{\theta}(t)} e^{i\lambda(\theta(t) - t)}
\end{equation}
\end{theorem}

\begin{proof}
Substituting $t \mapsto \theta(t)$ in (\ref{eq:cramer_spectral}):
\begin{equation}
\label{eq:Z_substitution}
\begin{aligned}
Z(t) &= \sqrt{\dot{\theta}(t)} \int_{\mathbb{R}} e^{i\lambda\theta(t)} d\Phi(\lambda)\\
&= \int_{\mathbb{R}} \left(\sqrt{\dot{\theta}(t)} e^{i\lambda\theta(t)}\right) d\Phi(\lambda)
\end{aligned}
\end{equation}
Thus $\phi_t(\lambda) = \sqrt{\dot{\theta}(t)} e^{i\lambda\theta(t)}$ and $A_t(\lambda) = \sqrt{\dot{\theta}(t)} e^{i\lambda(\theta(t) - t)}$ since $\phi_t(\lambda) = A_t(\lambda) e^{i\lambda t}$ by (\ref{eq:oscillatory_function}).
\end{proof}

\begin{corollary}
\label{cor:EPSD_time_change}
(EPSD for the unitary time change) If $dF(\lambda) = S(\lambda) d\lambda$, then:
\begin{equation}
\label{eq:EPSD_time_change}
S_t(\lambda) = |A_t(\lambda)|^2 S(\lambda) = \dot{\theta}(t) S(\lambda)
\end{equation}
\end{corollary}

\begin{proof}
From (\ref{eq:gain_time_change}):
\begin{equation}
\label{eq:gain_squared}
|A_t(\lambda)|^2 = \dot{\theta}(t) |e^{i\lambda(\theta(t) - t)}|^2 = \dot{\theta}(t)
\end{equation}
\end{proof}

\section{Zero Localization}

\subsection{Kac-Rice Formula}

\begin{theorem}
\label{thm:kac_rice}
(Generalized Kac-Rice formula) Let $Z(t)$ be a real-valued, zero-mean Gaussian process with covariance $K(t, s) = \mathbb{E}[Z(t) Z(s)]$. Assume $K(t, t) > 0$ and that $K(t, s)$ is twice continuously differentiable in a neighborhood of $(t, t)$. Define:
\begin{equation}
\label{eq:K_derivatives}
K(t) \defeq K(t, t), \quad K_s(t) \defeq \left.\frac{\partial K(t,s)}{\partial s}\right|_{s = t}, \quad K_{ss}(t) \defeq \left.\frac{\partial^2 K(t,s)}{\partial s^2}\right|_{s = t}
\end{equation}
Assume
\begin{equation}
\label{eq:V_condition}
V(t) \defeq K(t) K_{ss}(t) - [K_s(t)]^2 > 0
\end{equation}
for $t \in [a, b]$. Then:
\begin{equation}
\label{eq:kac_rice_formula}
\mathbb{E}[N_{[a, b]}] = \int_a^b \frac{1}{\pi}\sqrt{\frac{V(t)}{K(t)^2}} \, dt
\end{equation}
\end{theorem}

\begin{proof}
The joint density of $(Z(t), \dot{Z}(t))$ is Gaussian with covariance matrix $\Sigma(t) = \begin{pmatrix} K(t) & K_s(t)\\ K_s(t) & K_{ss}(t) \end{pmatrix}$. The Kac-Rice formula gives:
\begin{equation}
\label{eq:kac_rice_derivation}
\begin{aligned}
\mathbb{E}[N_{[a, b]}] &= \int_a^b \mathbb{E}[|\dot{Z}(t)| \mid Z(t) = 0] p_{Z(t)}(0) \, dt\\
&= \int_a^b \frac{1}{\sqrt{2\pi K(t)}} \sqrt{\frac{2}{\pi}\frac{K(t) K_{ss}(t) - K_s(t)^2}{K(t)^2}} \, dt
\end{aligned}
\end{equation}
Simplifying yields (\ref{eq:kac_rice_formula}).
\end{proof}

\subsection{Bulinskaya's Theorem}

\begin{theorem}
\label{thm:bulinskaya}
(Bulinskaya) Let $X(t)$ be a real-valued, zero-mean stationary Gaussian process with covariance $R(h) = \mathbb{E}[X(t) X(t + h)]$. If $R$ is twice continuously differentiable in a neighborhood of 0 and $R''(0) < 0$, then with probability 1 all zeros of $X$ are simple.
\end{theorem}

\begin{proof}
For fixed $t_0$, $(X(t_0), \dot{X}(t_0))$ is jointly Gaussian. Stationarity gives $\mathbb{E}[X(t_0) \dot{X}(t_0)] = R'(0) = 0$, so they are independent. Since $R''(0) < 0$, $\dot{X}(t_0)$ is non-degenerate and $\mathbb{P}(\dot{X}(t_0) = 0) = 0$. Thus $\mathbb{P}(X(t_0) = 0 \text{ and } \dot{X}(t_0) = 0) = 0$. By continuity and countable union over rationals, all zeros are simple almost surely.
\end{proof}

\section{Example: The Hardy Z-Function}

\subsection{Definitions}

\begin{definition}
\label{def:hardy_Z}
(Hardy Z-function) Let $\zeta(s)$ be the Riemann zeta function and let $\theta(t)$ denote the Riemann-Siegel theta function. Define:
\begin{equation}
\label{eq:hardy_Z}
Z(t) = e^{i\theta(t)} \zeta(1/2 + it)
\end{equation}
\end{definition}

\begin{definition}
\label{def:monotonized_theta}
(Monotonized theta time change) Let $a > 0$ be the unique critical point of $\theta$ in $(0, \infty)$ where $\dot{\theta}(a) = 0$. Define $\Theta : [0, \infty) \to [\Theta(0), \infty)$ by:
\begin{equation}
\label{eq:Theta_def}
\Theta(t) = \begin{cases}
2\theta(a) - \theta(t) & 0 \leq t \leq a\\
\theta(t) & t \geq a
\end{cases}
\end{equation}
\end{definition}

\subsection{Stationary Candidate and Exact Inversion}

\begin{definition}
\label{def:X_hardy}
(Stationary candidate defined by $U_{\Theta}^{-1}$) Define:
\begin{equation}
\label{eq:X_hardy}
X(u) = (U_{\Theta}^{-1} Z)(u) = \frac{Z(\Theta^{-1}(u))}{\sqrt{\Theta'(\Theta^{-1}(u))}} \quad \forall u \in [\Theta(0), \infty)
\end{equation}
\end{definition}

\begin{lemma}
\label{lem:hardy_reconstruction}
(Exact reconstruction $Z = U_{\Theta} X$) With $X$ as defined in (\ref{eq:X_hardy}):
\begin{equation}
\label{eq:Z_reconstruction}
Z(t) = (U_{\Theta} X)(t) = \sqrt{\Theta'(t)} X(\Theta(t)) \quad \forall t \in [0, \infty)
\end{equation}
\end{lemma}

\begin{proof}
This is (\ref{eq:inverse_identities}) from Theorem \ref{thm:unitary_time_change}.
\end{proof}

\subsection{$L^2_{\mathrm{loc}}$ Identity on Finite Intervals}

\begin{lemma}
\label{lem:finite_interval_identity}
(Finite-interval $L^2$ identity) For every $T > 0$:
\begin{equation}
\label{eq:finite_L2_identity}
\int_{\Theta(0)}^{\Theta(T)} |X(u)|^2 \, du = \int_0^T |Z(t)|^2 \, dt
\end{equation}
\end{lemma}

\begin{proof}
With $u = \Theta(t)$, $du = \dot{\Theta}(t) \, dt$, and $X(u) = \frac{Z(t)}{\sqrt{\dot{\Theta}(t)}}$:
\[ \int_{\Theta(0)}^{\Theta(T)} |X(u)|^2 \, du = \int_0^T \left|\frac{Z(t)}{\sqrt{\dot{\Theta}(t)}}\right|^2 \dot{\Theta}(t) \, dt = \int_0^T |Z(t)|^2 \, dt \]
\end{proof}

\begin{theorem}
\label{thm:X_in_L2loc}
($X \in L^2_{\mathrm{loc}}([\Theta(0), \infty))$) 
\begin{equation}
\label{eq:X_L2loc}
X \in L^2_{\mathrm{loc}}([\Theta(0), \infty))
\end{equation}
\end{theorem}

\begin{proof}
For compact $[c, d] \subset [\Theta(0), \infty)$, the preimage $[\Theta^{-1}(c), \Theta^{-1}(d)]$ is compact in $[0, \infty)$. The Hardy Z-function is continuous on compact sets, so $\int_{\Theta^{-1}(c)}^{\Theta^{-1}(d)} |Z(t)|^2 \, dt < \infty$. By Lemma \ref{lem:finite_interval_identity}, $\int_c^d |X(u)|^2 \, du$ equals this finite integral.
\end{proof}

\subsection{Limit-form Mean-Square Statements}

\begin{theorem}
\label{thm:hardy_littlewood}
(Hardy-Littlewood second moment)
\begin{equation}
\label{eq:HL_zeta}
\lim_{T \to \infty} \frac{\int_0^T |\zeta(1/2 + it)|^2 \, dt}{T\log T} = 1
\end{equation}
Equivalently:
\begin{equation}
\label{eq:HL_Z}
\lim_{T \to \infty} \frac{\int_0^T |Z(t)|^2 \, dt}{T\log T} = 1
\end{equation}
\end{theorem}

\begin{theorem}
\label{thm:Theta_limit}
(Ratio limit for $\Theta$)
\begin{equation}
\label{eq:Theta_asymptotic}
\lim_{T \to \infty} \frac{\Theta(T)}{(T/2)\log T} = 1
\end{equation}
\end{theorem}

\begin{theorem}
\label{thm:X_mean_square}
(Mean-square limit for $X$)
\begin{equation}
\label{eq:X_mean_square_limit}
\lim_{T \to \infty} \frac{1}{\Theta(T) - \Theta(0)} \int_{\Theta(0)}^{\Theta(T)} |X(u)|^2 \, du = 2
\end{equation}
\end{theorem}

\begin{proof}
By Lemma \ref{lem:finite_interval_identity}:
\begin{equation}
\label{eq:X_mean_square_step1}
\frac{\int_{\Theta(0)}^{\Theta(T)} |X(u)|^2 \, du}{\Theta(T) - \Theta(0)} = \frac{\int_0^T |Z(t)|^2 \, dt}{\Theta(T) - \Theta(0)}
\end{equation}
Writing:
\begin{equation}
\label{eq:X_mean_square_step2}
\frac{\int_0^T |Z(t)|^2 \, dt}{\Theta(T) - \Theta(0)} = \left(\frac{\int_0^T |Z(t)|^2 \, dt}{T\log T}\right) \left(\frac{T\log T}{\Theta(T) - \Theta(0)}\right)
\end{equation}
the first factor $\to 1$ by (\ref{eq:HL_Z}) and the second factor $\to 2$ by (\ref{eq:Theta_asymptotic}).
\end{proof}

\subsection{Time-Average Covariance Conjectures}

\begin{definition}
\label{def:empirical_covariance}
(Empirical covariance kernel) For $U > \Theta(0)$ and $\tau \in \mathbb{R}$ define:
\begin{equation}
\label{eq:K_U}
K_U(\tau) \defeq \frac{1}{U - \Theta(0)} \int_{\Theta(0)}^U X(u) X(u + \tau) \, du
\end{equation}
\end{definition}

\begin{conjecture}
\label{conj:stationary_covariance}
(Existence of a stationary covariance kernel) For each fixed $\tau \in \mathbb{R}$, the limit:
\begin{equation}
\label{eq:K_limit}
K(\tau) \defeq \lim_{U \to \infty} K_U(\tau)
\end{equation}
exists in $\mathbb{R}$.
\end{conjecture}

\begin{conjecture}
\label{conj:ergodic_realization}
(Ergodic stationary realization) There exists a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ and a stationary ergodic process $\{X_{\mathrm{st}}(u, \omega)\}_{u \in \mathbb{R}}$ such that for some $\omega_0 \in \Omega$:
\begin{equation}
\label{eq:X_st_match}
X_{\mathrm{st}}(u, \omega_0) = X(u) \quad \forall u \geq \Theta(0)
\end{equation}
and for every fixed $\tau \in \mathbb{R}$:
\begin{equation}
\label{eq:ergodic_covariance}
\mathbb{E}[X_{\mathrm{st}}(0, \omega) X_{\mathrm{st}}(\tau, \omega)] = \lim_{U \to \infty} \frac{\int_{\Theta(0)}^U X(u) X(u + \tau) \, du}{U - \Theta(0)}
\end{equation}
\end{conjecture}

\begin{thebibliography}{99}
\bibitem{cramerLeadbetter1967}
Harald Cramér and M. R. Leadbetter. Stationary and Related Processes: Sample Function Properties and Their Applications. Wiley, 1967.

\bibitem{mandrekar1972}
V. Mandrekar. A characterization of oscillatory processes and their prediction. Proc. Amer. Math. Soc., 32(1):280--284, 1972.

\bibitem{priestley1965}
Maurice B. Priestley. Evolutionary spectra and non-stationary processes. J. R. Stat. Soc. B, 27(2):204--229, 1965.

\bibitem{priestley1981}
Maurice B. Priestley. Spectral Analysis and Time Series. Academic Press, 1981.

\bibitem{bulinskaya1961}
E. V. Bulinskaya. On the mean number of crossings of a level by a stationary Gaussian process. Theory Probab. Appl., 6(4):435--438, 1961.
\end{thebibliography}

\end{document}
