\documentclass{article}
\usepackage[english]{babel}
\usepackage{geometry,amsmath,amssymb,latexsym,theorem}
\geometry{letterpaper}

%%%%%%%%%% Start TeXmacs macros
\newcommand{\assign}{:=}
\newcommand{\mathd}{\mathrm{d}}
\newcommand{\textdots}{...}
\newcommand{\tmem}[1]{{\em #1\/}}
\newcommand{\tmop}[1]{\ensuremath{\operatorname{#1}}}
\newcommand{\tmstrong}[1]{\textbf{#1}}
\newcommand{\tmtextbf}[1]{\text{{\bfseries{#1}}}}
\newcommand{\tmtextit}[1]{\text{{\itshape{#1}}}}
\newenvironment{proof}{\noindent\textbf{Proof\ }}{\hspace*{\fill}$\Box$\medskip}
\newtheorem{corollary}{Corollary}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}
{\theorembodyfont{\rmfamily}\newtheorem{remark}{Remark}}
\newtheorem{theorem}{Theorem}
%%%%%%%%%% End TeXmacs macros

\begin{document}

\title{
  Unitary Time Changes of Stationary Processes Yield Oscillatory Processes\\
  
}

\author{Stephen Crowley}

\date{September 16, 2025}

\maketitle

\begin{abstract}
  A unitary time-change operator $U_{\theta}$ is constructed for absolutely
  continuous, strictly increasing time reparametrizations $\theta$, acting on
  functions that are square-integrable over compact sets. Applying
  $U_{\theta}$ to the Cram{\'e}r spectral representation of a stationary
  process yields an oscillatory process in the sense of Priestley with
  oscillatory function $\varphi_t (\lambda) = \sqrt{\dot{\theta} (t)} 
  \hspace{0.17em} e^{i \lambda \theta (t)}$ and evolutionary spectrum $dF_t
  (\lambda) = \dot{\theta} (t) dF (\lambda)$. It is proved that sample paths
  of any non-degenerate second-order stationary process almost surely lie in
  $L^2_{\tmop{loc}} (\mathbb{R})$, making the operator applicable to typical
  realizations. A zero-localization measure $\mathd \mu (t) = \delta (Z (t))
  \hspace{0.17em} | \dot{Z} (t) |  \hspace{0.17em} dt$ induces a Hilbert space
  $L^2 (\mu)$ on the zero set of an oscillatory process $Z$, and the
  multiplication operator $(Lf) (t) = tf (t)$ has simple pure point spectrum
  equal to the zero crossing set of $Z$. This produces a concrete operator
  scaffold consistent with a Hilbert--P{\'o}lya-type viewpoint.
\end{abstract}

{\tableofcontents}

\section{Function Spaces}\label{sec:functionspaces}

\subsection{$\sigma$-compact sets and locally square-integrable functions}

\begin{definition}
  {\tmstrong{[$\sigma$-compact sets]\label{def:sigma_compact}}} A subset $U
  \subseteq \mathbb{R}$ is $\sigma$-compact if
  \begin{equation}
    U = \bigcup_{n = 1}^{\infty} K_n
  \end{equation}
  with each $K_n$ compact.
\end{definition}

\begin{definition}
  {\tmstrong{[Locally square-integrable functions]}}\label{def:L2loc} Define
  \begin{equation}
    L^2_{\tmop{loc}} (\mathbb{R}) \assign \left\{ f : \mathbb{R} \to
    \mathbb{C}: \int_K |f (t) |^2  \hspace{0.17em} dt < \infty \text{for every
    compact } K \subseteq \mathbb{R} \right\}
  \end{equation}
\end{definition}

\begin{remark}
  Every bounded measurable set in $\mathbb{R}$ is compact or contained in a
  compact set; hence $L^2_{\tmop{loc}} (\mathbb{R})$ contains functions that
  are square-integrable on every bounded interval, including functions with
  polynomial growth at infinity.
\end{remark}

\section{Gaussian Processes}

A Gaussian process is a {\textdots}

\subsection{Stationary processes}

\begin{definition}
  {\tmstrong{[Cram{\'e}r representation]\label{def:cramer}}} A zero-mean
  stationary process $X$ with spectral measure $F$ admits the sample path
  representation
  \begin{equation}
    X (t) = \int_{\mathbb{R}} e^{i \lambda t}  \hspace{0.17em} \Phi (d
    \lambda)
  \end{equation}
  which has covariance
  \begin{equation}
    R_X  (t - s) = \int_{\mathbb{R}} e^{i \lambda (t - s)}  \hspace{0.17em} dF
    (\lambda)
  \end{equation}
\end{definition}

\subsection{Oscillatory Processes}\label{sec:oscillatory}

A particularly tractable class of non-stationary Gaussian processes is that of
the oscillatory processes as defined by M.B. Priestley in
1965{\cite{evolutionarySpectraAndNonStationaryProcesses}}.

\begin{definition}
  {\tmstrong{[Oscillatory process]\label{def:osc_proc} }}link to Priestley
  1965 Let $F$ be a finite nonnegative Borel measure on $\mathbb{R}$. Let
  \begin{equation}
    A_t \in L^2 (F) \forall t \in \mathbb{R}
  \end{equation}
  be the gain function and
  \begin{equation}
    \varphi_t (\lambda) = A_t (\lambda) e^{i \lambda t} \label{of}
  \end{equation}
  be the corresponding oscillatory function then an {\tmem{oscillatory
  process}} is a stochastic process which can be represented as
  \begin{equation}
    \begin{array}{ll}
      Z (t) & = \int_{\mathbb{R}} \varphi_t (\lambda) \mathd \Phi (\lambda)\\
      & = \int_{\mathbb{R}} A_t (\lambda) e^{i \lambda t} \mathd \Phi
      (\lambda)
    \end{array}
  \end{equation}
  where $\Phi$ is a complex orthogonal random measure with spectral measure
  $F$ which satisfies the relation
  \begin{equation}
    \mathd \mathbb{E} \hspace{-0.17em} [\Phi (\lambda) \overline{\Phi (\mu)}]
    = \delta (\lambda - \mu)  \hspace{0.17em} dF (\lambda)
  \end{equation}
  and has the corresponding covariance kernel
  \begin{equation}
    \begin{array}{ll}
      R_Z (t, s) & =\mathbb{E} \hspace{-0.17em} [Z (t) \overline{Z (s)}]\\
      & = \int_{\mathbb{R}} A_t (\lambda) \hspace{0.17em} \overline{A_s
      (\lambda)} \hspace{0.17em} e^{i \lambda (t - s)}  \hspace{0.17em} dF
      (\lambda)\\
      & = \int_{\mathbb{R}} \phi_t (\lambda) \overline{\phi_s (\lambda)}
      \mathd F (\lambda)
    \end{array} \label{covar}
  \end{equation}
\end{definition}

\begin{theorem}
  {\tmstrong{[Real-valuedness criterion for oscillatory
  processes]\label{thm:realvaluedness}}}Let $Z$ be an oscillatory process with
  oscillatory function
  \begin{equation}
    \varphi_t (\lambda) = A_t (\lambda) e^{i \lambda t}
  \end{equation}
  and spectral measure $F$. Then $Z$ is real-valued if and only if
  \begin{equation}
    A_t  (- \lambda) = \overline{A_t (\lambda)}
  \end{equation}
  for $F$-almost every $\lambda \in \mathbb{R}$, equivalently
  \begin{equation}
    \varphi_t  (- \lambda) = \overline{\varphi_t (\lambda)}
  \end{equation}
  for $F$-almost every $\lambda \in \mathbb{R}$.
\end{theorem}

\begin{proof}
  Assume $Z$ is real-valued, i.e.
  \begin{equation}
    Z (t) = \overline{Z (t)} \quad \forall t \in \mathbb{R}
  \end{equation}
  Writing its oscillatory representation,
  \begin{equation}
    Z (t) = \int_{\mathbb{R}} A_t (\lambda) e^{i \lambda t} \mathd \Phi
    (\lambda)
  \end{equation}
  and taking the complex conjugate gives
  \begin{equation}
    \overline{Z (t)} = \int_{\mathbb{R}} \overline{A_t (\lambda)} e^{- i
    \lambda t} \mathd \overline{\Phi (\lambda)}
  \end{equation}
  For a real-valued process, the orthogonal random measure $\Phi$ must satisfy
  \begin{equation}
    \mathd \overline{\Phi (\lambda)} = - \mathd \Phi (\lambda)
  \end{equation}
  which ensures that the spectral representation produces real values.
  Substituting this identity and using the substitution
  \begin{equation}
    \mu = - \lambda
  \end{equation}
  it is shown that
  \begin{equation}
    \overline{Z (t)} = \int_{\mathbb{R}} \overline{A_t  (- \mu)} e^{i \mu t}
    \mathd \Phi (\mu)
  \end{equation}
  Since $Z (t) = \overline{Z (t)}$, comparison of the integrands (which are
  unique elements of $L^2 (F)$) yields
  \begin{equation}
    A_t (\lambda) = \overline{A_t  (- \lambda)} \quad \text{for } F
    \text{-a.e. } \lambda
  \end{equation}
  Equivalently, because the oscillatory function (\ref{of}) is given by
  \begin{equation}
    \varphi_t (\lambda) = A_t (\lambda) e^{i \lambda t}
  \end{equation}
  we have
  \begin{equation}
    \varphi_t  (- \lambda) = \overline{\varphi_t (\lambda)} \quad \text{for }
    F \text{-a.e. } \lambda
  \end{equation}
  Conversely, if
  \begin{equation}
    A_t  (- \lambda) = \overline{A_t (\lambda)}
  \end{equation}
  for $F$-a.e. $\lambda$, then the same substitution shows that
  \begin{equation}
    \overline{Z (t)} = Z (t) \quad \forall t \in \mathbb{R}
  \end{equation}
  so $Z$ is real-valued. This completes the proof.
\end{proof}

\begin{theorem}
  {\tmstrong{[Existence]}}\label{thm:existence_osc} Let $F$ be an absolutely
  continuous spectral measure and the gain function
  \begin{equation}
    A_t (\lambda) \in L^2 (F) \forall \mathbb{R} \ni t < \infty
  \end{equation}
  be measurable in both time and frequency then the time-dependent spectral
  density is defined by
  \begin{equation}
    \begin{array}{ll}
      S_t (\lambda) & = \int_{\mathbb{R}} |A_t (\lambda) |^2  \hspace{0.17em}
      dF (\lambda) < \infty\\
      & = \int_{\mathbb{R}} |A_t (\lambda) |^2 S (\lambda) d \lambda
    \end{array}
  \end{equation}
  and there exists a complex orthogonal random measure $\Phi$ with spectral
  measure $F$ such that for each sample path $\varpi \in \Theta$ in the space
  of sample paths having given covariance constituting the ensemble denoted
  $\Theta$
  \begin{equation}
    Z (t) = \int_{\mathbb{R}} A_t (\lambda) e^{i \lambda t} \mathd \Phi
    (\lambda)
  \end{equation}
  is well-defined in $L^2 (\Omega)$ and has covariance $R_Z$ as in
  (\ref{covar}) above.
\end{theorem}

\begin{proof}
  The proof proceeds by constructing the stochastic integral using the
  standard extension procedure. First, the integral is defined for simple
  functions of the form
  \begin{equation}
    g (\lambda) = \lim_{n \rightarrow \infty} \sum_{j = 1}^n c_j
    \text{\tmtextbf{1}}_{E_j} (\lambda)
  \end{equation}
  where $\{E_j \}$ are disjoint Borel sets with $F (E_j) < \infty$ and $c_j
  \in \mathbb{C}$:
  \begin{equation}
    \int_{\mathbb{R}} g (\lambda) \mathd \Phi (\lambda) = \lim_{n \rightarrow
    \infty} \sum_{j = 1}^n c_j \Phi (E_j)
  \end{equation}
  For simple functions such as this, the isometry property holds:
  \begin{equation}
    \begin{array}{ll}
      \mathbb{E} \left[ \left| \int_{\mathbb{R}} g (\lambda) \hspace{0.17em}
      \Phi \mathd (\lambda) \right|^2 \right] & =\mathbb{E} \left[ \lim_{n
      \rightarrow \infty} \left| \sum_{j = 1}^n c_j \Phi (E_j) \right|^2
      \right]\\
      & = \lim_{n \rightarrow \infty} \sum_{j = 1}^n \sum_{k = 1}^n c_j
      \overline{c_k} \mathbb{E} [\Phi (E_j) \overline{\Phi (E_k)}]\\
      & = \lim_{n \rightarrow \infty} \sum_{j = 1}^n |c_j |^2 F (E_j)\\
      & = \int_{\mathbb{R}} |g (\lambda) |^2  \hspace{0.17em} dF (\lambda)
    \end{array}
  \end{equation}
  Since simple functions are dense in $L^2 (F)$, the integral is extended by
  continuity {\forall}$g \in L^2 (F)$ since the oscillatory function
  (\ref{of}) is defined by
  \begin{equation}
    \varphi_t (\lambda) = A_t (\lambda) e^{i \lambda t} \in L^2 (F) \forall t
    \in \mathbb{R}
  \end{equation}
  and $A_t \in$. Therefore
  \begin{equation}
    Z (t) = \int_{\mathbb{R}} \varphi_t (\lambda) \mathd \Phi (\lambda)
  \end{equation}
  is well-defined in $L^2 (\Omega)$. The covariance is computed as:
  \begin{equation}
    \begin{array}{ll}
      R_Z (t, s) & =\mathbb{E} [Z (t) \overline{Z (s)}]\\
      & =\mathbb{E} \left[ \int_{\mathbb{R}} \varphi_t (\lambda) \mathd \Phi
      (\lambda) \int_{\mathbb{R}} \overline{\varphi_s (\mu)} \mathd
      \overline{\Phi (\mu)} \right]\\
      & = \int_{\mathbb{R}} \int_{\mathbb{R}} \varphi_t (\lambda)
      \overline{\varphi_s (\mu)} \mathd \mathbb{E} [\Phi (\lambda)
      \overline{\Phi (\mu)}]\\
      & = \int_{\mathbb{R}} \varphi_t (\lambda) \overline{\varphi_s
      (\lambda)} \hspace{0.17em} dF (\lambda)\\
      & = \int_{\mathbb{R}} A_t (\lambda) \overline{A_s (\lambda)} e^{i
      \lambda (t - s)}  \hspace{0.17em} dF (\lambda)
    \end{array}
  \end{equation}
\end{proof}

\section{Unitarily Time-Changed Stationary
Processes}\label{sec:stationary_timechange}

\subsection{Unitary time-change operator}

\begin{definition}
  {\tmstrong{[Unitary time-change]\label{def:Utheta}}} Let the time-scaling
  function $\theta : \mathbb{R} \to \mathbb{R}$ be absolutely continuous,
  strictly increasing, and bijective, with $\dot{\theta} (t) > 0$ almost
  everywhere and $\dot{\theta} (t) = 0$ only on sets of Lebesgue measure zero.
  The function $\theta$ maps $\sigma$-compact sets to $\sigma$-compact sets.
  Define, for $f$ measurable,
  \begin{equation}
    (U_{\theta} f) (t) = \sqrt{\dot{\theta} (t)} f (\theta (t)) \label{U}
  \end{equation}
\end{definition}

\begin{proposition}
  {\tmstrong{[Inversion of Unitary time-change]\label{prop:inverse} }}The
  inverse of the unitary time-change operator $U$ in Equation (\ref{U}) is
  given by
  \begin{equation}
    (U_{\theta}^{- 1} g) (s) = \frac{g (\theta^{- 1} (s))}{\sqrt{\dot{\theta}
    (\theta^{- 1} (s))}}
  \end{equation}
  which is well-defined almost everywhere on every $\sigma$-compact set.
\end{proposition}

\begin{proof}
  Since $\dot{\theta} (t) = 0$ only on sets of measure zero, and $\theta^{-
  1}$ maps sets of measure zero to sets of measure zero because of the fact
  that absolutely continuous bijective functions preserve measure-zero sets,
  the denominator $\sqrt{\dot{\theta} (\theta^{- 1} (s))}$ is positive almost
  everywhere. The expression is therefore well-defined almost everywhere on
  every $\sigma$-compact set, which suffices for defining an element of
  $L^2_{\tmop{loc}} (\mathbb{R})$.
\end{proof}

\begin{theorem}
  {\tmstrong{[Local unitarity on $\sigma$-compact
  sets]\label{thm:local_unitarity}}} For every $\sigma$-compact set $C
  \subseteq \mathbb{R}$ and $f \in L^2_{\tmop{loc}} (\mathbb{R})$,
  \begin{equation}
    \int_C | (U_{\theta} f) (t) |^2 \hspace{0.17em} dt = \int_{\theta (C)} |f
    (s) |^2  \hspace{0.17em} ds
  \end{equation}
  Moreover, $U_{\theta}^{- 1}$ is the inverse of $U_{\theta}$ on
  $L^2_{\tmop{loc}} (\mathbb{R})$.
\end{theorem}

\begin{proof}
  Let $f \in L^2_{\tmop{loc}} (\mathbb{R})$ and let $C$ be any
  $\sigma$-compact set. The local $L^2$-norm of $U_{\theta} f$ over $C$ is:
  \begin{equation}
    \begin{array}{ll}
      \int_C | (U_{\theta} f) (t) |^2  \hspace{0.17em} dt & = \int_C \left|
      \sqrt{\dot{\theta} (t)} f (\theta (t)) \right|^2  \hspace{0.17em} dt\\
      & = \int_C \dot{\theta} (t) |f (\theta (t)) |^2  \hspace{0.17em} dt
    \end{array}
  \end{equation}
  Since $\theta$ is absolutely continuous and strictly increasing, applying
  the change of variables $s = \theta (t)$ gives
  \begin{equation}
    ds = \dot{\theta} (t) dt
  \end{equation}
  almost everywhere. Since $\theta$ maps $\sigma$-compact sets to
  $\sigma$-compact sets, as $t$ ranges over $C$, $s = \theta (t)$ ranges over
  $\theta (C)$, which is $\sigma$-compact. Therefore:
  \begin{equation}
    \int_C \dot{\theta} (t)  |f (\theta (t)) |^2 \hspace{0.17em} dt =
    \int_{\theta (C)} |f (s) |^2  \hspace{0.17em} ds
  \end{equation}
  To verify that $U_{\theta}^{- 1}$ is indeed the inverse, it is seen that:
  \begin{equation}
    \begin{array}{llcccc}
      (U_{\theta}^{- 1} U_{\theta} f) (s) & = \left( U_{\theta}^{- 1} 
      \sqrt{\dot{\theta} (s)} f (\theta (s)) \right) (s) &  &  &  & \\
      & = \frac{\sqrt{\dot{\theta} (\theta^{- 1} (s))}}{\sqrt{\dot{\theta}
      (\theta^{- 1} (s))}} f (\theta (\theta^{- 1} (s))) &  &  &  & \forall f
      \in L^2_{\tmop{loc}} (\mathbb{R})\\
      & = f (s) &  &  &  & 
    \end{array}
  \end{equation}
  since
  \begin{equation}
    \theta (\theta^{- 1} (s)) = s
  \end{equation}
  and similarly, its also plain to see that:
  \begin{equation}
    \begin{array}{llcccc}
      (U_{\theta} U_{\theta}^{- 1} g) (t) & = \sqrt{\dot{\theta} (t)} 
      (U_{\theta}^{- 1} g) (\theta (t)) &  &  &  & \\
      & = \frac{\sqrt{\dot{\theta} (t)}}{\sqrt{\dot{\theta} (\theta^{- 1}
      (\theta (t)))}} g (\theta^{- 1} (\theta (t))) &  &  &  & \forall g \in
      L^2_{\tmop{loc}} (\mathbb{R})\\
      & = \frac{\sqrt{\dot{\theta} (t)}}{\sqrt{\dot{\theta} (t)}} g (t) &  & 
      &  & \\
      & = g (t) &  &  &  & 
    \end{array}
  \end{equation}
  since
  \begin{equation}
    \theta^{- 1} (\theta (t)) = t
  \end{equation}
  Therefore
  \begin{equation}
    \begin{array}{ll}
      (U_{\theta} U_{\theta}^{- 1} f) (t) & = (U_{\theta}^{- 1} U_{\theta} f)
      (t)\\
      & = f (t)
    \end{array}
  \end{equation}
  on $L^2_{\tmop{loc}} (\mathbb{R})$.
\end{proof}

\subsection{Transformation of Stationary $\to$ Oscillatory Processes via
$U_{\theta}$}

\begin{theorem}
  {\tmstrong{[Unitary time change yields oscillatory
  process]\label{thm:Utheta_to_osc}}} Let $X$ be zero-mean stationary as in
  Definition~\ref{def:cramer}. For scaling function $\theta$ as in
  Definition~\ref{def:Utheta}, define
  \begin{equation}
    \begin{array}{ll}
      Z (t) & = (U_{\theta} X) (t)\\
      & = \sqrt{\dot{\theta} (t)}  \hspace{0.17em} X (\theta (t))
    \end{array}
  \end{equation}
  Then $Z$ is a realization of an oscillatory process with oscillatory
  function
  \begin{equation}
    \varphi_t (\lambda) = \sqrt{\dot{\theta} (t)}  \hspace{0.17em} e^{i
    \lambda \theta (t)}
  \end{equation}
  gain function
  \begin{equation}
    A_t (\lambda) = \sqrt{\dot{\theta} (t)}  \hspace{0.17em} e^{i \lambda
    (\theta (t) - t)}
  \end{equation}
  and covariance
  \begin{equation}
    \begin{array}{ll}
      R_Z (t, s) & =\mathbb{E} [Z (t) \overline{Z (s)}]\\
      & =\mathbb{E} \left[ \sqrt{\dot{\theta} (t)} X (\theta (t))
      \overline{\sqrt{\dot{\theta} (t)} X (\theta (t))} \right]\\
      & = \sqrt{\dot{\theta} (t)  \dot{\theta} (s)} \mathbb{E} [X (\theta
      (t)) \overline{X (\theta (s))}]\\
      & = \sqrt{\dot{\theta} (t)  \dot{\theta} (s)} R_X  (\theta (t) - \theta
      (s))\\
      & = \sqrt{\dot{\theta} (t)  \dot{\theta} (s)}  \int_{\mathbb{R}} e^{i
      \lambda (\theta (t) - \theta (s))}  \hspace{0.17em} dF (\lambda)
    \end{array} \label{covar}
  \end{equation}
\end{theorem}

\begin{proof}
  Applying the unitary time change operator to the spectral representation of
  $X (t)$:
  \begin{equation}
    \begin{array}{ll}
      Z (t) & = (U_{\theta} X) (t)\\
      & = \sqrt{\dot{\theta} (t)}  \hspace{0.17em} X (\theta (t))\\
      & = \sqrt{\dot{\theta} (t)}  \int_{\mathbb{R}} e^{i \lambda \theta (t)}
      \hspace{0.17em} \mathd \Phi (\lambda)\\
      & = \int_{\mathbb{R}} \sqrt{\dot{\theta} (t)} e^{i \lambda \theta (t)}
      \mathd \Phi (\lambda)\\
      & = \int_{\mathbb{R}} \varphi_t (\lambda) \mathd \Phi (\lambda)
    \end{array}
  \end{equation}
  where
  \begin{equation}
    \varphi_t (\lambda) = \sqrt{\dot{\theta} (t)} e^{i \lambda \theta (t)}
  \end{equation}
  To verify this constitutes an oscillatory representation according to
  Definition~\ref{def:osc_proc}, $\varphi_t (\lambda)$ has the form $A_t
  (\lambda) e^{i \lambda t}$:
  \begin{equation}
    \begin{array}{ll}
      \varphi_t (\lambda) & = \sqrt{\dot{\theta} (t)} e^{i \lambda \theta
      (t)}\\
      & = \sqrt{\dot{\theta} (t)} e^{i \lambda (\theta (t) - t)} e^{i \lambda
      t}\\
      & = A_t (\lambda) e^{i \lambda t}
    \end{array}
  \end{equation}
  where
  \begin{equation}
    A_t (\lambda) = \sqrt{\dot{\theta} (t)} e^{i \lambda (\theta (t) - t)}
  \end{equation}
  Since $\dot{\theta} (t) \geq 0$ almost everywhere and $\dot{\theta} (t) = 0$
  only on sets of measure zero, $A_t (\lambda)$ is well defined almost
  everywhere. Moreover, $A_t \in L^2 (F)$ for each $t$ since:
  \begin{equation}
    \begin{array}{ll}
      \int_{\mathbb{R}} |A_t (\lambda) |^2  \hspace{0.17em} dF (\lambda) & =
      \int_{\mathbb{R}} \left| \sqrt{\dot{\theta} (t)} e^{i \lambda (\theta
      (t) - t)} \right|^2  \hspace{0.17em} dF (\lambda)\\
      & = \int_{\mathbb{R}} \dot{\theta} (t) |e^{i \lambda (\theta (t) - t)}
      |^2  \hspace{0.17em} dF (\lambda)\\
      & = \dot{\theta} (t)  \int_{\mathbb{R}} dF (\lambda)\\
      & = \dot{\theta} (t) F (\mathbb{R}) < \infty
    \end{array}
  \end{equation}
  where $|e^{i \alpha} | = 1$ for all real $\alpha$ is used. The covariance
  (\ref{covar}) is computed by substituting the spectral representation and
  applying Fubuni's theorem to interchange the order of operations.
  \begin{equation}
    \begin{array}{cc}
      & 
    \end{array}
  \end{equation}
\end{proof}

\begin{corollary}
  {\tmstrong{[Evolutionary spectrum of unitarily time-changed stationary
  process]\label{cor:evol_spec}}}{\cite{evolutionarySpectraAndNonStationaryProcesses}}
  Link to The evolutionary spectrum, also called the time-varying spectral
  density, is
  \begin{equation}
    \begin{array}{ll}
      dF_t (\lambda) & = |A_t (\lambda) |^2  \hspace{0.17em} dF (\lambda)\\
      & = \dot{\theta} (t) dF (\lambda)
    \end{array}
  \end{equation}
\end{corollary}

\begin{proof}
  By definition of the evolutionary spectrum and using the gain function from
  Theorem~\ref{thm:Utheta_to_osc}:
  \begin{equation}
    \begin{array}{ll}
      dF_t (\lambda) & = |A_t (\lambda) |^2  \hspace{0.17em} dF (\lambda)\\
      & = \left| \sqrt{\dot{\theta} (t)} e^{i \lambda (\theta (t) - t)}
      \right|^2  \hspace{0.17em} dF (\lambda)\\
      & = \dot{\theta} (t) |e^{i \lambda (\theta (t) - t)} |^2 
      \hspace{0.17em} dF (\lambda)\\
      & = \dot{\theta} (t)  \hspace{0.17em} dF (\lambda)
    \end{array}
  \end{equation}
  since
  \begin{equation}
    |e^{i \alpha} | = 1 \forall a \in \mathbb{R}
  \end{equation}
\end{proof}

\subsection{Covariance operator conjugation}

\begin{proposition}
  {\tmstrong{[Operator conjugation]\label{prop:conjugation}}} Let
  \begin{equation}
    (T_K f) (t) \assign \int_{\mathbb{R}} K (|t - s|) f (s) ds
  \end{equation}
  with stationary kernel
  \begin{equation}
    K (h) = \int_{\mathbb{R}} e^{i \lambda h} dF (\lambda)
  \end{equation}
  Define the transformed kernel
  \begin{equation}
    K_{\theta} (s, t) \assign \sqrt{\dot{\theta} (t)  \dot{\theta} (s)} 
    \hspace{0.17em} K \hspace{-0.17em} (| \theta (t) - \theta (s) |)
  \end{equation}
  then the corresponding integral covariance operator is conjugated $\forall f
  \in L^2_{\tmop{loc}} (\mathbb{R})$ by
  \begin{equation}
    \begin{array}{ll}
      (T_{K_{\theta}} f) (t) & = \int_{\mathbb{R}} K_{\theta} (s, t) f (s)
      \hspace{0.17em} ds\\
      & = \left( U_{\theta}  \hspace{0.17em} T_K  \hspace{0.17em}
      U_{\theta}^{- 1} f \right) (t)
    \end{array}
  \end{equation}
\end{proposition}

\begin{proof}
  For any $g \in L^2_{\tmop{loc}} (\mathbb{R})$, compute:
  \begin{equation}
    \begin{array}{ll}
      ((U_{\theta} T_K U_{\theta}^{- 1}) g) (t) & = (U_{\theta} (T_K
      U_{\theta}^{- 1} g)) (t)\\
      & = \sqrt{\dot{\theta} (t)}  (T_K U_{\theta}^{- 1} g) (\theta (t))\\
      & = \sqrt{\dot{\theta} (t)}  \int_{\mathbb{R}} K (| \theta (t) - \theta
      (s) |)  (U_{\theta}^{- 1} g) (\theta (s)) \dot{\theta} (s) d s\\
      & = \sqrt{\dot{\theta} (t)}  \int_{\mathbb{R}} K (| \theta (t) - \theta
      (s) |) \frac{g (s)}{\sqrt{\dot{\theta} (s)}}  \dot{\theta} (s) 
      \hspace{0.17em} ds\\
      & = \sqrt{\dot{\theta} (t)}  \int_{\mathbb{R}} K (| \theta (t) - \theta
      (s) |) g (s) \sqrt{\dot{\theta} (s)}  \hspace{0.17em} ds\\
      & = \int_{\mathbb{R}} \sqrt{\dot{\theta} (t) \dot{\theta} (s)} K (|
      \theta (t) - \theta (s) |) g (s)  \hspace{0.17em} ds\\
      & = \int_{\mathbb{R}} K_{\theta} (t, s) g (s)  \hspace{0.17em} ds\\
      & = (T_{K_{\theta}} g) (t)
    \end{array}
  \end{equation}
\end{proof}

\section{The Ensemble of Sample Path Realizations}\label{sec:samplepaths}

Question: is this called local integrability? state this more eloquently

\begin{theorem}
  {\tmstrong{[Sample paths in $L^2_{\tmop{loc}}
  (\mathbb{R})$]\label{thm:paths_loc}}} Let $\{X (t)\}_{t \in \mathbb{R}}$ be
  a second-order stationary process with
  \begin{equation}
    \sigma^2 \assign \mathbb{E} [X (t)^2] < \infty
  \end{equation}
  then, almost surely, every sample path $t \mapsto X (\omega, t) \in
  L^2_{\tmop{loc}} (\mathbb{R})$.
\end{theorem}

\begin{proof}
  Fix any bounded interval $[a, b]$ and consider the random variable
  \begin{equation}
    Y_{[a, b]} \assign \int_a^b X (t)^2  \hspace{0.17em} dt
  \end{equation}
  By stationarity and Fubini's theorem:
  \begin{equation}
    \begin{array}{ll}
      \mathbb{E} [Y_{[a, b]}] =\mathbb{E} \left[ \int_a^b X (t)^2 
      \hspace{0.17em} dt \right] & = \int_a^b \mathbb{E} [X (t)^2] 
      \hspace{0.17em} dt\\
      & = \int_a^b \sigma^2  \hspace{0.17em} dt\\
      & = \sigma^2  (b - a) < \infty
    \end{array}
  \end{equation}
  By Markov's inequality, for any $M > 0$:
  \begin{equation}
    P (Y_{[a, b]} > M) \leq \frac{\mathbb{E} [Y_{[a, b]}]}{M} = \frac{\sigma^2
    (b - a)}{M}
  \end{equation}
  Taking $M \to \infty$, the conclusion is
  \begin{equation}
    P (Y_{[a, b]} < \infty) = 1
  \end{equation}
  i.e., almost surely the sample path is square-integrable on $[a, b]$. Since
  $\mathbb{R}$ is the countable union of bounded intervals:
  \begin{equation}
    \mathbb{R}= \bigcup_{n = 1}^{\infty} [- n, n]
  \end{equation}
  by countable subadditivity of probability:
  \begin{equation}
    P \left( \bigcap_{n = 1}^{\infty} \left\{ \int_{- n}^n X (t)^2 
    \hspace{0.17em} dt < \infty \right\} \right) = 1
  \end{equation}
  Now let $K$ be any compact set. Then $K$ is bounded, so
  \begin{equation}
    K \subseteq [- N, N]
  \end{equation}
  for some $N$. Therefore:
  \begin{equation}
    \int_K X (t)^2  \hspace{0.17em} dt \leq \int_{- N}^N X (t)^2 
    \hspace{0.17em} dt < \infty
  \end{equation}
  almost surely. This holds for every compact set $K$, so almost surely every
  sample path lies in $L^2_{\tmop{loc}} (\mathbb{R})$.
\end{proof}

\section{Zero Localization}\label{sec:HP}

The construction
\begin{equation}
  \text{stationary } X \xrightarrow{U_{\theta}} \text{oscillatory } Z
  \xrightarrow{\mu = \delta (Z) | \dot{Z} |  \hspace{0.17em} dt} L^2 (\mu)
  \xrightarrow{L : t f (t)} (L, \sigma (L))
\end{equation}
produces a self-adjoint operator whose eigenvalues equal the zero set of the
realization sample path realization $Z (t)$ from the ensemble of possible
sample path functions having the given covariance structure \ and whose
spectrum equals the closure of the zero set, determined by the choice of
time-change $\theta (t)$, spectral measure $F (\lambda)$, and complex
orthogonal random measure $\Phi (\lambda)$ which uniquely corresponds to a
given sample path from the ensemble.

\subsection{Zero localization measure}

\begin{definition}
  {\tmstrong{[Zero localization measure]\label{def:zeromeasure}}} Let $Z$ be
  real-valued with $Z \in C^1 (\mathbb{R})$ having only simple zeros
  \begin{equation}
    Z (t_0) = 0 \Rightarrow \dot{Z} (t_0) \neq 0
  \end{equation}
  Define, for Borel $B \subset \mathbb{R}$,
  \begin{equation}
    \mu (B) = \int_{\mathbb{R}} \text{\tmtextbf{1}}_B (t)  \hspace{0.17em}
    \delta (Z (t)) \hspace{0.17em} | \dot{Z} (t) |  \hspace{0.17em} dt
  \end{equation}
\end{definition}

\begin{theorem}
  {\tmstrong{[Atomicity on the zero set]\label{thm:atomic}}} For every $\phi
  \in C_c^{\infty} (\mathbb{R})$,
  \begin{equation}
    \int_{\mathbb{R}} \phi (t)  \hspace{0.17em} \delta (Z (t)) \hspace{0.17em}
    | \dot{Z} (t) |  \hspace{0.17em} dt = \sum_{t_0 : Z (t_0) = 0} \phi (t_0)
  \end{equation}
  hence
  \begin{equation}
    \mu (t) = \sum_{t_0 : Z (t_0) = 0} \delta_{t_0} (t)
  \end{equation}
\end{theorem}

\begin{proof}
  Since all zeros of $Z$ are simple and $Z \in C^1 (\mathbb{R})$, by the
  inverse function theorem each zero $t_0$ is isolated. Near each zero $t_0$,
  $Z$ is locally monotonic, so the one-dimensional change of variables formula
  for the Dirac delta can be applied. Specifically, near $t_0$ where $Z (t_0)
  = 0$ and $\dot{Z} (t_0) \neq 0$, locally
  \begin{equation}
    Z (t) = (t - t_0)  \dot{Z} (t_0) + O ((t - t_0)^2)
  \end{equation}
  holds. The distributional identity for the Dirac delta under smooth changes
  of variables gives:
  \begin{equation}
    \delta (Z (t)) = \sum_{t_0 : Z (t_0) = 0} \frac{\delta (t - t_0)}{|
    \dot{Z} (t_0) |}
  \end{equation}
  Therefore:
  \begin{equation}
    \begin{array}{ll}
      \int_{\mathbb{R}} \phi (t)  \hspace{0.17em} \delta (Z (t))
      \hspace{0.17em} | \dot{Z} (t) |  \hspace{0.17em} dt & = \int_{-
      \infty}^{\infty} \phi (t) \hspace{0.17em} | \dot{Z} (t) |  \sum_{t_0 : Z
      (t_0) = 0} \frac{\delta (t - t_0)}{| \dot{Z} (t_0) |}  \hspace{0.17em}
      dt\\
      & = \sum_{t_0 : Z (t_0) = 0} \int_{\mathbb{R}} \phi (t) \frac{| \dot{Z}
      (t) | \delta (t - t_0)}{| \dot{Z} (t_0) |}  \hspace{0.17em} dt\\
      & = \sum_{t_0 : Z (t_0) = 0} \frac{| \dot{Z} (t_0) |}{| \dot{Z} (t_0)
      |} \phi (t_0)\\
      & = \sum_{t_0 : Z (t_0) = 0} \phi (t_0)
    \end{array}
  \end{equation}
  This shows that $\mu$ is the discrete measure
  \begin{equation}
    \mu (t) = \sum_{t_0 : Z (t_0) = 0} \delta_{t_0} (t)
  \end{equation}
  assigning unit mass to each zero.
\end{proof}

\subsection{Hilbert space on zeros and multiplication operator}

\begin{definition}
  {\tmstrong{[Hilbert space on the zero set]\label{labeldef:Hmu}}} Let
  $\mathcal{H}= L^2 (\mu)$ with inner product
  \begin{equation}
    \langle f, g \rangle = \int_{- \infty}^{\infty} f (t) \overline{g (t)}
    \hspace{0.17em} \mathd \mu (t)
  \end{equation}
\end{definition}

\begin{proposition}
  {\tmstrong{[Atomic structure]\label{prop:atomic}}} Let
  \begin{equation}
    \mu = \sum_{t_0 : Z (t_0) = 0} \delta_{t_0}
  \end{equation}
  then
  \begin{equation}
    \mathcal{H} \cong \left\{ f : \{t_0 : Z (t_0) = 0\} \to \mathbb{C}:
    \sum_{t_0 : Z (t_0) = 0} |f (t_0) |^2 < \infty \right\} \cong \ell^2
  \end{equation}
  with orthonormal basis $\{e_{t_0} \}_{t_0 : Z (t_0) = 0}$ where
  \begin{equation}
    e_{t_0} (t_1) = \delta_{t_0 } (t_1)
  \end{equation}
\end{proposition}

\begin{proof}
  By the atomic form of $\mu$, for any $f \in L^2 (\mu)$:
  
  \begin{align}
    \|f\|_{\mathcal{H}}^2 & = \int |f (t) |^2 \mathd \mu (t) \\
    & = \int |f (t) |^2  \sum_{t_0 : Z (t_0) = 0} \delta_{t_0}  (t) \\
    & = \sum_{t_0 : Z (t_0) = 0} |f (t_0) |^2 
  \end{align}
  
  This shows the isomorphism with $\ell^2$ where the functions $e_{t_0}$
  defined by
  \begin{equation}
    e_{t_0} (t_1) = \delta_{t_0} (t_1)
  \end{equation}
  satisfy the relations
  \begin{equation}
    \begin{array}{ll}
      \langle e_{t_0}, e_{t_1} \rangle & = \int e_{t_0} (t) \overline{e_{t_1}
      (t)} \mathd \mu (t)\\
      & = \sum_{t : Z (t) = 0} \delta_{t_0 } (t) \delta_{t_1} (t)\\
      & = \delta_{{t_0} } (t_1)\\
      & = \delta t_1 (t_0)
    \end{array}
  \end{equation}
  thus forming an orthonormal set. Thus, any $f (t) \in \mathcal{H}$ can be
  written as
  \begin{equation}
    f (t) = \sum_{t_0 : Z (t_0) = 0} f (t_0) e_{t_0} (t)
  \end{equation}
  proving they form a basis.
\end{proof}

\begin{definition}
  {\tmstrong{[Multiplication operator]\label{def:L}}} Define the linear
  operator
  \begin{equation}
    L : \mathcal{D} (L) \subset \mathcal{H} \to \mathcal{H}
  \end{equation}
  by
  \begin{equation}
    (Lf) (t) = tf (t)
  \end{equation}
  on the support of $\mu$ with domain
  \begin{equation}
    \mathcal{D} (L) \assign \left\{ f \in \mathcal{H}: \int |t f (t) |^2
    \mathd \mu (t) < \infty \right\}
  \end{equation}
\end{definition}

\begin{theorem}
  {\tmstrong{[Self-adjointness and spectrum]\label{thm:spectrum}}} $L$ is
  self-adjoint on $\mathcal{H}$ and has pure point, simple spectrum
  \begin{equation}
    \sigma (L) = \overline{\{t \in \mathbb{R}: Z (t) = 0\}}
  \end{equation}
  with eigenvalues $\lambda = t_0$ for each zero $t_0$ and corresponding
  eigenvectors $e_{t_0}$.
\end{theorem}

\begin{proof}
  First, self-adjointness is verified. For $f, g \in \mathcal{D} (L)$:
  \begin{equation}
    \begin{array}{ll}
      \langle Lf, g \rangle & = \int (Lf) (t) \overline{g (t)} \mathd \mu
      (t)\\
      & = \int tf (t) \overline{g (t)} \hspace{0.17em} \mathd \mu (t)\\
      & = \int f (t) \overline{tg (t)} \mathd \mu (t)\\
      & = \int f (t) \overline{(Lg) (t)} \mathd \mu (t)\\
      & = \langle f, Lg \rangle
    \end{array}
  \end{equation}
  Thus $L$ is symmetric and acts as
  \begin{equation}
    (Lf) (t_0) = t_0 f (t_0)
  \end{equation}
  for each $t_0$ in the atomic representation where
  \begin{equation}
    Z (t_0) = 0
  \end{equation}
  This is unitarily equivalent to the diagonal operator on $\ell^2$ with
  diagonal entries
  \begin{equation}
    \{t_0 : Z (t_0) = 0\}
  \end{equation}
  Such diagonal operators are self-adjoint. For the spectrum calculation:
  \begin{equation}
    Le_{t_0} = t_0 e_{t_0} \forall \{t_0 : Z (t_0) = 0\}
  \end{equation}
  holds, so each $t_0$ is an eigenvalue of $L$ with eigenvector $e_{t_0}$ and
  since $\{e_{t_0} \}$ forms an orthonormal basis, $L$ has pure point
  spectrum. The spectrum of a diagonal operator equals the closure of the set
  of diagonal entries, hence
  \begin{equation}
    \sigma (L) = \overline{\{t_0 : Z (t_0) = 0\}}
  \end{equation}
  The eigenvalues are simple.
\end{proof}

\subsection{Regularity and Simplicity of Sample Path Zero Crossings}

TODO: insert the fundamental theorem on the non-tangency of zero crossings so
that it doesnt have to be assumed but is in fact a fundamental theorem of
non-degenerate Gaussian processes

\begin{definition}
  {\tmstrong{[Regularity and simplicity]\label{def:regularity}}} Assume $Z \in
  C^1 (\mathbb{R})$ and every zero is simple:
  \begin{equation}
    Z (t_0) = 0 \Rightarrow \dot{Z} (t_0) \neq 0
  \end{equation}
\end{definition}

\begin{lemma}
  {\tmstrong{[Local finiteness and delta decomposition]\label{lem:delta}
  }}Under Definition~\ref{def:regularity}, zeros are locally finite and
  \begin{equation}
    \delta (Z (t)) = \sum_{t_0 : Z (t_0) = 0} \frac{\delta (t - t_0)}{|
    \dot{Z} (t_0) |}
  \end{equation}
  whence
  \begin{equation}
    \mu = \sum_{t_0 : Z (t_0) = 0} \delta_{t_0}
  \end{equation}
\end{lemma}

\begin{proof}
  Since $Z \in C^1 (\mathbb{R})$ and $\dot{Z} (t_0) \neq 0$ at each zero
  $t_0$, the inverse function theorem implies that $Z$ is locally invertible
  near each zero. Specifically, there exists a neighborhood $U_{t_0}$ of $t_0$
  such that $Z|_{U_{t_0}}$ is strictly monotonic and invertible.
  
  This implies zeros are isolated: if $Z (t_0) = 0$ and $\dot{Z} (t_0) \neq
  0$, then there exists $\epsilon > 0$ such that $Z (t) \neq 0$ for $0 < |t -
  t_0 | < \epsilon$. Therefore zeros are locally finite (finitely many in any
  bounded interval).
  
  For the distributional identity, the one-dimensional change of variables
  formula for the Dirac delta is considered. If $g : I \to \mathbb{R}$ is
  $C^1$ on interval $I$ with $\dot{g} (x) \neq 0$ for all $x \in I$, then
  \begin{equation}
    \delta (g (x)) = \sum_{x_0 : g (x_0) = 0} \frac{\delta (x - x_0)}{|
    \dot{g} (x_0) |}
  \end{equation}
  Applying this locally around each zero $t_0$ of $Z$, and since zeros are
  isolated, the local results can be patched together to obtain the global
  identity:
  \begin{equation}
    \delta (Z (t)) = \sum_{t_0 : Z (t_0) = 0} \frac{\delta (t - t_0)}{|
    \dot{Z} (t_0) |}
  \end{equation}
  Consequently:
  \begin{equation}
    \begin{array}{ll}
      \mathd \mu (t) & = \delta (Z (t)) | \dot{Z} (t) |  \hspace{0.17em} dt\\
      & = \sum_{t_0 : Z (t_0) = 0} \frac{| \dot{Z} (t) |}{| \dot{Z} (t_0) |}
      \delta (t - t_0)  \hspace{0.17em} dt\\
      & = \sum_{t_0 : Z (t_0) = 0} \delta_{t_0}  (dt)
    \end{array}
  \end{equation}
  where the last equality uses the fact that
  \begin{equation}
    \frac{| \dot{Z} (t_0) |}{| \dot{Z} (t_0) |} = 1
  \end{equation}
  when evaluating at $t = t_0$.
\end{proof}

\subsection{The Kac-Rice Formula For The Expected Zero Counting Function}

\begin{theorem}[Kac-Rice Formula for Zero Crossings]
  \label{thm:kac_rice}Let $Z (t)$ be a centered Gaussian process on $[a, b]$
  with covariance $K (s, t) =\mathbb{E} [Z (s) Z (t)]$ then the expected
  number of zeros in $[a, b]$ is
  \begin{equation}
    \label{eq:kac_rice} \mathbb{E} [N_{[a, b]}] = \int_a^b
    \sqrt{\frac{2}{\pi}}  \frac{\sqrt{K (t, t) K_{\dot{Z}} (t, t) - K_{Z,
    \dot{Z}} (t, t)^2}}{K (t, t)}  \hspace{0.17em} dt
  \end{equation}
  where
  \begin{equation}
    K (t, t) =\mathbb{E} [Z (t)^2]
  \end{equation}
  \begin{equation}
    K_{\dot{Z}} (t, t) = - \partial^2_s \partial_t K (s, t) |_{s = t}
  \end{equation}
  and
  \begin{equation}
    K_{Z, \dot{Z}} (t, t) = \partial_s K (s, t) |_{s = t}
  \end{equation}
\end{theorem}

\begin{proof}
  
  \begin{enumerate}
    The exact zero counting function is
    \begin{equation}
      N_{[a, b]} = \int_a^b \delta (Z (t)) | \dot{Z} (t) |  \hspace{0.17em} dt
    \end{equation}
    so
    \begin{equation}
      \label{eq:expectation} \begin{array}{ll}
        \mathbb{E} [N_{[a, b]}] & = \int_a^b \mathbb{E} [\delta (Z (t)) |
        \dot{Z} (t) |]  \hspace{0.17em} dt\\
        & = \int_a^b \int_{- \infty}^{\infty} |v|  \hspace{0.17em} p_{Z,
        \dot{Z}} (0, v)  \hspace{0.17em} dv \hspace{0.17em} dt
      \end{array}
    \end{equation}
    The vector $(Z (t), \dot{Z} (t))$ is bivariate Gaussian with covariance
    matrix
    \begin{equation}
      \Sigma = \left(\begin{array}{cc}
        K (t, t) & K_{Z, \dot{Z}} (t, t)\\
        K_{Z, \dot{Z}} (t, t) & K_{\dot{Z}} (t, t)
      \end{array}\right)
    \end{equation}
    whose determinant is given by
    \begin{equation}
      \det \Sigma = K (t, t) K_{\dot{Z}} (t, t) - K_{Z, \dot{Z}} (t, t)^2
    \end{equation}
    the inverse of which satisfies
    \begin{equation}
      \Sigma^{- 1}_{22} = \frac{K (t, t)}{\det \Sigma}
    \end{equation}
    yielding
    \begin{equation}
      p_{Z, \dot{Z}} (0, v) = \frac{1}{\sqrt{2 \pi K (t, t)}} \cdot \frac{e^{-
      \frac{K (t, t) v^2}{2 \det \Sigma}}}{\sqrt{2 \pi \det \Sigma / K (t,
      t)}}
    \end{equation}
    which factorizes as $p_Z (0) \cdot p_{\dot{Z} |Z} (v| 0)$ where
    \begin{equation}
      p_Z (0) = \frac{1}{\sqrt{2 \pi K (t, t)}}
    \end{equation}
    and
    \begin{equation}
      \dot{Z} |Z = 0 \sim \mathcal{N} (0, \det \Sigma / K (t, t))
    \end{equation}
    For zero-mean Gaussian $Y \sim \mathcal{N} (0, \sigma^2)$, direct
    integration gives
    \begin{equation}
      \begin{array}{ll}
        \mathbb{E} [|Y|] & = 2 \int_0^{\infty} \frac{y}{\sqrt{2 \pi \sigma^2}}
        e^{- y^2 / (2 \sigma^2)} dy\\
        & = \frac{2 \sigma}{\sqrt{2 \pi}}  \int_0^{\infty} e^{- u} du\\
        & = \sqrt{\frac{2}{\pi}} \sigma
      \end{array}
    \end{equation}
    so that combining results yields
    \begin{equation}
      \begin{array}{ll}
        \int_{- \infty}^{\infty} |v|  \hspace{0.17em} p_{Z, \dot{Z}} (0, v) 
        \hspace{0.17em} dv & = \frac{\sqrt{\frac{2}{\pi}}  \sqrt{\frac{\det
        \Sigma}{K (t, t)}}}{\sqrt{2 \pi K (t, t)}}\\
        & = \sqrt{\frac{2}{\pi}}  \frac{\sqrt{\det \Sigma}}{K (t, t)}
      \end{array}
    \end{equation}
  \end{enumerate}
\end{proof}

\begin{theorem}
  {\tmstrong{[Expected Zero-Counting
  Function]}}\label{thm:expected_zero_counting}Let $\theta \in \mathcal{F}$
  and let
  \begin{equation}
    \label{eq:covariance_def} K (t, s) = \mathrm{cov} (Z (t), Z (s))
  \end{equation}
  be twice differentiable at $s = 0$ and $t = 0$ then expected number of zeros
  of the process $Z (t)$ in $[a, b]$ is
  \begin{equation}
    \label{eq:expected_zeros} \mathbb{E} [N_{[a, b]}] = \sqrt{- K (0)} 
    \hspace{0.17em} (\theta (b) - \theta (a))
  \end{equation}
\end{theorem}

\begin{proof}
  The covariance function of the time-changed process is
  \begin{equation}
    \label{eq:time_changed_cov} \begin{array}{ll}
      K_{\theta} (s, t) & = \mathrm{cov} (Z (t), Z (s))\\
      & = \sqrt{\dot{\theta} (s) \dot{\theta} (t)} K (| \theta (t) - \theta
      (s) |)
    \end{array}
  \end{equation}
  For the zero-crossing analysis, consider the normalized process. By the
  Kac-Rice formula:
  \begin{equation}
    \label{eq:kac_rice_formula} \mathbb{E} [N_{[a, b]}] = \int_a^b \sqrt{-
    \lim_{s \to t}  \frac{\partial^2}{\partial s \partial t} K_{\theta} (s,
    t)}  \hspace{0.17em} dt
  \end{equation}
  Computing the mixed partial derivative:
  \begin{equation}
    \label{eq:mixed_partial} \frac{\partial}{\partial t} K_{\theta} (s, t) =
    \frac{1}{2}  \frac{\dot{\theta} (t)}{\sqrt{\theta (t)}} 
    \sqrt{\dot{\theta} (s)} K (| \theta (t) - \theta (s) |)
    \label{eq:mixed_partial_continued} + \sqrt{\theta (s)}  \sqrt{\theta (t)}
    \dot{K} (| \theta (t) - \theta (s) |) \mathrm{sgn} (\theta (t) - \theta
    (s)) \hspace{0.17em} \dot{\theta} (t)
  \end{equation}
  Taking the limit as $s \to t$ and using the fact that $\dot{K} (0) = 0$ for
  stationary processes:
  \begin{equation}
    \begin{array}{ll}
      \lim_{s \to t}  \frac{\partial^2}{\partial s \partial t} K_{\theta} (s,
      t) & = \lim_{s \to t} \dot{\theta} (s) \hspace{0.17em} \dot{\theta} (t) 
      \hspace{0.17em} \ddot{K} (0)\\
      & = \dot{\theta} (t)^2  \ddot{K} (0)
    \end{array} \label{eq:limit_mixed_partial}
  \end{equation}
  Substituting into the Kac-Rice formula we have
  \begin{equation}
    \label{eq:substituted_kac_rice} \begin{array}{ll}
      \mathbb{E} [N_{[a, b]}] & = \int_a^b \sqrt{- \dot{\theta} (t)^2 
      \hspace{0.17em} \ddot{K} (0)}  \hspace{0.17em} dt\\
      & = \sqrt{- \ddot{K} (0)}  \int_a^b \dot{\theta} (t)  \hspace{0.17em}
      dt\\
      & = \sqrt{- \ddot{K} (0)}  \hspace{0.17em} (\theta (b) - \theta (a))
    \end{array}
  \end{equation}
  since $\dot{\theta} (t) \geq 0$ almost everywhere.
\end{proof}

\begin{thebibliography}{1}
  \bibitem[1]{evolutionarySpectraAndNonStationaryProcesses}Maurice~B
  Priestley. {\newblock}Evolutionary spectra and non-stationary processes.
  {\newblock}\tmtextit{Journal of the Royal Statistical Society: Series B
  (Methodological)}, 27(2):204--229, 1965.{\newblock}
\end{thebibliography}

\end{document}
